[{"content":"　在怀来城内的守将亲眼见到了这一幕惨剧，但他也没有办法，只能派人快马加鞭回去报信，一天之后（八月十六日），京城的人们知道了这个消息。\n　天塌了。\n　二十万大军毁于一旦，无数文官武将战死，最为精锐的三大营全军覆没，京城已经不堪一击。\n　后宫太后和皇后哭成一团，大臣们如同热锅上的蚂蚁，急得跳脚却又没有办法，千头万绪从何处做起？\n　姜还是老的辣，此时吏部尚书王直站了出来，他明确地指出了问题的要害，也是当前必须先解决的首要矛盾：\n　皇帝是生是死？\n　是啊，乱成了一团，把皇帝给忘了，要知道，这确实是当前最为重要的问题。\n　兵没有了可以再召，大臣死了可以再考，其实皇帝死了倒也没有什么，再立一个就是了。\n　问题在于你得先确定朱祁镇先生是不是真的死了，万一把他当成死人注销了户口和皇籍，另外立了皇帝，过两天他自己屁颠屁颠地回来了，你还要脑袋不要？\n　社稷为重，君为轻，和国家比起来，你朱祁镇不算啥，但问题在于你得给个准消息，死了开追悼会，活着咱们再想办法。\n　太后和皇后当然希望他还活着，但大臣们就不一定了。\n　从后来的事情发展看，大臣们的意见应该是：皇帝死了比活着好。\n　朱祁镇，你还是死了吧，反正这一次把你祖宗的面子都丢光了，你死后我们好重新立一个皇帝，简单方便，别又搞出个建文帝来，折腾几十年。\n　有的时候，皇帝的命也是不值钱的。\n　虽然很残酷，但这是事实。\n　朱棣为了建文帝的消息足足等了二十一年，但朱祁镇的大臣们是幸运的，他们只等了一天。\n　正当大臣们盘算着这个问题时，有人前来通报，一个叫梁贵的锦衣卫（千户，随同出征）有要事禀报，也正是这个梁贵，带来了确定的答案。\n　皇帝陛下还活着。\n　人质\n　朱祁镇确实还活着。\n　在大军崩溃的时候，他的侍卫不是战死，就是早不见了踪影，人人只顾得上自己逃跑，也先士兵的喊杀声，被砍杀士兵的惨叫声汇成一片，小小的土木堡一下子变成了人间地狱。\n　朱祁镇虽然没有识人之明，却不是个窝囊废。\n　他失去了二十万大军，失去了大臣和侍卫，也失去了随身的所有财产，却保留了一样东西：\n　大明皇帝的尊严。\n　在这情况万分危急的时刻，他没有像其它人一样四散奔逃，而是安静地坐了下来，等待着决定自己命运时刻的来临。\n　此刻陪伴着朱祁镇的，是一个叫喜宁的太监。\n　不过，他可不是个好人。\n　一个瓦剌士兵发现了盘膝而坐的朱祁镇，便上前用刀威逼他，要他脱下身上穿着的贵重衣物。\n　出乎这位士兵意料的是，这个坐着的人根本就不理他，看都不看他一眼。\n　这位瓦剌士兵万万想不到，已经一盘散沙，只顾逃命的明军中居然还有这样的一个沉着镇定的人，自己手持利刃，张牙舞爪，这个人手无寸铁，却镇定自若，他顿时有一种被侮辱的感觉。\n　于是他举起了手中的刀，决定杀了这个人。\n　这一刀如果砍了下去，倒是省事了。\n　但就在此时，他的哥哥赶到了，这是一个见过世面的人，看到此人有如此气度，便阻止了他，说道：“这个人举止特别，不是一般人。”（此非凡人，举动自别）。\n　他随即请朱祁镇先生去见也先的弟弟——赛刊王。\n　赛刊王是瓦剌的高级人物，世面也算见得多了，但这位被俘的大明天子还是让他吃了一惊。\n　朱祁镇见到赛刊王后，也没有和他说客套话，居然先给他出了一道三选一的选择题。\n　“子额森（也先）乎？伯颜帖木尔（也先之弟）乎？赛刊王（猜对了）乎？”\n　赛刊王大惊失色，俘虏见得多了，但这样的真没有见过。派头实在不是一般的大，胆量也确实过人，他也拿不定主意了，只好跑去找他的领§导——也先。\n　也先得知此事后，大为震惊，他认为这个人很可能就是大明的皇帝，于是便让两个见过朱祁镇的部下去看，并最后证实了他的猜想。\n　一场争论就此展开。\n　七十多年前，蒙古贵族们被赶出中原，数十万大军被徐达、常遇春、蓝玉等人打得落花流水，才流落到了茫茫草原大漠。也先虽然不是黄金家族的人，但他已拥立了黄金家族的脱脱不花为大汗，继承了皇室正统，更重要的是，他也是蒙古人。\n　虽无家恨，却有国仇。\n　也先首先发言，他掩饰不住自己的喜悦，对众人说道：“我以前不断向上天祷告，希望大元有朝一日能统一天下，现在果然应验了，明军被我打败，天子也在我手！”\n　此时，一个名叫乃公的人说道：“上天把仇家赐给我们，杀掉他吧！”\n　我查了很多史料，也不知此人到底是个什么身份，估计是个无名小卒，他说这句话可能无非是想凑个热闹，拍个马屁而已，可是这个马屁实在拍得不是地方。\n　要知道，高级贵族谈话，哪有小人物说话的份，就如同电视剧里的黑社会谈判，大哥还没有开口，小弟就先跳出来，一般出现这种情况，小弟都不会有好下场，这次也不例外。\n　听到这句话，另一个重量级人物——朱祁镇选择题中的第二选择伯颜帖木尔开口了，他大怒，跳出来对也先说：“这人是什么东西，哪里有他说话的份！”\n　然后他用一个字打发了这位乃公：“滚（去）！”\n　处理完这位小弟后，伯颜帖木尔发表了自己的看法，他说的话很长，大致意思是，打仗这么乱，大明皇帝居然没有死，这说明上天还没有抛弃他，而且大明皇帝对我们一直都还不错，如果也先大人主动把皇帝送回去，能得个好名声，岂不是更好？\n　众人纷纷点头，也先同意他的看法，并把朱祁镇交给伯颜帖木尔看管。\n　史料记载如此，但我认为，这其中有一大半是胡扯的。\n　伯颜帖木尔和某些蒙古贵族不愿意杀朱祁镇，自然是历史的真实，但如此描述，就有点问题了，在这场争论中，看不到真正的反对意见，满篇仁义道德，很明显夹杂着后代史官的人生理念和思想。\n　也先虽然文化不高，但权谋手段还是懂得一些的，他既然与大明开战，就说明双方之间没有什么情分可谈，他又不是读四书五经长大的，所谓的好名声，他又怎么会在乎呢？\n　在我看来，事实应该是这样的：\n　也先：现在怎么处理朱祁镇呢？\n　伯颜帖木尔：杀掉他可能没有什么好处吧，不如留着他。\n　也先：留着他干什么？\n　伯颜帖木尔：真笨，皇帝在手里，还怕没有好处吗，可以带着他去要赎金，还可以带着他去命令边关守军开城门，天下就是我们的了！\n　于是众人纷纷点头，也先同意他的看法，并把朱祁镇交给伯颜帖木尔看管。\n　事实证明，这一推测并不是没有依据的，在后来的数年中，也先玩的也就是这几招。\n　从此，俘虏朱祁镇就成为了人质，而也先也摇身一变，成为了绑匪集团的头目。\n　根据绑匪集团内部安排，朱祁镇由绑匪第二把手伯颜帖木尔看管，但估计这位二当家做梦也没有想到，这个看似手无缚鸡之力的朱祁镇是个有着特殊才能的人。\n　朱祁镇的才能，就是他的人缘。\n　在我们的身边，经常会出现一些人，让我们一见如故，感觉温暖，如沐春风，这种气质往往是天生的，我们都愿意和这样的人交往。而朱祁镇正是一个这样的人。\n　年仅二十三岁的朱祁镇实际上是一个非常宽厚的人，他虽然身为皇帝，却对身边的下人很好，对大臣们也是礼遇有加，用谦谦君子，温润如玉来形容并不过分。\n　正是他的这种特质，使得他创造了一个奇迹。\n　在被敌人俘虏的窘境中，在时刻面临死亡威胁的阴影下，在异国他乡的茫茫大漠里，朱祁镇始终保持着镇定自若的态度，即使对自己的敌人也是有礼有节，时间一长，连看管他的蒙古士兵和军官都心甘情愿为他效力。\n　其中甚至还包括二当家伯颜帖木尔。\n　而朱祁镇的这种能力作用还不限于此，甚至在他回国后被弟弟关押起来时，奉命看守他的大臣也被他感化，心甘情愿任他驱使，为他出力。\n　在心理学中，有一种病症叫“斯得哥尔摩症候群”，这个名称来源于一起抢劫案，案件中的被劫人质一反常态，居然主动掩护枪匪逃走，阻拦警察，让很多人不解。\n　这个现象是可以用心理学来解释的：人质在强大的压力和威胁下，会倾向于服从控制自己的一方，这也正是为什么人质会服从配合绑匪的原因。著名的战争影片《桂河桥》描述的就是这样一群被日军俘虏后，积极配合日军军事行动，患上“斯得哥尔摩症候群”的人。\n　可是朱祁镇先生却开创了历史，他创造了“土木堡症候群”，在他的这种能力的影响下，绑匪竟然会主动站在人质一边！此后伯颜帖木尔不但数次要求释放朱祁镇，还主动为其争取皇位，每每看到这些记载，都让我目瞪口呆。\n　这真是一种可怕的能力。\n　忠诚与背叛\n　朱祁镇固然是个有亲和力的人，但很明显，他的亲和力并不是无往不胜的，至少对那位叫喜宁的太监就没有作用。\n　在朱祁镇被带走后，喜宁就迫不及待地抛弃了他的主人，投降了也先，现在看来，当初他守在朱祁镇身边，实在是别有企图，更为可恶的是，他还不断为也先出谋划策，并告知边关的防守情况，为蒙古军队带路，活脱脱就是一幅汉奸嘴脸。\n　也正是这个喜宁，主动向也先提出，现在京城空虚，可以立刻进攻，必可得中原。\n　估计这位太监与大明有仇，或是本来就是卧底，除此之外，实在无法理解他的行为动机。\n　也先雄心勃勃，在他看来，有了喜宁出谋划策，一统天下的梦想很快就能实现。\n　由于喜宁的背叛，朱祁镇身边没有了人照顾，于是也先为大明天子另外挑选了一个仆人，这个人叫袁彬，也是在大战中被俘虏的。\n　也先不会想到，他的这个随意的决定却给了朱祁镇极大的支持，在后来的岁月里，袁彬用他的忠诚陪伴着朱祁镇，并最终等到了自由的那一天。\n　而此刻以心腹自居，得意洋洋的喜宁也没有料到，在不久的将来，他会死在这个叫袁彬的人的手里。\n　在做好一切准备后，绑匪也先开始实行绑架的最后一个步骤：通知人质家属。\n　这是一件十分紧急的事情，当年没有电话，必须要找人去报信，而且这一次绑架比较特殊，报信的人必须加快速度，如果晚了的话，可能会出现“撕票”的情况。\n　所以他释放了一个叫梁贵的俘虏，让他赶紧回去报信，务必在对方“撕票”之前，把消息送到。\n　这也算是个举世奇闻，绑匪竟然怕“撕票”？\n　千真万确，三条腿的蛤蟆不好找，两条腿的皇帝还是容易立的，大明王朝的子孙繁衍速度是很快的，排队等皇位的人足以从东直门排到西直门。如果不赶紧，万一新立皇帝，手上的这个活宝就不值钱了。\n　于是，大明王朝的精英们就此得知：他们的好皇帝还活着。\n　这就麻烦了。\n　死了最好，死了可以重新立一个，失踪也不错，起码可以先立个皇帝，把事情解决完，等到一切走上正轨，即使前皇帝最终沿途乞讨回来了，也没有什么大的作用了。\n　可是现在的情形恰恰是最差的一种，人不但活着，还做了绑匪的人质，明目张胆地找你要赎金。\n　钱不是问题，要钱给你就是了，问题是即使给了钱，人也不一定能回来，如果让也先尝到了甜头，他可能会每年过年都会来要一次，就当是压岁钱。拿钱后又不放人，你要是敢不给，就是不顾皇帝死活，舆论压力也是顶不住的。\n　然而这并不是最麻烦的，更大的问题在后头。\n　由于王振一味想靠人数压倒也先，所以他出征时带走了京城三大营的全部兵力和北方明军的精锐，此时的北京城中，所剩兵力不到十万，还都是老弱残兵，而且士气低落。也先击溃了明军主力，必然会借助余威攻击北京城。照目前的情况看，凭借着这点兵力是很难抵挡住对方的攻势的。\n　而且也先进攻的时候必然会带着他的人质朱祁镇，作用很简单——当人盾。\n　其实朱祁镇的真正作用不在于他是皇帝，而在于所有的守军都知道他是皇帝！\n　不知道也就算了，问题是大家都知道也先手中的这个人是皇帝，而也先很清楚这一点，只要把大明皇帝放在他的队伍里，明军投鼠忌器，自然不敢真打，万一有哪个不长眼的在乱军中把皇帝打死了，那可就是灭族的罪过。\n　守也守不住，打也不能打，该怎么办呢？\n　在我看来，实在没有办法。\n　大明王朝即将陷入绝境。\n　怒吼\n　大臣们在思考着对策，他们毕竟经验多，阅历丰富，即使在如此不利的情况下，他们也能够冷静下来，商量解决问题的方法。\n　但后宫就不同了，朱祁镇被俘虏的消息如同晴天霹雳，一下子震晕了钱皇后，在女人看来，自己的丈夫是最重要的，于是她立刻把后宫的所有金银珠宝全部派人送到也先的军营里，希望能够赎回丈夫。\n　人回来了吗？当然没有。\n　也先好不容易抓到这么个稀世珍宝，还指望着慢慢收地租，吃利息，怎么可能把人送回来！\n　于是他耍了流氓，钱收了，人不放，表示这些还不够，要宫里接着给。\n　后宫哪里还有钱呢，钱皇后虽然姓钱，但也变不出钱来，于是只好每天哭天抢地，以泪洗面。\n　没经验就是没经验啊。\n　后宫干了蠢事，大臣们也无计可施，因为他们已经自顾不暇。眼看蒙古军队就要攻入北京，万事无头绪，人心惶惶，贪生怕死的倒是占了多数，很多人主张南迁。\n　这倒也怪不得他们，怕死是人的本性，不过这些怕死一族最担心的，倒不单单是自己的性命，还有他们的前途。\n　他们主张南迁，其实是有着私心的，在他们看来，北京可能保不住了，朝廷如不迁都，很有可能玉石俱焚，而如果南迁，即使半壁江山丢了，自己还是可以接着当官。\n　至于国家社稷，那实在是比较次要的事情。\n　这种情绪一直缠绕着文武百官，很多人也已经准备好包袱，南迁令一下马上就走。\n　但不管自己怎么打算，如果没有皇帝的命令，还是走不成的，于是怕死一族做好了准备，要在第二天的朝会上提出建议，一定要让皇帝同意南迁。\n　在这些逃跑派中，有一个人叫做徐珵。\n　此时的徐珵正跃跃欲试，他将在第二天提出自己南迁的建议，而且他很有自信，自己的建议一定能够得到皇帝的认可。\n　因为他有充分的理论依据。\n　第二天到来了。\n　正统十四年（1449）八月十八日。\n　大明王朝的国运就在这一天被决定。\n　早上，朝会正式开始，由暂代皇帝执政的朱祁钰主持。\n　这是大明王朝历史上十分重要的一次朝会，会议的主题是如何处理眼前的诸多问题，而其中最关键的问题就是逃还是战。\n　逃就会丢掉半壁江山，战则可能玉石俱焚。\n　朱祁钰初掌大权，十分紧张，他迫切地等待着群臣提出建议。然而接下来发生的事情却大出他的意料。\n　这些文武百官们上朝之后，竟然什么也不说，只是嚎啕大哭，整个朝廷哭成一片。\n　搞得朱祁钰手足无措，呆若木鸡。\n　其实这也容易理解，这些大臣们都有同事亲属在这次战乱中死去，而且好好的一个国家搞到如此地步，实在也让人心寒，多日的痛苦终于在朝会上得以发泄，算是哭了个痛快。\n　于是，这场关键朝会以痛哭拉开了序幕。\n　哭了一阵之后，大臣们渐渐恢复了理智，毕竟伤心总是难免的，活着的人还要应付眼前的难题。目前最关键的就是讨论朝廷是走还是留的问题。\n　徐珵首先发言，我们有理由相信，他已经等得不耐烦了，因为从他后来的表现来看，在他的心目中，最重要的永远是自己的荣华富贵。\n　徐珵大声说道：\u0026ldquo;我夜观天象，对照历数，发现如今天命已去，只有南迁才可以避过此难。\u0026rdquo;\n　这似乎是算命先生的说法，在座的人都是饱读诗书之辈，也不是三岁小孩，徐珵怎么会愚蠢到把所谓天象当成理论依据呢？他的这套理论又能说服谁呢，不是自取其辱吗？\n　可是奇怪的是，徐珵本人却洋洋得意，认定大家都会相信他。他到底凭什么如此自信呢？\n　这其中还是有原因的。\n　徐珵，吴县人（今苏州，姚广孝的同乡），宣德八年考中进士，正统十二年（1447）任侍讲学士，大家知道，所谓侍讲学士是个翰林官，如果不是博学之士是当不了的。而翰林院里往往书呆子多，每天只是不停地读圣人之言，四书五经，可是这位徐珵却是工作休闲两不误，除了经学理学外，他还有自己的个人爱好——阴阳术数之学。\n　前面提到过，所谓阴阳术数之学范围很广，包括天文、地理、兵法、算命等，可以说，这门学问如果钻研透了，倒也确实能出人才。著名的阴谋家姚广孝就是研究这个的，不过徐珵和姚广孝有所不同，姚先生研究的主要是前面三项（天文地理兵法），徐珵却偏偏挑了第四项（算命）。\n　算命这玩意可谓历史悠久，源远流长，具体准不准我们不好说，但只要人类对未知的恐惧仍旧存在，它就会不断延续下去。\n　徐珵就是一个有志于研究算命的人，他经常主动给人家算，虽说他不收钱，只是凭兴趣义务劳动，不过他经常算不准，所以人们也不大信他。\n　似乎上天想要挽救他的算命名声，在不久之后，这位失败的算命业余爱好者却对当时的一件重要事件做出了准确地判断。\n　这件事情就是土木堡之败。\n　在明英宗亲征前，他夜观天象，大惊失色，跑回家对老婆说：\u0026ldquo;我观天象，此战必败，到时瓦剌军队攻来就来不及了。你赶紧回老家躲躲吧。\u0026rdquo;\n　可是徐先生的算命水平连他的老婆都不相信，对他的这一忠告，人们只是笑笑而已。\n　所以当土木堡之败的消息传来后，徐珵除了对自己的将来命运的担忧之外，还有几分高兴。\n　\u0026ldquo;都不信我，现在信了吧！\u0026rdquo;\n　这件事情最终也挽救了他的算命威望，所以此刻他才能够如此有底气地说出那一番话。\n　让我们看看现在的大明王朝的五个关键词：\n　军队惨败皇帝被俘京城空虚人心惶惶投降（逃跑）派。\n　真是一片亡国之象。\n　这一幕似乎似曾相识，不错，在三百二十三年前，曾发生过极其相似的情况。\n　北宋靖康元年(1126)十月，盘踞北方的金兵对北宋发动进攻，太原、真定失守。十一月中旬，金军渡过黄河。宋钦宗惊慌失措，不知该怎么办，而大臣们全无战意，纷纷主张投降。\n　在这种情况下，十二月初二，宋钦宗正式向金投降。\n　靖康二年(1127)四月一日，金将完颜宗望押着被俘的宋徽宗、宋钦宗和赵氏皇子后妃、宫女四百余人及其掠夺的大量金银财宝回朝，北宋灭亡。\n　如果对照一下，就会发现，相隔三百多年的两个朝代，境况竟然如此的相似，都是兵败不久，都是京城空虚，都是人心惶惶，都是投降逃跑言论甚嚣尘上。而且此时的大明境况更为不利，因为他们的皇帝已经落在了敌人的手上，投鼠忌器，欲打不能。\n　但大明最终没有沦落到和北宋一样的下场，因为和当年的北宋相比，此时的大明多了一个人，多了一声怒吼：\n　“建议南迁之人，该杀！”\n　发言者，兵部侍郎于谦。\n　于谦\n　洪武三十一年（1398），明帝国送走了它的缔造者——朱元璋，这对于帝国而言，是一个不小的损失。\n　但也就在同一年，浙江钱塘县（现属杭州市）的一个普通家庭诞生了一个帝国未来的拯救者。这自然就是我们的主角于谦。\n　当然，当时的于谦并不是什么拯救者，对于还是婴孩的他而言，目前最重要的任务和目标就是吃奶。\n　由于家庭环境不错，于谦有着自己的书斋，他就在这里度过了自己的童年时光。与当时的所有读书人一样，于谦也是从四书五经开始自己的求学生涯的。\n　说老实话，像四书五经这种东西是很容易培养出书呆子的，但于谦似乎是个例外，他十分上进，读书用功刻苦，却从不拘泥于书本上的东西，除了学习考试内容，他还喜欢阅读课外书籍（如兵法等），历史告诉我们，喜欢看课外书的孩子将来一般都是有出息的。\n　就如同现在的追星族一样，于谦也有着自己的偶像，他把这位偶像的画像挂在自己的书斋里（此举比较眼熟），日夜膜拜。\n　有一次，教他读书的先生发现他经常看那幅画像，便好奇地问他为什么这样做。\n　于谦闻言，立刻正色回答：“将来我要做像他那样的人！”\n　画像上的人物就是文天祥。\n　除此之外，于谦还在书斋中写下了两句话作为对文天祥的赞词。\n　殉国忘身，舍生取义\n　宁正而毙，不苟而全！\n　在我看来，这正是少年于谦对自己未来一生的行为举止的承诺。\n　三十余年后，他用生命实现了自己的承诺。\n　永乐十九年（1421），于谦二十三岁，此时的他已经乡试中举，即将赴京赶考。\n　他将从此告别自己的家，告别江南水乡的故土，前往风云聚汇、气象万千的北京。\n　前路艰险，但于谦却毫无怯意，他明白，一个更为宽广的世界在等待着自己，实现平生抱负的时候到了。\n　于谦收拾好行李，告别家人，遥望前路漫漫，口吟一诗，踏上征途。\n　拔剑舞中庭，\n　浩歌振林峦！\n　丈夫意如此，\n　不学腐儒酸！\n　于谦，天下是广阔的，就此开始你波澜壮阔的一生吧！\n　清风\n　在京城的这次会试中，于谦顺利考中进士，并最终被任命为御史。在之后的宣德元年的朱高煦叛乱中，于谦以其洪亮的声音，严厉的词句，深厚的骂功狠狠地教训了这位极其失败的藩王，并给明仁宗留下了深刻地印象。\n　从此，于谦走上了青云之路。\n　宣德五年（1430），明宣宗任命于谦为兵部右侍郎，并派他巡抚山西、河南等地。这一年，于谦只有三十二岁。\n　年仅三十二岁，却已经位居正三品，副部级，实在不能不说是一个奇迹，于谦也成为了他同年们羡慕的对象。\n　这当然与朝中有人赏识他是分不开的，而着力栽培，重用他的正是“三杨”。\n　像杨士奇、杨荣这种久经宦海的人自然是识货的，于谦这样的人才逃不过他们的眼睛，事实上，当时确实有人对于谦升迁得如此之快表示不满，而杨士奇却笑着说：“此人是难遇之奇才，将来必成栋梁！我是为国家升迁他而已。”\n　奇才不奇才，栋梁不栋梁，也不是杨士奇说了算的，只有干出成绩，大家才会承认你。\n　于谦就此离开了京城，开始了他地方官的生涯，不过他估计也没有料到，这一去就是十九年。\n　在这十九年中，于谦巡抚山西、河南一带，他没有辜负杨士奇的信任，工作兢兢业业，在任期间，威望很高，老百姓也十分尊重他，更为难得的是，他除了有能力外，还十分清廉。\n　正统年间，王振已经掌权，他这个人是属于雁过拔毛型的，地方官进京报告情况，多多少少都会带点东西，即使是些日常用品，王振也来者不拒，让人哭笑不得。可是于谦却大不相同，他是巡抚，权力很大，却能够做到不贪一针一线。不但自己不贪，也不让别人贪。\n　一个贪，一个不贪，矛盾就此产生了。\n　于是正统六年（1441），一直看于谦不顺眼的王振找了个借口，把这位巡抚关了起来，结果之前我们已经说过了，王振完全没有估计到于谦的人望如此之高，如果要杀掉这个人，后果可能会极其严重。于是王振退让了，他放出了于谦。\n　这件事情也让王振了解到，于谦这个人是不能得罪的。后来于谦官复原职，王振连个屁都不敢放，可见王振此人实在是欺软怕硬，纯种小人。\n　在牢里仍然大骂王振的于谦出狱后仍然坚持了他的原则，清廉如故。\n　曾经有人劝于谦多少送点东西做人情，对于这样的劝解，于谦做了一首诗来回答。\n　估计他本人也想不到，这个无意间的回答竟然变成了千古名句，为人们所传颂。\n　绢帕蘑菇及线香，\n　本资民用反为殃。\n　清风两袖朝天去，\n　免得闾阎话短长！\n　成语两袖清风即来源于此，于谦先生版权所有，特此注明。\n　正统十三年（1448），于谦被召入京城，任兵部侍郎，他的顶头上司正是邝埜。\n　邝埜是一个十分正派的人，在其任间，他与于谦建立了良好的关系，两人合作无间，感情深厚。\n　如果就这么干下去，估计于谦会熬到邝埜退休，并接替他的位置，当一个正二品的大官，死后混一个太子太师（从一品）的荣誉称号，明史上留下两笔：于谦，钱塘人，何年何月何日生，任何官，何年何月何日死。\n　应该也就是这样吧。\n　对于于谦和邝埜自己而言，这样的生活似乎也不错，可是历史不能假设，邝埜不会退休，于谦也不会这么平淡活下去，惊天动地的正统十四年终究还是来到了。\n　之后便是我们已经熟悉的内容，贸易纠纷、边界吃了败仗、太监的梦想、愚蠢的决策、苦苦的劝阻、一意孤行、胡乱行军，最后一起完蛋了事。\n　于谦眼睁睁地看着这一切的发生，但他无能为力，他也曾陷入极端的痛苦，邝埜是一个好上司，好领§导，他给了自己很多帮助，而且从某种意义上说，那个牺牲在远征途中的命运可能本来应该属于自己。\n　不要再悲痛下去，是应该做点什么的时候了。\n　英雄\n　在国家出现危难之时，总有一些人挺身而出，为国效力，这样的人，我们称为英雄。\n　在每个人的心底，都有着当英雄的渴望，就连王振也不例外，他出征也是希望得到这个称号。\n　但英雄不是人人都能当的，如果那么容易，岂不人人都是英雄？！\n　一般看来，英雄是这样的几种人：\n　所谓英雄者，敢为人之所不敢为，敢当人之所不敢当。\n　所谓英雄者，挽狂澜于既倒，扶大厦于将倾。\n　所谓英雄者，坚强刚毅，屡败屡战。\n　如此之人，方可称为英雄！\n　但是在我看来，真正的英雄绝不限于此。\n　所谓英雄，其实是一群心怀畏惧的人。\n　要成为英雄，必须先学会畏惧。\n　何解？待我解来：\n　我们都曾经历天真无邪的童年，踌躇满志的少年，也时常梦想着将来一展抱负，开创事业，天下之大，任我往来！\n　但当你真正融入这个世界，就会发现，这并不是你自己一个人的世界，你会遇到很多的不如意，很多的挫折，事情从来不会如同你所想的那样去进行。\n　于是人们开始退缩，开始畏惧。\n　他们开始意识到，在这个世界上生存下去不是那么容易的。\n　于是有人沉沦，有人消极。\n　然而英雄就是在此时出现的。\n　这个世界上本来就不存在着天生的英雄，没有谁一生下来就会刚毅果断，坚强勇敢，在母亲怀中的时候，我们都是同样的人。\n　如果你的人生就此一帆风顺，那当然值得祝贺。\n　但可惜的是，这是不可能的。在你的成长历程中，必然会遇到各种各样的挫折。\n　而这些挫折会带给你许多并不快乐的体验，踌躇、痛苦、绝望，纷至沓来，让你不得安宁。\n　被人打才会知痛！被人骂才会知辱！\n　当你遭受这些痛和辱的时候，你才会明白，要实现你的目标是多么的不容易，你会开始畏惧，畏惧所有阻挡在你眼前的障碍。\n　如果你遇到这些困难，感到畏惧和痛苦，支撑不下去的时候，你应该同时意识到，决定你命运的时候到了。\n　因为畏惧并不是消极的，事实上，它是一个人真正强大的开始，也是成为英雄的起点。\n　不懂得畏惧的人不知道什么是困难，也无法战胜困难。\n　只有懂得畏惧的人，才能唤起自己的力量。\n　只有懂得畏惧的人，才有勇气去战胜畏惧。\n　懂得畏惧的可怕，还能超越它，征服它，最终成为它的主人的人，就是英雄。\n　所以英雄这个称号，并不单单属于那些建功立业，名留青史的人，事实上，所有懂得畏惧并最后战胜畏惧的人都是英雄。\n　因为即使你一生碌碌无为，平淡度日，但当你年老回望往事时，仍然可以为之骄傲和自豪。\n　在那个困难的时刻，我曾作出了勇敢的选择，我是当之无愧的英雄！\n　这就是我所认为真正的英雄——畏惧并战胜畏惧的人。\n　关键只在于那畏惧的一刻，你是选择战胜他，还是躲避他。\n　人生的分界线就在这里，跨过了这一步就是英雄！退回这一步就是懦夫！\n　于谦不是天生的英雄。\n　至少在正统十四年八月十八日的那个早晨之前，他还不能算是个真正的英雄。\n　虽然他为官清廉，虽然他官居三品，手握大权，但这些都不足证明他是一个英雄。\n　他还需要去显示他的畏惧和战胜畏惧的力量。\n　于谦是一个很强势的人，从他怒斥朱高煦到不买王振的帐，他一直都很强硬，似乎天下没有他怕的东西。\n　但这次不同，作为代理兵部事务的侍郎，他要面对的是瓦剌的大军和城内低迷的士气。自己生死可以置之度外，但如今国家的重担已经压在了自己的身上，必须谨慎处理，一旦出现失误，后果不堪设想。\n　于谦十分清楚，逃就会丢掉半壁江山，所以不能逃。\n　那么战呢，说说豪言壮语自然容易，但瓦剌攻来的时候，用语言是不可能退敌的。万一要是指挥失误，大明王朝有可能毁于一旦。\n　是战是逃，这是个问题。\n　面对如此重担，如此巨责，谁能不犹豫万分，谁能不心生畏惧！\n　于谦也是人，也会畏惧，但他之所以能够名留青史，永垂不朽，就因为他能战胜畏惧。\n　他并非天生就是硬汉。\n　从幼年的志向到青年的科举，再经过十余年的外放生涯，直到被召回京城，担任兵部侍郎，他并非一帆风顺，他曾平步青云，也曾被人排挤，身陷牢狱，几乎性命不保。但无论是成功还是失败，这一切都一直在磨练着他。\n　也正是在这一天天地磨练中，他逐渐变得坚毅，逐渐变得强大。\n　强大到足以战胜畏惧。\n　邝埜临走时期冀的目光还在他的眼前，到了这个时候，他应该站出来挽救危局。\n　可是身陷敌营成为人质的皇帝，也先精锐的士兵，城中惊慌失措的百姓，不堪一击士气低落的明军，还有类似徐珵这样只顾着自己的逃跑派煽风点火，一切的一切都在提醒他：\n　这是一团乱麻，一盘死棋。\n　殉国忘身，舍生取义\n　宁正而毙，不苟而全！\n　于谦最终还是迈出了这一步。\n　国家兴亡，我来担当！——《明朝那些事儿》\n","description":"正直大明王朝生死存亡之际，于谦站了出来，指导了北京保卫战，国士无双也。本文全部节选自《明朝那些事儿》，作者：当年明月。","id":4,"section":"posts","tags":["",""],"title":"力挽狂澜的于谦","uri":"https://niub.link/posts/yuqian/"},{"content":"收到慕课网直播间抽奖送的礼物了，今天最大的收获；\n","description":"自闭的一天，什么也不想说。","id":6,"section":"posts","tags":["",""],"title":"自闭的一天，什么也不想说","uri":"https://niub.link/posts/zibi/"},{"content":"0、今天搞点锤子语录 突然觉得罗锤子还是个蛮有趣的人。\n一、想开点，多数人本质上都是盲目崇拜强者的 二、撒娇改变不了什么，加油 三、高调和情怀都没有错 ","description":"罗永浩这句话我觉得很不错，大多数人都是盲目崇拜强者的。弱者，贫穷在这片土地上从来就不受欢迎。","id":7,"section":"posts","tags":["",""],"title":"搞点锤子语录","uri":"https://niub.link/posts/worship/"},{"content":"一、Spark海量数据处理：技术详解与平台实战 ★几句重要的   函数式编程属于声明式编程，与其相对的是命令式编程。 架构师技术的灵魂，它体现了技术对于需求的取舍，架构决定了技术的优点与缺点。 目前大数据与人工智能的结合是很多业务与应用成功的关键。   二、MySQL技术内幕：SQL编程 ★几句重要的   SQL编程是指通过SQL语言来完成对于数据库的逻辑操作。 逻辑查询处理表示执行查询应该产生什么样的结果，而物理查询代表MySQL数据库是如何得到该结果的。 只有理解事务的本质，那么所有的问题都会迎刃而解。   ","description":"Spark技术笔记、感想、画横线的重点，以及Spark对未来的展望。SQL，一直魂牵梦绕着我...花的时间太多了导致没有时间写正经博文了，先贴两张笔记长截图。","id":8,"section":"posts","tags":["",""],"title":"微信读书笔记截图（一）","uri":"https://niub.link/posts/read-note01/"},{"content":"一、运行时数据区域 “Java虚拟机在执行Java程序的过程中会把它所管理的内存划分为若干个不同的数据区域。这些区域有各自的用途，以及创建和销毁的时间，有的区域随着虚拟机进程的启动而一直存在，有些区域则是依赖用户线程的启动和结束而建立和销毁。”\nJava虚拟机运行时数据区：\n二、各个数据区域说明 2.1 程序计数器 程序计数器是一块内存较小的内存空间，它可以看做是当前线程所执行的字节码的行号指示器。主要是用来做什么的呢？是程序控制流的指示器，分支、循环、跳转、异常处理、线程恢复等基础功能都依赖这个程序计数器来完成。\n每条线程都需要有一个独立的程序计数器，各个线程之间计数器互不影响，独立存储，这种内存区域称为“线程私有”的内存。\n2.2 Java虚拟机栈 同程序计数器，虚拟机栈也是线程私有的，它的声明周期与线程相同。虚拟机栈中的局部变量表存放了编译期可知的各种Java虚拟机基本数据类型、对象引用类型和returnAddress类型（指向了一条字节码指令的地址）。\n这些数据类型在局部变量表中的存储空间以局部变量槽来表示，其中64位长度的long和double类型的数据会占用两个变量槽，其余的数据类型只占用一个。局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在栈帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。\n2.3 本地方法栈 本地方法栈与虚拟机栈所发挥的作用非常相似，它为虚拟机使用到的本地（Native）方法服务。\n2.4 ★ Java堆 对Java程序而言，Java堆是虚拟机所管理的内存中最大的一块。Java堆是被所有线程共享的一块内存区域，它在虚拟机启动的时候创建。它的作用是存放“对象的实例”。\nJava堆是垃圾收集器管理的内存区域，因此一些资料中它也被称作“GC堆”。\n “如果从分配内存的角度看，所有线程共享的Java堆中可以划分出多个线程私有的分配缓冲区（Thread Local Allocation Buffer，TLAB），以提升对象分配时的效率。不过无论从什么角度，无论如何划分，都不会改变Java堆中存储内容的共性，无论是哪个区域，存储的都只能是对象的实例，将Java堆细分的目的只是为了更好地回收内存，或者更快地分配内存。”——《深入理解Java虚拟机：JVM高级特性与最佳实践》\n 2.5 方法区 方法区（Method Area）与Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等数据。\n2.6 运行时常量池 运行时常量池（Runtime Constant Pool）是方法区的一部分。Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池表（Constant Pool Table），用于存放编译期生成的各种字面量与符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中。\n2.7 直接内存  “直接内存（Direct Memory）并不是虚拟机运行时数据区的一部分，也不是《Java虚拟机规范》中定义的内存区域。但是这部分内存也被频繁地使用，而且也可能导致OutOfMemoryError异常出现，所以我们放到这里一起讲解。\n在JDK 1.4中新加入了NIO（New Input/Output）类，引入了一种基于通道（Channel）与缓冲区（Buffer）的I/O方式，它可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆里面的DirectByteBuffer对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在Java堆和Native堆中来回复制数据。\n显然，本机直接内存的分配不会受到Java堆大小的限制，但是，既然是内存，则肯定还是会受到本机总内存（包括物理内存、SWAP分区或者分页文件）大小以及处理器寻址空间的限制，一般服务器管理员配置虚拟机参数时，会根据实际内存去设置-Xmx等参数信息，但经常忽略掉直接内存，使得各个内存区域总和大于物理内存限制（包括物理的和操作系统级的限制），从而导致动态扩展时出现OutOfMemoryError异常。”——《深入理解Java虚拟机：JVM高级特性与最佳实践》\n ","description":"Java虚拟机在执行Java程序的过程中会把它所管理的内存划分为若干个不同的数据区域。这些区域有各自的用途，以及创建和销毁的时间...","id":9,"section":"posts","tags":["Java",""],"title":"Java自动内存管理之运行时数据区","uri":"https://niub.link/posts/hello-jvm/"},{"content":"一、Kafka中几个重要的架构示意图 1.1 Kafka架构体系图 由图可知，Kafka通过Zookeeper管理集群的元数据，发布订阅模式使用的是send/pull的模式。\n1.2 Kafka消息写入模式图 可以看到Kafka写入消息的时在每个分区是有序的。\n1.3 Kafka分区多副本架构图  ISR副本同步队列，由一个Leader和多个Follower分区副本组成。leader副本负责同生产者、消费者打交道（即生产消息通过它，消费消息也是通过它），follower副本用于同步leader副本分区的数据，且follower分区副本都是分布在Kafka集群上的。\n“分区中的所有副本统称为AR（Assigned Replicas）。所有与leader副本保持一定程度同步的副本（包括leader副本在内）组成ISR（In-SyncReplicas），ISR集合是AR集合中的一个子集。消息会先发送到leader副本，然后follower副本才能从leader副本中拉取消息进行同步，同步期间内follower副本相对于leader副本而言会有一定程度的滞后。\n前面所说的“一定程度的同步”是指可忍受的滞后范围，这个范围可以通过参数进行配置。与leader副本同步滞后过多的副本（不包括leader副本）组成OSR（Out-of-Sync Replicas），由此可见，AR=ISR+OSR。在正常情况下，所有的follower 副本都应该与 leader 副本保持一定程度的同步，即 AR=ISR，OSR集合为空。”\n 1.4 偏移量说明示意图  读懂此图需要了解下面几个概念：\n HW：High Watermark的缩写，俗称高水位，它标识了一个特定的消息偏移量（offset），消费者只能拉取到这个offset之前的消息； LEO：是Log End Offset的缩写，它标识当前日志文件中下一条待写入消息的offset  上图中offset为6的消息对消费者而言是不可见的。\nLEO的大小相当于当前日志分区中最后一条消息的offset值加1。分区ISR集合中的每个副本都会维护自身的LEO，而ISR集合中最小的LEO即为分区的HW，对消费者而言只能消费HW之前的消息。\n 1.5 Kafka中主题、分区、副本、日志之间的关系图： 2020年10月12日22:53:42更新\nKafka中主题、分区、副本、日志之间的关系图：\n从Kafka的底层实现来说，主题和分区都是逻辑上的概念，分区可以有一至多个副本，每个副本对应一个日志文件，每个日志文件对应一至多个日志分段（LogSegment），每个日志分段还可以细分为索引文件、日志存储文件和快照文件等。\n严谨地说，其实＜topic＞-＜partition＞这类文件夹对应的不是分区，分区同主题一样是一个逻辑的概念而没有物理上的存在。\n一层一层扒皮，Kafka最终落地的物理文件是分段的日志文件（LogSegment）。同理，我们可以类比HBase，最终的物理落地文件是存储在HDFS之上的HFile文件。HBase在分层组织形式上和Kafka很类似：\n   Kafka中的概念 HBase中的概念 说明     主节点：Controller Broker 主节点：Master 同理，Spark中的Cluster Manager、Flink中的JobManager\u0026hellip;   从节点：Broker 从节点：RegionServer HBase中RegionServer的具体实现是HRegionServer   主题：Topic 表：Table Kafka中主题是逻辑概念，Table是逻辑概念吗？   分区：Partition 区域：Region Kafka中的分区是分布在不同的Brokers上的，HBase中的Region是分布在不同RegionServers上的。   分区副本（leader副本、follower副本） 无Region副本 因为HBase最终的文件落地是HDFS上的HFile。   Log（LogSegment） StoreFile（HFile） 分区副本再往下就是物理概念，文件以日志的形式存储。   LogSegment包括：索引文件.index、日志存储文件.log、时间戳.timeindex、快照等文件.snapshot HFile包括：Scanned block section、Nonscanned block section、Load-on-open section、Trailer等 Nonscanned block section、Load-on-open section、Trailer算是HFile的元数据信息。    对比学习法，一层一层扒皮\u0026hellip;会发现很多大数据生态组件组件有很多异曲同工的地方。\n二、Kafka基本使用 2.1 创建主题 创建一个名为topic-demo的主题，且副本因子为3，分区数为4：\n1  bin/kafka-topics.sh --zookeeper hadoop200m:2181 --create --topic topic-demo --replication-factor 3 --partitions 4    各个参数说明：\n\u0026ndash;zookeeper 指定了Kafka所连接的Zookeeper服务地址\n\u0026ndash;create 创建主题的动作指令\n\u0026ndash;topic 指定了创建的主题名称\n\u0026ndash;replication-factor 指定了副本因子\n\u0026ndash;partitions 指定分区个数\n\u0026ndash;describe 展示主题的更多具体信息\n 2.3 查看主题详细信息 查看topic-demo的主题详细信息：\n1  bin/kafka-topics.sh --zookeeper hadoop200m:2181 --describe --topic topic-demo   2.3 订阅(消费)主题 通过kafka-console-consumer.sh脚本订阅topic-demo主题：\n1  bin/kafka-console-consumer.sh --bootstrap-server hadoop200m:9092 --topic topic-demo    参数的含义：\n\u0026ndash;bootstrap-server 指定了连接Kafka集群地址\n\u0026ndash;topic 指定消费者订阅的主题\n 2.4 生产者生产消息 生产者生产消息到topic-demo主题：\n1  bin/kafka-console-producer.sh --broker-list hadoop200m:9092 --topic topic-demo    \u0026ndash;broker-list 指定了连接Kafka集群地址\n 三、使用Kafka API生产/消费的逻辑步骤 3.1 生产逻辑 生产逻辑的几个步骤：\n 配置生产者客户端参数及创建相应的生产者实例 构建待发送的消息 发送消息 关闭生产者实例  3.2 消费逻辑 消费逻辑的几个步骤：\n 配置消费者客户端参数及创建相应的消费者实例 订阅主题 拉取消息并消费 提交消费位移（偏移量） 关闭消费者实例  ","description":"消息会先发送到leader副本，然后follower副本才能从leader副本中拉取消息进行同步，同步期间内follower副本相对于leader副本而言会有一定程度的滞后。","id":11,"section":"posts","tags":["Kafka"],"title":"Kafka几个重要的图","uri":"https://niub.link/posts/kafka-02/"},{"content":"一、Kafka副本机制 Kafka使用Zookeeper来维护集群Brokers的信息，每个Broker都有一个唯一的标识broker.id，用于标识自己在集群中的身份。Brokers会通过Zookeeper选举出一个叫Controller Broker节点，它除了具备其它Brokers的功能外，还负责管理主题分区及其副本的状态。\n在Kafka中Topic被分为多个分区（Partition），分区是Kafka最基本的存储单位。在创建主题的时候可使用replication-factor参数指定分区的副本个数。分区副本总有一个Leader副本，所有的消息都直接发送给Leader副本，其它副本都需要通过复制Leader中的数据保存数据一致。当Leader副本不可用时，其中一个Follower将成为新的Leader。\n每个分区都有一个ISR列表，用于维护所有同步的、可用的副本。并不是所有Follower都有资格成为同步副本，需要满足下面两个条件：\n 与Zookeeper有一个活跃的会话，定时向其发送心跳 在规定的时间内从Leader副本那低延迟地获取消息  如果不满足上述条件，会被从ISR列表中移出，直到满足条件后才会被加入到ISR中。\n★ Kafka为什么提供元数据请求机制？\n 在所有副本中，只有Leader副本才能进行消息的读写处理。由于不同分区的领导副本可能在不同的 broker 上，如果某个 broker 收到了一个分区请求，但是该分区的领导副本并不在该 broker 上，那么它就会向客户端返回一个Not a Leader for Partition的错误响应。\n 二、Kafka偏移量 2.1 生产者和消费者 Kafka中Topic由于分区的存在，因此无法保证这个Topic范围内消息有序，但是可以保证消息在单个分区内有序。\n生产者：生产者负责创建消息，一般情况下生产者会把消息均衡地分布到所在Topic的分区上，如果我们想把信息写到指定的分区，可以通过自定义分区器来实现。\n消费者：负责消费消息。消费者可以订阅一个或者多个Topic。消费者通过消息的offset来区分消息是否消费。偏移量是一个不断递增的数值，在创建消息时，Kafka会把它添加到其中，给定分区中的消息偏移量是唯一的。消费者把每个分区最后读取的偏移量保存在Zookeeper或Kafka中，如果消费关闭或者重启，它还可以重新获取offset，以保证状态不会丢失。\n 注意：一个分区只能被一个消费者群组当中的一个消费者所消费，但是可以被不同群组的所组成的多个消费者共同消费。\n 2.2 Kafka消费详解 ★ Kafka为什么要设置消费者群组这个东西？\n 单个消费者消费能力有限且还经常做一些高延迟的操作，比如将数据写入数据库或者HDFS，或者对数据进行耗时计算，这种情况下单个消费者完全无法跟上数据生产的速度。因此Kafka引入了消费者群组这个概念，通过群组内的更多消费者去消费消息，让它们分担负载，分别处理各个Partition上的消息。\n 2.3 生产者相关 生产者向Topic发送消息的两种方式：\n 同步发送 异步发送  ★ 生产者如何保证消息成功发送？\n生产者有一个可选参数ack，可设置发送数据是否需要服务端的反馈。该参数在一定程度上保证了Kafka写入消息的容错性。\n  当acks = 0时，消息发送出去就认为已经成功了，不会等待任何来自Broker的响应； 当acks = 1时，只要集群Leader副本收到消息，则认为发送成功； 当acks = -1时，所有的follower副本都接受消息时，则认为发送成功；   ★ Kafka有哪些优点，为什么它可以做到每秒上百万消息的高效分发？\n  高吞吐量，低延迟【零拷贝写入数据、Topic分区、Consumer分组】 良好的扩展性、容错性 持久性、可靠性：消息能被持久化到本地磁盘，并且有副本策略 高并发【支持上千个客户端同时读写】   2.4 偏移量 偏移量是一个不断递增的数值，在创建消息时，Kafka会把它添加到其中，给定分区中的消息偏移量是唯一的。\n★ 关于偏移量的重要性\n Kafka的每一条消息都有一个偏移量属性，它是一个不断递增的数值，该属性记录了消息在分区中的位置。当消费者消费消息时，会往一个叫_consumer_offset的特殊主题发送消息，消息里面包含其消费每个分区的偏移量。消费者不消费时，会触发分区再均衡。那么问题来了，等下一次该消费者消费消息时如何知道该从哪里开始消费呢？\n偏移量的作用就在此，为了能够继续之前的工作，消费者需要读取每个分区最后一次提交的偏移量，然后从偏移量指定的地方继续处理。\n可见，如果不能够正确的提交偏移量，则可能会造成下面的问题：\n 提交的offset \u0026gt; 客户端last commit offset，则会造成消息漏消费； 提交的offset \u0026lt; 客户端last commit offset，则会造成消息重复消费；   Kafka中提供了几种提交偏移量的方式：\n 自动提交偏移量 手动提交偏移量  同步提交方式 异步提交范式 同步+异步提交方式    ★ Kafka在什么情况下会触发分区再均衡？\n 分区再均衡可能出现在如下几种情况：\n（1）当Topic发生变化时，比如新的Partition加入Topic，分区和消费者会被重新分配；\n（2）当消费者群组发生变化时，比如某个消费者因意外因素导致下线，它离开群组之后，原本由它消费的Partition会被交由群组内其它消费者消费。这是因为消费者会在轮询消息时或者提交偏移量时发送心跳，如果消费者停止发送心跳的时间足够长，会话过期，群组协调器认为它已经死亡，因而会触发分区再均衡。（新的消费加入群组也会触发分区再均衡）；\n ","description":"在Kafka中Topic被分为多个分区（Partition），分区是Kafka**最基本的存储单位**。在创建主题的时候可使用`replication-factor`参数指定分区的副本个数。","id":12,"section":"posts","tags":["Kafka"],"title":"Kafka副本机制和偏移量","uri":"https://niub.link/posts/kafka-01/"},{"content":"一、RDD是什么有何特点？ 1.1 RDD的基本概念 什么是RDD？Spark官网给出的解释是：\n The main abstraction Spark provides is a resilient distributed dataset (RDD), which is a collection of elements partitioned across the nodes of the cluster that can be operated on in parallel.\n RDD全称是一个叫弹性分布式数据集的东西，是Spark对数据的核心抽象，也是最关键的抽象，它实质上是一组分布式的JVM不可变对象集合。不可变意味着它是只读的，RDD在经过转换产生新的RDD时，原有的RDD不会改变。\nSpark提供一个统一的数据解决方案——RDD，所有需要经过Spark引擎处理的数据都需要被转成RDD，这样便可以提供统一的计算引擎结构。RDD可以处理很多种类型数据，比如JSON、text、集合\u0026hellip;，使用Spark进行分布式计算编程，最核心的就是RDD。\nRDD名字中虽然带有分布式，但是它的目的却是要让用户感觉不到分布式，而像操作本地数据集一样操作在分布式存储中的数据。用户可以将RDD看作一个数组，数组并没有保存数据，而是每个数据分区的引用，数据以分区中的元素的形式分散保存在集群中的各个节点上。从这个角度上来说，RDD存储的是元数据而非数据本身。\n1.2 RDD中有什么 每个RDD都有如下几个成员：\n 分区的集合 用来基于分区进行计算的函数（算子） 依赖（与其他RDD）的集合 对于用来计算出每个分片的地址集合（如HDFS上文件的块存储地址） 对于KV类型的RDD而言有散列分区器  1.3 RDD有什么特性？   RDD维护血统关系图\n    延迟计算\n    支持持久化\n 当对RDD执行持久化操作时，每个节点都会将自己操作的partition数据持久化到内存中，并且之后对该RDD的反复使用中直接使用内存中缓存的partition数据。\n巧妙使用RDD持久化，在某些场景下对spark应用程序的性能有很大的提升。\n如何持久化一个RDD？调用cache()或者persist()方法即可；cache()是persist()的简化方式，cache()底层调用是persist()无参版本，也就是调用persist(MEMORY_ONLY)，将数据持久化到内存中。\n常见的几种持久化策略机制：\nMEMORY_ONLY\nMEMORY_AND_DISK\nMEMORY_ONLY_SER\nMEMORY_AND_DISK_SER\nDISK_ONLY\nMEMORY_ONLY_2、MEMORY_AND_DISK_2\n   二、RDD中的算子 2.1 关于RDD中的算子 “RDD算子主要分为两类，一类为转换（transform）算子，另一类为行动（action）算子，转换算子主要负责改变RDD中数据、切分RDD中数据、过滤掉某些数据等。转换算子按照一定顺序组合，Spark会将其放入到一个计算的有向无环图中，并不立刻执行，当Driver请求某些数据时，才会真正提交作业并触发计算，而行动算子就会触发Driver请求数据。这种机制与函数式编程思想的惰性求值类似。这样设计的原因首先是避免无谓的计算开销，更重要的是Spark可以了解所有执行的算子，从而设定并优化执行计划。”\n转换算子：主要负责改变RDD中数据、切分RDD中数据、过滤掉某些数据等。\n行动算子从功能上来说作为一个触发器，会触发提交整个作业并开始执行。从代码上来说，它与转换算子的最大不同之处在于：转换算子返回的还是RDD，行动算子返回的是非RDD类型的值，如整数，或者根本没有返回值。\n2.2 窄依赖和宽依赖 窄依赖的准确定义是子RDD中的分区与父RDD中的分区只存在一对一的映射关系，而宽依赖则是子RDD中的分区与父RDD中的分区存在一对多的映射关系，那么从这个角度来说，map、filter、union等就是窄依赖，而groupByKey、cogroup就是典型的宽依赖。如下图所示：\n理解宽窄依赖还是很有用的，因为Spark作业是按照宽窄依赖划分计算阶段Stage，DAGScheduler在遇到Shuffle的时候会生成一个计算阶段，在遇到Action函数的时候会生成一个作业（Job）。\n","description":"RDD全称是一个叫弹性分布式数据集的东西，是Spark对数据的核心抽象，也是最关键的抽象，它实质上是一组分布式的JVM不可变对象集合。","id":13,"section":"posts","tags":["Spark",""],"title":"RDD知识点梳理","uri":"https://niub.link/posts/about-rdd/"},{"content":"一、Spark Executor端内存管理模型详解 1.1 前言 众所周知Spark是一代基于内存进行计算的大数据计算引擎框架，它能够有效的利用内存进行分布式计算。为了更好的利用Spark，深入地理解其内存管理模型有着很重要的意义。当程序出现BUG时能够快速且头脑清醒的定位问题，对工作中Spark调优也有一定的帮助。本文主要探讨的是Spark2.x版本的Executor端的内存模型，Driver端的内存模型在此先不表。\n1.2 堆内内存（On-heap Memory） Executor进程作为一个JVM进程，其内存管理建立在JVM的内存管理之上，下图所展示了Executor进程的内存模型：\nExecutor端堆内内存模型如下图所示：\n一般情况下，Spark仅仅使用了堆内内存，Executor端的堆内内存区域可以分为以下四大块：\n Execution内存：主要用于存放Shuffle、Join、Sort、Aggregation等计算过程中的临时数据 Storage内存：主要用于存储Spark的cache数据，例如RDD的cache，Broadcast变量，Unroll数据等。需要注意的是，unrolled的数据如果内存不够，会存储在driver端 用户内存（User Memory）：主要用于存储 RDD 转换操作所需要的数据，例如 RDD 依赖等信息 预留内存（Reserved Memory）：系统预留内存，用来存储Spark内部对象  1.3 堆外内存（Off-heap Memory） 堆外内存是自Spark1.6之后引入的，这种模式并不在JVM内存中申请内存。所以堆外内存不受JVM内存管理，可以避免频繁的GC，但是有一个缺点是必须用户自己编写内存申请和释放的逻辑。\n默认情况下堆外内存是关闭的，可通过spark.memory.offHeap.enabled参数启用，并通过spark.memory.offHeap.size参数设置堆外内存的大小，单位为字节。如果堆外内存被启用，那么Executor内将同时存在堆内和堆外内存，两者的使用互补影响，这个时候Executor中的Execution内存是堆内的Execution内存和堆外的Execution内存之和，同理，Storage内存也一样。\n与Executor堆内内存相比，堆外内存只有Execution内存和Storage内存，结构图如下所示：\n1.4 Execution内存和Storage内存之间的动态调整 在Spark1.5之前，Execution内存和Storage内存分配是静态的。换言之，如果Execution内存不足，即使Storage内存还有很多空闲内存也是无法被Execution所利用的。\n而现在Execution内存和Storage内存可以互相共享（双向共享，单向回收）的。也就是说，如果 Execution内存不足，而Storage内存有空闲，那么Execution可以从 Storage中申请空间；反之亦然。所以上图中的虚线代表Execution内存和Storage内存是可以随着运作动态调整的，这样可以有效地利用内存资源。\nExecution内存和Storage内存之间的动态调整图如下所示：\n具体的实现逻辑如下：\n 程序提交时会设定基本的Execution内存和Storage内存区域（通过 spark.memory.storageFraction 参数设置）； 在程序运行时，如果双方的空间都不足时，则存储到硬盘；将内存中的块存储到磁盘的策略是按照LRU规则进行的。若己方空间不足而对方空余时，可借用对方的空间;（存储空间不足是指不足以放下一个完整的 Block） Execution内存的空间被Storage占用后，可让对方将占用的部分转存到硬盘，然后\u0026quot;归还\u0026quot;借用的空间； Storage内存的空间被Execution占用后，目前的实现是无法让对方\u0026quot;归还\u0026quot;，因为需要考虑 Shuffle 过程中的很多因素，实现起来较为复杂；而且 Shuffle 过程产生的文件在后面一定会被使用到，而 Cache 在内存的数据不一定在后面使用。  可见，“双向共享，单向回收”指的是Execution占用的Storage内存无法被Storage所“归还”。\n1.5 Task任务如何使用内存 为了更高效的利用宝贵的内存资源，Executor内运行的Task之间共享着 Execution内存。\n二、Spark架构原理（入门级） 2.1 Spark计算阶段的划分 Spark会根据应用的复杂程度，将计算程序分割成更多的计算阶段（stage），这些计算阶段组成一个有向无环图DAG，Spark任务调度器可以根据DAG的依赖关系执行计算阶段。\n所谓DAG也就是有向无环图，就是说不同阶段的依赖关系是有向的，计算过程只能沿着依赖关系方向执行，被依赖的阶段执行完成之前，依赖的阶段不能开始执行，同时，这个依赖关系不能有环形依赖，否则就成为死循环了。下面这张图展示了一个典型的Spark运行DAG的不同阶段：\n从上图可知，整个应用被划分为3个阶段，且阶段3需要依赖阶段1和阶段2，而阶段1和阶段2互不依赖；Spark在执行调度的时候，先执行Stage1和Stage2，再执行Stage3，如果有更多的阶段，其策略也是一样的。\n只要根据程序初始化好DAG，然后根据依赖关系顺序执行各个计算阶段。更为详细的说，Spark是通过DAGScheduler负责生成并管理DAG。DAGScheduler根据用户编写的代码生成DAG，然后将程序分发到分布式计算集群，按计算阶段的先后关系调度执行。可见，有了DAG，每个阶段的计算任务划分好了，将程序分发到集群的WorkNode上去执行，便实现了分布式计算。\n★ 那么问题来了，DAG是根据什么划分Stage的呢？\n 答案是根据是否发生Shuffle过程（或者说根据宽窄依赖划分）。\nSpark也需要通过shuffle将数据进行重新组合，相同Key的数据放在一起，进行聚合、关联等操作，因而每次shuffle都产生新的计算阶段。这也是为什么计算阶段会有依赖关系，它需要的数据来源于前面一个或多个计算阶段产生的数据，必须等待前面的阶段执行完毕才能进行shuffle，并得到数据。\nShuffle是一项昂贵的操作，但是，shuffle也是Spark最重要的一个环节，只有通过shuffle，相关数据才能互相计算，构建起复杂的应用逻辑。\n ★ 为什么Spark比MapReduce计算更高效呢？\n  Spark是基于内存计算的，只有当内存不够时才会使用磁盘。本文的第一部分讲的就是关于Spark内存模型的管理； 从本质上来说Spark计算也是基于MapReduce的，但是它更为细腻。细腻在它通过DAG把作业划分为Stage，减少作业的调度次数，使得很多计算步骤避免对HDFS不必要的访问。   2.2 Spark的作业管理 Spark中RDD函数有两种，一种是Transformation函数（转换函数），一种是Action函数。Transformation函数调用以后得到的还是一个RDD，RDD的计算逻辑主要是通过转换函数来完成。而Action函数调用以后不再返回RDD了，比如count()函数，返回RDD中数据的元素个数；saveAsTextFile(path)，将RDD数据存储到path路径下。\nSpark的DAGScheduler在遇到shuffle的时候，会生成一个计算阶段，在遇到action函数的时候，会生成一个作业（job）。在遇到Action函数之前所有的RDD操作执行的都是逻辑操作，并没有真正被执行，这种也叫做懒式加载，Lazy化的加载方式有利于Spark对应用程序的优化。\n★ Spark作业中几个核心概念：\n Job（作业）：以Action函数为界限，将代码切分成多个Job； Stage（调度阶段）：根据宽窄依赖划分Stage； Task（任务）：真正执行计算的部分。Stage相当于TaskSet，每个Stage内部包含了多个Task，并将多个Task发送到各个Executor中执行计算。**每个Task的处理逻辑完全一样，不同的是对应处理的数据。**还是“移动数据不如移动计算”的大数据计算思想； Partition（分区）  2.3 Spark作业执行过程 首先看一下Spark的运行流程图：\n 首先，Spark应用程序启动在自己的JVM进程里，即Driver进程，启动后调用SparkContext初始化执行配置和输入数据。SparkContext启动DAGScheduler构造执行的DAG图，划分Stage然后切分成最小的执行单位也就是计算任务。\n然后Driver向Cluster Manager请求计算资源，用于DAG的分布式计算。Cluster Manager收到请求以后，将Driver的主机地址等信息通知给集群的所有计算节点Worker。\nWorker收到信息以后，根据Driver的主机地址，跟Driver通信并注册，然后根据自己的空闲资源向Driver通报自己可以领用的任务数。Driver根据DAG图开始向注册的Worker分配任务。\nWorker收到任务后，启动Executor进程开始执行任务。Executor先检查自己是否有Driver的执行代码，如果没有，从Driver下载执行代码，通过Java反射加载后开始执行。\n 2.4 小结 先炒菜去了\u0026hellip;2020-10-8 18:24:44\nSpark三个特点使得分布式计算变得更加简单、高效、快速：\n RDD编程模型 DAG切分多Stage 使用内存存储中间结果  ヾ(⌐■_■)ノ 帅瞎\n","description":"众所周知Spark是一代基于内存进行计算的大数据计算引擎框架，它能够有效的利用内存进行分布式计算。为了更好的利用Spark，深入地理解其内存管理模型有着很重要的意义。","id":14,"section":"posts","tags":["Spark"],"title":"浅析Spark内存管理并附送入门级架构原理","uri":"https://niub.link/posts/spark-mem-and-process/"},{"content":"一、关于HBase建表时的几个设计原则 1.1 预分区 背景：HBase默认建表时有一个Region，且这个Region是没有RowKey边界的，所有数据在写入时都是往这个默认的Region中存入数据。随着数据量的不断增加，Region达到一定大小后会自动Split，而Split过程中会产生两个问题：\n 数据可能只会往一个Region里面写，造成热点问题； Split是昂贵的操作，会消耗宝贵的集群IO资源；  对策：在创建表的时候，创建多个空Region，并确定每个Region的StartRowKey和EndRowKey，通过RowKey的合理设计使得数据均匀的落在各个Region上，不会存在热点问题；\n1.2 RowKey的设计原则 （1）RowKey长度越短越好。HBase中的底层数据是以HFile文件形式组织的，而HFile中是安装KV存储的，如果K过大会极大的影响存储效率；写入数据时会经过MemStore，如果K过长所占空间过大，内存的有效利用就会降低。\n（2）RowKey尽量散列。建议将RowKey的高位作为散列字段，使得数据均衡分布在每个RegionServer，提高负载均衡的几率，避免热点问题；\n（3）保证RowKey的唯一性\n1.3 列族的设计原则 （1）列族名不宜过长\n（2）建表时至少指定一个列族，列族一般不超过五个\n（3）不同列族的记录数据集不应相差太大\n二、关于HBase的常用优化方法 2.1 调优从如下几方面着手 （1）Master高可用：在HBase中Master负责监控RegionServer的生命周期，均衡RegionServer的负载，如果Master宕机则HBase集群将无法使用。\n（2）RegionServer预分区：提前大致规划好RegionServer的分区，因为每一个Region维护着StartRowKey和EndRowKey，如果加入的数据RowKey符合某个范围，则把该数据提交给Region。\n（3）优化RowKey的设计：RowKey是数据的唯一表示，数据存储在哪个Region取决于RowKey在哪一个预分区区间内，所以合理设计RowKey可在一定程度上防止数据倾斜。\n（4）内存优化：HBase操作的过程中需要大量的内存开销，一般会分配整个可用内存的70%给HBase的Java堆，如果配置太大则GC过程持续太久会导致RegionServer长期处于不可用状态。\n（5）减少Region分裂次数，给HFile设置合理大小；\n2.2 各种减少 （1）关闭Compation操作，合并操作在业务低峰时手动进行；\n（2）减少数据量，开启布隆过滤器可提高查询速度，降低网络I/O\n（3）数据存储时使用压缩，如Snappy、LZO、GZip等压缩方式\n2.3 HMaster和HRgionserver职责 HMaster和HRegionServer分别是Master和RegionServer在操作系统层面上的具体实现，体现的是两个HBase进程；\nHMaster的职责：\n（1）记录Region在哪台RegionServer服务器上；\n（2）新机器加入时负责RegionServer的负载均衡；\n（3）Region满足一定大小后需要Split后，HMaster负责Region的分配；\n（4）RegionServer宕机之后，负责迁移n多个Region到其它RegionServer；\n（5）管理用户对Table表的增删改操作；\nHRegionServer的职责：\n（1）负责响应用户的IO请求，比如读写HDFS上的数据；\n（2）管理多个Region分区；\n三、附送：Hive和HBase的区别 3.1 HBase和Hive的区别 共同点：HBase和Hive都是基于Hadoop的，都是使用HDFS作为底层存储。\nHive是基于Hadoop的数据仓库分析工具，其作用是对海量的数据进行离线分析、计算，本质是将Hive SQL转化成MapReduce任务。\nHive不支持索引，所进行的操作都是全表扫描；而HBase支持索引，支持海量数据的随机读操作，一定程度上弥补了HDFS对准实时查询操作的缺陷。\nHive中的表是纯逻辑概念，它本身不存储和计算数据，而HBase中的表是物理表，而且都是以列存储数据的。其内部有一个超大内存的Hash表，用来存储数据的索引，支持随机访问；\nHBase负责组织HDFS上的文件（HDFS只负责存储）；\n","description":"HBase中的底层数据是以HFile文件形式组织的，而HFile中是安装KV存储的，如果K过大会极大的影响存储效率...","id":15,"section":"posts","tags":["HBase",""],"title":"HBase建表设计原则和优化","uri":"https://niub.link/posts/hbase-table-and-optimize/"},{"content":"一、前言 1.1 关于HBase我早就想学了 刚接触大数据的时候就听说过这些名词，Hadoop、HDFS、MapReduce、YARN、Hive、Spark、Flink\u0026hellip;.等，其中也听说过今天的主角——HBase。看到它的简要介绍时不禁发出感叹，好吊啊！能够存储几亿行*几百万列的数据量，当时截图给网友看的时候我都惊呆了。\n后面也陆续看了一些入门级别的HBase的教程，脑子里也有一些关于它的印象，什么RegionServer啊，Master啥的，心里也惦记着什么时候来学一学它。\n1.2 之前做了些什么？ 相比于其它组件，我还是算比较早接触到HBase的，从安装好了Hadoop集群之后就把HBase分布式数据库也给安装起来了，安装好了之后打开Web监控页面，写个test表建表语句，Web端看看瞧瞧也就算完成任务了。后面就去学习其他大数据组件去了，什么Hive、Spark、Flink、数据仓库、Kafka轮着来，就是没有轮到HBase，于是HBase的学习就一拖再拖\u0026hellip;\n1.3 为什么放缓学习HBase的进度？ 偶然的机会进入了一位网课老师的QQ学习内部群，是关于入行大数据的课程的学习群。我在群里有问到他课程体系中怎么没有HBase，他说HBase在这个系列课程中用的不是很多，追求精简就直接把HBase这块的内容给删减掉了。还有一个原因是传统JavaWeb方向也有用到HBase服务的，所以给我的感觉是HBase也重要但是不如其它大数据组件重要，于是就没有把重心放在HBase的学习上，不过我倒是也有在无聊的时候看看它，有时候技术交流群里面也会谈到HBase，也能顺便学到一些知识。\n1.4 今天开始学习HBase 昨天晚上躺床上我就想着今天应该把HBase给学了，因为看到很多小伙伴在群里讨论HBase的相关技术，我一句话也插不上，简直白瞎，哈哈( • ̀ω•́ )✧。在慕课网找了两门关于HBase的免费课程，一个偏入门，一个偏存储原理，而今天的这则笔记主要摘自HBase入门的视频课程。\n二、HBase入门 2.0 重要的事情才标0 今天在视频中听到老师说了这么一句话“学习任何一门技术之前需要搞清楚意义在哪里，学完之后它能帮助我们解决什么问题，和其它相类似的技术有什么区别。”，这句话很快就被我捕捉到了，我觉得这句话对我帮助很大很大。目前为止也学了蛮多技术了，从前端到后端再到大数据，每个框架每门语言都有着特定的用途，这也是它们在软件开发中的定位。比如Python虽然也能搞Web后端，但是远不如Java搞后端；比如JavaScript天生为Web页面而生，Go语言优秀的性能使得它完美的适合用于处理高并发、区块链的开发之中\u0026hellip;.\n于是我又想到了——HBase在Hadoop大数据体系的定义和定位。为什么要考虑这个，换个思路，你是否也要考虑你在这个世界的定义和定位？\n2.1 HBase的应用场景及特点  面向列：HBase是面向列的存储，支持独立检索 多版本存储：每一个列的数据存储有多个Version 稀疏性：表中为空的列并不占用存储空间，因此表可以设计的非常稀疏 良好的扩展性：数据底层依赖于HDFS 高可靠性：WAL预写日志机制保证了数据写入时不会因为集群出现异常而导致数据丢失或损坏 高性能：底层的LSM日志合并树和RowKey有序排序的独特架构特性，使得HBase具有非常高的写入性能  2.2 HBase架构体系与设计模型 HBase强烈依赖于两个外部服务：HDFS和Zookeeper。主要包含两个进程：Master、RegionServer（在Linux系统上实际实现的进程分别是：HMaster、HRegionServer；\n（本想在这里插入一张HBase体系架构图，但是考虑到Typora插入图片并发布到网上可能会耗费我很多时间，而且今天的时间已经不多了，所以打算明天再来解决插入图片的问题）。\n 利用Gitee+PicGo搞了一个免费的Hugo博客图床服务，不得不说Gitee真的很良心，免费提供5G存储空间，大赞！在Typora中设置图床服务为PicGo，在你把图片粘贴到编辑器中时Typora会通过PicGo自动把图片上传到Gitee上，图片链接全网可访问！\n 在HBase中有一个Master和多个RegionServer服务，其中RegionServer管理多个Region，Region是HBase实现高性能和负载均衡的基本单位。一个Region含有多个列族，每个列族下有多个列。\n关于HBase更多的底层存储细节今天在此不表，打算明天在写一则关于HBase存储原理的博客，进一步强化自己对HBase的理解。比如为什么HBase插入性能很高，为什么随机读的速度很快等常见问题都可以被轻松的回答\u0026hellip;\u0026hellip;(给自己挖坑)！\n2.3 HBase数据模型举例说明 关于列族：\n 一张表的列族不会超过5个 每个列族中的列数没有限制 列只有插入数据后存在 列在列族中是有序的（字典序）  关于Region：\n 每个Region管理若干条数据记录 一个RegionServer中有多个Region，且不同的Region可能会分不到不同的RegionServer上 Region中的数据和其它Region中的数据是互斥的  2.4 HBase表和传统关系型数据表结构的对比 在HBase中，列可以动态增加、数据可自动切分（一个Region达到阈值大小会自动切分成多个Region）、高并发读写，但不支持条件查询。\n而传统关系型数据库支持复杂的条件查询，对事务的支持很好，但是不具备HBase所具有的优点。\n2.5 HBase的安装部署 安装部署就不赘述了，右手就能做，正经人谁去老老实实的把安装部署的全过程贴出来啊！不过需要值得注意的是安装HBase之前需要做这么几件事：\n JDK1.8以上的安装 Hadoop的安装 Zookeeper的安装 hbase-env.sh的配置 hbase-site.xml的配置 别忘记了，web监控页面端口是16010  2.6 HBase常用命令 正经人一般不贴这玩意儿，什么诸如list、scan、drop、create、delete、enable、disable、describe、is_enabled\u0026hellip;啥的，就不一一列举出来了，在HBase shell中敲一个help就有一大坨指导你怎么用的东西了，很简单。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  hbase(main):024:0\u0026gt; help \u0026#39;create\u0026#39; Creates a table. Pass a table name, and a set of column family specifications (at least one), and, optionally, table configuration. Column specification can be a simple string (name), or a dictionary (dictionaries are described below in main help output), necessarily including NAME attribute. Examples: Create a table with namespace=ns1 and table qualifier=t1 hbase\u0026gt; create \u0026#39;ns1:t1\u0026#39;, {NAME =\u0026gt; \u0026#39;f1\u0026#39;, VERSIONS =\u0026gt; 5} Create a table with namespace=default and table qualifier=t1 hbase\u0026gt; create \u0026#39;t1\u0026#39;, {NAME =\u0026gt; \u0026#39;f1\u0026#39;}, {NAME =\u0026gt; \u0026#39;f2\u0026#39;}, {NAME =\u0026gt; \u0026#39;f3\u0026#39;} hbase\u0026gt; # The above in shorthand would be the following: hbase\u0026gt; create \u0026#39;t1\u0026#39;, \u0026#39;f1\u0026#39;, \u0026#39;f2\u0026#39;, \u0026#39;f3\u0026#39; hbase\u0026gt; create \u0026#39;t1\u0026#39;, {NAME =\u0026gt; \u0026#39;f1\u0026#39;, VERSIONS =\u0026gt; 1, TTL =\u0026gt; 2592000, BLOCKCACHE =\u0026gt; true} hbase\u0026gt; create \u0026#39;t1\u0026#39;, {NAME =\u0026gt; \u0026#39;f1\u0026#39;, CONFIGURATION =\u0026gt; {\u0026#39;hbase.hstore.blockingStoreFiles\u0026#39; =\u0026gt; \u0026#39;10\u0026#39;}} hbase\u0026gt; create \u0026#39;t1\u0026#39;, {NAME =\u0026gt; \u0026#39;f1\u0026#39;, IS_MOB =\u0026gt; true, MOB_THRESHOLD =\u0026gt; 1000000, MOB_COMPACT_PARTITION_POLICY =\u0026gt; \u0026#39;weekly\u0026#39;} Table configuration options can be put at the end. Examples: hbase\u0026gt; create \u0026#39;ns1:t1\u0026#39;, \u0026#39;f1\u0026#39;, SPLITS =\u0026gt; [\u0026#39;10\u0026#39;, \u0026#39;20\u0026#39;, \u0026#39;30\u0026#39;, \u0026#39;40\u0026#39;] hbase\u0026gt; create \u0026#39;t1\u0026#39;, \u0026#39;f1\u0026#39;, SPLITS =\u0026gt; [\u0026#39;10\u0026#39;, \u0026#39;20\u0026#39;, \u0026#39;30\u0026#39;, \u0026#39;40\u0026#39;] hbase\u0026gt; create \u0026#39;t1\u0026#39;, \u0026#39;f1\u0026#39;, SPLITS_FILE =\u0026gt; \u0026#39;splits.txt\u0026#39;, OWNER =\u0026gt; \u0026#39;johndoe\u0026#39; hbase\u0026gt; create \u0026#39;t1\u0026#39;, {NAME =\u0026gt; \u0026#39;f1\u0026#39;, VERSIONS =\u0026gt; 5}, METADATA =\u0026gt; { \u0026#39;mykey\u0026#39; =\u0026gt; \u0026#39;myvalue\u0026#39; } hbase\u0026gt; # Optionally pre-split the table into NUMREGIONS, using hbase\u0026gt; # SPLITALGO (\u0026#34;HexStringSplit\u0026#34;, \u0026#34;UniformSplit\u0026#34; or classname) hbase\u0026gt; create \u0026#39;t1\u0026#39;, \u0026#39;f1\u0026#39;, {NUMREGIONS =\u0026gt; 15, SPLITALGO =\u0026gt; \u0026#39;HexStringSplit\u0026#39;} hbase\u0026gt; create \u0026#39;t1\u0026#39;, \u0026#39;f1\u0026#39;, {NUMREGIONS =\u0026gt; 15, SPLITALGO =\u0026gt; \u0026#39;HexStringSplit\u0026#39;, REGION_REPLICATION =\u0026gt; 2, CONFIGURATION =\u0026gt; {\u0026#39;hbase.hregion.scan.loadColumnFamiliesOnDemand\u0026#39; =\u0026gt; \u0026#39;true\u0026#39;}} hbase\u0026gt; create \u0026#39;t1\u0026#39;, \u0026#39;f1\u0026#39;, {SPLIT_ENABLED =\u0026gt; false, MERGE_ENABLED =\u0026gt; false} hbase\u0026gt; create \u0026#39;t1\u0026#39;, {NAME =\u0026gt; \u0026#39;f1\u0026#39;, DFS_REPLICATION =\u0026gt; 1} You can also keep around a reference to the created table: hbase\u0026gt; t1 = create \u0026#39;t1\u0026#39;, \u0026#39;f1\u0026#39; Which gives you a reference to the table named \u0026#39;t1\u0026#39;, on which you can then call methods.   没错，我就是凑字数的，不服来打我啊ヾ(•ω•`。)\n三、小结一下 3.1 关于实操性的东西 比如常见命令的时候真的没有必要去死记硬背，要智慧的借助工具来完成自己的目的。比如前面提到的shell界面敲一个help就能够解决我们很多关于操作性的命令。我们应该把有限的精力和时间投入到无限的学习之中，学习什么呢？学习如何学习，也就是学习智慧。\n3.2 思考 \u0026gt; 动手 以前我学习的时候喜欢边学边做笔记，所以打字速度算是比较快的，但是学完某个东西之后却发现除了留下死水一般的笔记之外什么也没有得到。什么原因？我觉得这是思维上的懒惰所导致的，大脑不去思考只喜欢做机械性的事情，比如抄笔记。其实学习更重要的是体会与理解，体会老师说的理解书上写的视频中放的\u0026hellip;，正所谓笔记易得，知识难学。\n3.3 自顶向下，由外而内的学习方法 学过计算机网络的boys肯定知道有一本很有名的书，叫《计算机网络——自顶向下方法》。很多年过去了，现在突然觉得自顶向下的学习方法真的很受用，它能使你以一种俯视的角度去看待某个东西。越顶层越接近用户，越底层越接近计算机，如果一开始就是学习距离用户很遥远的东西会产生很强烈的挫败感。因为你没法和知识产生共鸣，觉得这个东西学了对我好像也没什么用处，死记硬背记住它那更是生不如死，着实痛苦。\n比如关于HBase采用自顶向下，由外而内的学习方法，你可以学到：从LSM日志合并树这一条主线，分层次的去学习HBase的存储原理，你会豁然开朗。（比如Level 0,就引申出了Store、MemStore、WAL、StoreFile等重要的概念。）因为学习的自始至终过程你都是抓住了主线的，一层一层的剥开它的心，彻底走进它的心房。这个过程是很自然的，很舒畅的甚至是很开心的，并不会产生一种强烈的不愉快感。\n在此引用视频中老师的几句话，我觉得对我的启发很大对我十分有帮助：\n  首先从高层次的思想上来看HBase 的存储思想。(LSM存储思想） 看似很复杂的工作流程经过拆分讲解其实也不是特别的难懂；   3.4 该止笔了 今天只剩下20分钟不到的时间了，等会还要把写好的文章编译上传到Github，那今天的任务就算完成了。这篇博客居然差不多有3000千字，写了一个多小时，侧重点还是关于学习的感悟上，具体知识点的记录还是比较少。考虑到时间的问题，打算明天在写一篇更加深入的HBase文章——关于其存储原理的具体剖析。当然了，这些也是我看视频学习整理之后的笔记，并加上自己的学习感悟和理解，对自己学习如何学习肯定有很大的帮助的~\n","description":"学习任何一门技术之前需要搞清楚意义在哪里，学完之后它能帮助我们解决什么问题，和其它相类似的技术有什么区别。","id":16,"section":"posts","tags":["HBase",""],"title":"浅谈HBase入门以及一些学习感悟","uri":"https://niub.link/posts/talk-about-hbase01/"},{"content":"一、回顾Hive的架构 1.1 Hive的基本结构 在Hadoop 2.x版本以后，Hive所有运行的任务都是交由YARN来统一管理。下图所示为Hive作业的工作流程：\n客户端提交SQL作业到HiveServer2, HiveServer2会根据用户提交的SQL作业及数据库中现有的元数据信息（实际生产中存放在MySQL中）生成一份可供计算引擎执行的计划。每个执行计划对应若干MapReduce作业，Hive会将所有的MapReduce作业都一一提交到YARN中，由YARN去负责创建MapReduce作业对应的子任务任务，并协调它们的运行。YARN创建的子任务会与HDFS进行交互，获取计算所需的数据，计算完成后将最终的结果写入HDFS或者本地。\n从整个Hive运行作业的过程我们可以知道Hive自身主要包含3个部分：\n 第一部分是客户端（Client） 第二部分是HiveServer2 第三部分是元数据以及元数据服务。  1.2 关于Hive的元数据 Hive的元数据保存在Hive的metastore数据中，里面记录着Hive数据库、表、分区和列的一些当前状态信息，通过收集这些状态信息，可以帮助我们更好地监控Hive 数据库当前的状态，提前感知可能存在的问题；可以帮助基于成本代价的SQL 查询优化，做更为正确的自动优化操作。\nHive的元数据主要分为5个大部分：\n 数据库相关的元数据 表相关的元数据 分区相关的元数据 文件存储相关的元数据 其他（事务信息、锁信息以及权限相关信息）  1.3 Hive的知识体系 下面一张图摘自《Hive性能调优实战》，全面的展示了Hive的知识体系，其实这篇文章算是我阅读这本书的读书笔记吧，很多知识点讲的比较详细我就直接摘抄下来了。\n二、YARN详解 2.1 传统多线程编程和调度框架的对比 在单机程序设计中， 为了快速处理一个大的数据集， 通常采用多线程并行编程。大体流程如下 ：\n先由操作系统启动一个主线程， 由它负责数据切分、 任务分配、 子线程启动和销毁等工作， 而各个子线程只负责计算自己的数据， 当所有子线程处理完数据后， 主线程再退出。\n而，在生产环境中的大数据集群，所有作业或系统运行所需的资源，都不是直接向操作系统申请，而是交由资源管理器和调度框架代为申请。每个作业或系统所需的资源都是由资源管理和调度框架统一分配、协调。在业界中扮演这一角色的组件有YARN、Mesos等。\n2.2 YARN的优点 YARN作为资源调用框架有着如下优点：\n 提高系统的资源利用率。不同系统和不同业务在不同的时间点对硬件资源的需求是不一样的，例如一些离线业务通常在凌晨时间启动，除了这个阶段的离线业务对资源的占用比较高，其他时间段基本是空闲的，通过统一资源调度和协调，将这些时间段的资源分配给其他系统。不仅计算资源可以共享，由于允许多套系统部署在一个集群，也能增加系统存储资源的利用率。 协调不同作业/不同系统的资源，减少不同作业和不同系统之间的资源争抢。例如通过资源管理和调度框架并通过一定的资源分配策略，能够保证在多作业情况下，各个作业都能够得到足够的资源得以运行，而不会出现一个作业占用所有资源，导致其他作业全部阻塞的情况。 增强系统扩展性。资源管理和调度框架，允许硬件资源的动态伸缩，而不会影响作业的运行。 资源调度与管理工具把控着资源的分配和任务的调度，直接影响程序的运行效率。如果任务得到资源少了，必将影响自身的程序运行效率，如果任务占用过多资源，在集群任务运行高峰期，必然导致挤占其他任务运行所需的资源。  那么如何利用资源与调度管理工具？作为大数据集群的使用者，基于Hive 做业务的开发者要高效地利用资源与调度管理工具，需要知道两方面的内容：\n YARN运行的基本组成和工作原理，能够基本理清程序运行的整体流程，知道哪些过程或者配置可能成为瓶颈，可以先不用了解，但一定要有意识。 YARN资源调度与分配算法。   这里有个感触就是，对学习任何一个大数据组件是不是也应该采用这种方式呢？第一要熟悉该组件的基本组成和工作原理，对其大体的工作流程要熟悉。当然了看一遍是不可能全部记住以及全部消化和理解的。不如多看几遍，很多陌生的名词头一次看或许印象不深，但是如果多看几遍甚至发到技术群讨论一下，印象和理解或许更加深刻，也有助于对该技术组件的学习。\n由此引申HDFS、MapReduce、Kafka、HBase、Spark、Flink\u0026hellip;都按照这种套路来学，会不会有触类旁通的效果呢？\n 2.3 YARN的基本组成 YARN的基本结构由一个ResourceManager与多个NodeManager组成。ResourceManager负责对NodeManager所持有的资源进行统一管理和调度。当在处理一个作业时ResourceManager会在NodeManager所在节点创建一全权负责单个作业运行和监控的程序ApplicationMaster。\n  ResouceManager（简称RM）\n 资源管理器负责整个集群资源的调度，该组件由两部分构成：调度器（Scheduler）和ApplicationsMaster（简称ASM）。调度器会根据特定调度器实现调度算法，结合作业所在的队列资源容量，将资源按调度算法分配给每个任务。分配的资源将用容器（container）形式提供，容器是一个相对封闭独立的环境，已经将CPU、内存及任务运行所需环境条件封装在一起。通过容器可以很好地限定每个任务使用的资源量。YARN调度器目前在生产环境中被用得较多的有两种：能力调度器（CapacityScheduler）和公平调度器（Fair Scheduler）。（还有一种FIFO Scheduler）\n   ApplicationMaster（简称AM）\n 每个提交到集群的作业（job）都会有一个与之对应的AM 来管理。它负责进行数据切分，并为当前应用程序向RM 去申请资源，当申请到资源时会和NodeManager 通信，启动容器并运行相应的任务。此外，AM还负责监控任务（task）的状态和执行的进度。\n   NodeManage（简称NM）\n NodeManager负责管理集群中单个节点的资源和任务，每个节点对应一个NodeManager, NodeManager负责接收ApplicationMaster的请求启动容器，监控容器的运行状态，并监控当前节点状态及当前节点的资源使用情况和容器的运行情况，并定时回报给ResourceManager。\n   2.4 YARN工作流程 YARN在工作时主要会经历3个步骤：\n（1）ResourceManager收集NodeManager反馈的资源信息，将这些资源分割成若干组，在YARN中以队列表示。（2）当YARN接收用户提交的作业后，会尝试为作业创建一个代理ApplicationMaster。\n（3）由ApplicationMaster将作业拆解成一个个任务（task），为每个任务申请运行所需的资源，并监控它们的运行。\nYARN在处理任务时的工作流程如下图所示。经历了以下几个步骤：\n（1）客户端向YARN提交一个作业（Application）。\n（2）作业提交后，RM根据从NM收集的资源信息，在有足够资源的节点分配一个容器，并与对应的NM进行通信，要求它在该容器中启动AM。\n（3）AM创建成功后向RM中的ASM注册自己，表示自己可以去管理一个作业（job）。\n（4）AM注册成功后，会对作业需要处理的数据进行切分，然后向RM申请资源，RM会根据给定的调度策略提供给请求的资源AM。\n（5）AM申请到资源成功后，会与集群中的NM通信，要求它启动任务。\n（6）NM接收到AM的要求后，根据作业提供的信息，启动对应的任务。\n（7）启动后的每个任务会定时向AM提供自己的状态信息和执行的进度。\n（8）作业运行完成后AM会向ASM注销和关闭自己。\n三、再谈MapReduce 3.1 移动数据不如移动计算的大数据计算思想 一个完整的MapReduce任务提交到Hadoop集群，Mapper中的逻辑会被分发到集群中的各个节点，并读取该节点的本地数据进行处理，最后写入到本地。这种模式就是所谓的不移动数据，而只移动计算逻辑的模式。目前绝大部分的分布式计算引擎，相比于移动计算，移动数据需要消耗更多的网络I/O和磁盘I/O的资源。在进行调优时，我们借鉴这种设计方法，尽可能地减少数据在节点之间的传输。\n3.2 Map和Reduce的工作流程 Map 在读取数据时，先将数据拆分成若干数据，并读取到Map 方法中被处理。数据在输出的时候，被分成若干分区并写入内存缓存（buffer）中，内存缓存被数据填充到一定程度会溢出到磁盘并排序（缓冲区大小默认100M，数据超过80M时进行溢写操作），当Map 执行完后会将一个机器上输出的临时文件进行归并存入到HDFS中。\n当Reduce 启动时，会启动一个线程去读取Map 输出的数据，并写入到启动Reduce机器的内存中，在数据溢出到磁盘时会对数据进行再次排序（由此可见Reduce阶段是会有排序的）。当读取数据完成后会将临时文件进行合并，作为Reduce函数的数据源。整个过程如下图所示。\n3.3 MapReduce整体环节的浅析 下面这张图体现的是MapReduce整体工作流程：\n一个完整的MapReduce任务提交到Hadoop集群，Reducer中的逻辑会被分发到集群中的各个节点。但是不同于Mapper读取本地文件，Reducer会去拉取远程Map节点产生的数据，这里必然也会涉及网络I/O 和磁盘I/O。从这里我们可以看到，如非需要对数据进行全局处理，例如全局排序，就关掉Reduce阶段的操作，可以提升程序性能。\n在写入到HDFS的过程中，为了下游Reducer任务顺序快速拉取数据，会将数据进行排序后再写入临时文件中，当整个Map 执行结束后会将临时文件归并成一个文件。如果不进行文件的排序归并，意味着下游Reducer任务拉取数据会频繁地搜索磁盘，即将顺序读变为随机读，这会对磁盘I/O产生极大的负载。\nReducer任务启动后，会启动拉取数据的线程，从HDFS拉取所需要的数据。为什么不选用Mapper任务结束后直接推送到Reducer节点，这样可以节省写入到磁盘的操作，效率更高？因为采用缓存到HDFS，让Reducer主动来拉，当一个Reducer任务因为一些其他原因导致异常结束时，再启动一个新的Reducer依然能够读取到正确的数据。\n从HDFS拉取的数据，会先缓存到内存缓冲区，当数据达到一定的阈值后会将内存中的数据写入内存或者磁盘中的文件里。当从HDFS 拉取的数据能被预先分配的内存所容纳，数据会将内存缓存溢出的数据写入该内存中，当拉取的数据足够大时则会将数据写入文件，文件数量达到一定量级进行归并。\n3.4 关于Combiner Combiner用于处理数据的聚合，但是其只发生在本地的Mapper任务阶段，因此也被称为Map端的Reducer任务。使用Combiner的初衷是为了减少Shuffle过程的数据量，减轻系统的磁盘和网络压力。（Shuffle是一项昂贵的操作）\nHive中提供了另外一种聚合方式——使用散列表，每个Mapper中直接使用散列表进行聚合，而不是另起Combiner聚合任务，这样避免另外起一个任务和额外的数据读写所带来的开销。散列表，可以类比Java中的HashMap。\n 通常使用Map聚合往往是为了减少Map任务的输出，减少传输到下游任务的Shuffle数据量，但如果数据经过聚合后不能明显减少，那无疑就是浪费机器的I/O资源。\n 四、HDFS的基本组成 偷个懒，不想写了\u0026hellip;ಠ╭╮ಠ\n(；´д｀)ゞ\n༼༎ຶᴗ༎ຶ༽\n(′へ`、)\n五、附送：今天下午骑单车去了 双脚一蹬就是13.7公里，骄傲！ㄟ( ▔, ▔ )ㄏ\n","description":"这篇文章很多内容都是直接摘自上午看的《Hive性能调优实战》一书，主要内容是梳理了一下关于Hive、YARN以及MapReduce等知识点。","id":17,"section":"posts","tags":["Hive","Hadoop"],"title":"关于Hive和YARN的读书笔记","uri":"https://niub.link/posts/helloyarn/"},{"content":"一、求每一年最高气温的那一天以及温度 1.1 数据准备 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  2014010114 2014010216 2014010317 2014010410 2014010506 2012010609 2012010732 2012010812 2012010919 2012011023 2001010116 2001010212 2001010310 2001010411 2001010529 2013010619 2013010722 2013010812 2013010929 2013011023 2008010105 2008010216 2008010337 2008010414 2008010516 2007010619 2007010712 2007010812 2007010999 2007011023 2010010114 2010010216 2010010317 2010010410 2010010506 2015010649 2015010722 2015010812 2015010999 2015011023   数据的含义是：2010012325表示在2010年01月23日的气温为25度。\n建表、导入数据：\n1 2 3  create table tempertrue(data string); load data local inpath \u0026#34;/data/soft/hive-3.2.1/mydata/tempertrue.txt\u0026#34; into table tempertrue;   ※ 1.2 求每一年最高气温的那一天以及温度 首先，先创建一个临时视图，把data分割日期和温度两个字段。\n1 2 3 4 5 6  create view temp as select substr(data, 1, 8) as ttime, substr(data, 9) as tep from tempertrue;   利用开窗函数、substr函数对data分割后分组并排序：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  select ttime, tep from ( select ttime, tep, rank() over( partition by substr(ttime, 1, 4) order by tep desc ) as num from temp ) as t1 where t1.num = 1;   结果：\n1 2 3 4 5 6 7 8 9 10 11 12  +-----------+------+ | ttime | tep | +-----------+------+ | 20010105 | 29 | | 20070109 | 99 | | 20080103 | 37 | | 20100103 | 17 | | 20120107 | 32 | | 20130109 | 29 | | 20140103 | 17 | | 20150109 | 99 | +-----------+------+    关于这题，我的启发是，substr函数可以将表中某个字段列的值分割，然后再利用开窗函数对分割后的子字符串进行分组、排序。分组用的是partition by，排序用的是order by。\n还有，关于临时视图，好像很有用的样子。其实就是一个中间表，引入中间表我想是为了简化SQL语句的编写。\n 二、SQL中常见的几个字符分割函数：   SUBSTR(str, pos, len): 从pos开始的位置，截取len个字符\n  SUBSTR(str, pos): pos开始的位置，一直截取到最后\n  substr(string ,1,3) ：取string左边第1位置起，3字长的字符串。所以结果为： strsubstr(string, -1,3)：取string右边第1位置起，3字长的字符串。显然右边第一位置起往右不够3字长。结果只能是： gsubstr(string, -3,3)：取string右边第3位置起，3字长的字符串。结果为: ing\nHive中在group by查询的时候要求出现在select后面的列都必须是出现在group by后面的，即select列必须是作为分组依据的列\nHive中collect相关的函数有collect_list和collect_set。它们都是将分组中的某列转为一个数组返回，不同的是collect_list不去重而collect_set去重。\n","description":"求每一年最高气温的那一天以及温度","id":18,"section":"posts","tags":["Hive",""],"title":"再来一道SQL题","uri":"https://niub.link/posts/keep-water-for-hive/"},{"content":"一、Hive中的开窗函数 1.1 关于开窗函数 什么是开窗函数？\n回答这个问题之前先要了解一下什么是聚合函数。聚合函数是SQL的基本函数，其功能是对一组值执行计算，并返回单个值。再说一遍，聚合函数是SQL的基本函数，其功能是对一组值执行计算，并返回单个值。\n常见的聚合函数有：sum()，count()，max()，min()， avg()等，这些聚合函数通常与group by 子句连用，除了count以外，聚合函数忽略空值；\n上面有说到，聚合函数只返回单个值，而开窗函数则可为窗口中的每行都返回一个值。更简单的理解就是，对查询的结果多出一列或者多列，列中可以是聚合值也可以试排序值。\n一般地，开窗函数也叫分析函数，有两类：聚合开窗函数、排序开窗函数。\n另外：\n SQL标准运行将所有的聚合函数用作开窗函数，用OVER关键字区分开窗函数和聚合函数。 聚合函数每组只返回一个值，开窗函数每组（每个窗口）可返回多个值。（上面也有说到过为每行都返回一个值）  1.2 举个不太熟栗子 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  [root@hadoop200m mydata]# more student_score.data 1 zs1 chinese 80 2 zs1 math 90 3 zs1 english 89 4 zs2 chinese 60 5 zs2 math 75 6 zs2 english 80 7 zs3 chinese 79 8 zs3 math 83 9 zs3 english 72 10 zs4 chinese 90 11 zs4 math 76 12 zs4 english 80 13 zs5 chinese 98 14 zs5 math 80 15 zs5 english 70   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  select * from student_score; +-------------------+---------------------+--------------------+----------------------+ | student_score.id | student_score.name | student_score.sub | student_score.score | +-------------------+---------------------+--------------------+----------------------+ | 1 | zs1 | chinese | 80 | | 2 | zs1 | math | 90 | | 3 | zs1 | english | 89 | | 4 | zs2 | chinese | 60 | | 5 | zs2 | math | 75 | | 6 | zs2 | english | 80 | | 7 | zs3 | chinese | 79 | | 8 | zs3 | math | 83 | | 9 | zs3 | english | 72 | | 10 | zs4 | chinese | 90 | | 11 | zs4 | math | 76 | | 12 | zs4 | english | 80 | | 13 | zs5 | chinese | 98 | | 14 | zs5 | math | 80 | | 15 | zs5 | english | 70 | +-------------------+---------------------+--------------------+----------------------+   ※ 需求是：计算出班级中单科排名前三的学生姓名以及成绩信息。\n这题的思路大概是使用开窗函数并按照sub划分窗口，且按照score排序。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  select * from ( select *, row_number() over( partition by sub order by score desc ) as rank from student_score ) as ss where ss.rank \u0026lt;= 3;    row_number()，对数据进行编号，从1开始 over()函数将数据划分到一个窗口内 partition by表示按照字段对数据进行分组 order by对分组内的数据按照某个字段进行排序  得到的结果如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  +--------+----------+----------+-----------+----------+ | ss.id | ss.name | ss.sub | ss.score | ss.rank | +--------+----------+----------+-----------+----------+ | 13 | zs5 | chinese | 98 | 1 | | 10 | zs4 | chinese | 90 | 2 | | 1 | zs1 | chinese | 80 | 3 | | 3 | zs1 | english | 89 | 1 | | 6 | zs2 | english | 80 | 2 | | 12 | zs4 | english | 80 | 3 | | 2 | zs1 | math | 90 | 1 | | 8 | zs3 | math | 83 | 2 | | 14 | zs5 | math | 80 | 3 | +--------+----------+----------+-----------+----------+   其中关于排序（排名先后顺序问题）\n row_number() over() 正常顺序 rank() over() 跳跃排序，有两个第一名时接下来就是第三名（在各个分组内） dense_rank() over() 连续排序，有两个第一名时接下来是二名（在各个分组内）  比如dense_rank() over() 连续排序（个人认为这种还是比较符合实际的情况，并列第一也是第一！）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  +--------+----------+----------+-----------+----------+ | ss.id | ss.name | ss.sub | ss.score | ss.rank | +--------+----------+----------+-----------+----------+ | 13 | zs5 | chinese | 98 | 1 | | 10 | zs4 | chinese | 90 | 2 | | 1 | zs1 | chinese | 80 | 3 | | 3 | zs1 | english | 89 | 1 | | 12 | zs4 | english | 80 | 2 | | 6 | zs2 | english | 80 | 2 | | 9 | zs3 | english | 72 | 3 | | 2 | zs1 | math | 90 | 1 | | 8 | zs3 | math | 83 | 2 | | 14 | zs5 | math | 80 | 3 | +--------+----------+----------+-----------+----------+   总结一下：从写的Hive SQL来看，开窗函数的调用格式为：\n 函数名(列名) over(partition by 列名 order by 列名)。\n 二、几道关于Hive SQL的题 2.1 单月访问次数和总访问次数 数据是这样的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  +-----------------+------------------+------------------+ | t_access.uname | t_access.umonth | t_access.ucount | +-----------------+------------------+------------------+ | A | 2015-01 | 5 | | A | 2015-01 | 15 | | B | 2015-01 | 5 | | A | 2015-01 | 8 | | B | 2015-01 | 25 | | A | 2015-01 | 5 | | A | 2015-02 | 4 | | A | 2015-02 | 6 | | B | 2015-02 | 10 | | B | 2015-02 | 5 | | A | 2015-03 | 16 | | A | 2015-03 | 22 | | B | 2015-03 | 23 | | B | 2015-03 | 10 | | B | 2015-03 | 1 | +-----------------+------------------+------------------+   ※ 需求是：求出每个用户截止到每月为止的最大单月访问次数、累计到该月的总访问次数和当月访问次数。大概长这样：\n1 2 3 4 5 6 7 8 9 10 11  +-----------+------------+------------+--------------+------------+ | t1.uname | t1.umonth | t1.ucount | current_max | total_cnt | +-----------+------------+------------+--------------+------------+ | A | 2015-01 | 33 | 33 | 33 | | A | 2015-02 | 10 | 33 | 43 | | A | 2015-03 | 38 | 38 | 81 | | B | 2015-01 | 30 | 30 | 30 | | B | 2015-02 | 15 | 30 | 45 | | B | 2015-03 | 34 | 34 | 79 | +-----------+------------+------------+--------------+------------+   这题的关键是求出当月的访问次数，然后再使用开窗函数累加截止到本月的总访问次数以及最大访问次数。\n求出当月访问次数，很简单，使用如下命令：\n1 2 3 4 5 6 7 8 9  select uname, umonth, sum(ucount) as ucount from t_access group by uname, umonth;   得到的结果是：\n1 2 3 4 5 6 7 8 9 10 11  +--------+----------+---------+ | uname | umonth | ucount | +--------+----------+---------+ | A | 2015-01 | 33 | | A | 2015-02 | 10 | | A | 2015-03 | 38 | | B | 2015-01 | 30 | | B | 2015-02 | 15 | | B | 2015-03 | 34 | +--------+----------+---------+    紧接着，使用开窗函数累加截止到本月的总访问次数以及最大访问次数。贴上参考SQL：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  select *, max(ucount) over( partition by uname order by umonth ) as current_max, sum(ucount) over( partition by uname order by umonth ) as total_cnt from ( select uname, umonth, sum(ucount) as ucount from t_access group by uname, umonth ) as t1;   2.2 学生课程成绩 数据是这样的：\n1 2 3 4 5 6 7 8 9 10 11  +------------+-------------+----------------+---------------+ | course.id | course.sid | course.course | course.score | +------------+-------------+----------------+---------------+ | 1 | 1 | yuwen | 43 | | 2 | 1 | shuxue | 55 | | 3 | 2 | yuwen | 77 | | 4 | 2 | shuxue | 88 | | 5 | 3 | yuwen | 98 | | 6 | 3 | shuxue | 65 | +------------+-------------+----------------+---------------+   ※ 需求：求所有数学课程成绩大于语文课程成绩的学生的信息，格式如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  +--------+ | a.sid | +--------+ | 1 | | 2 | +--------+ # 为了方便展示，把成绩也贴出来 +--------+-----------+----------+-----------+----------+ | a.sid | a.course | a.score | b.course | b.score | +--------+-----------+----------+-----------+----------+ | 1 | shuxue | 55 | yuwen | 43 | | 2 | shuxue | 88 | yuwen | 77 | +--------+-----------+----------+-----------+----------+   解决的思路：course表先自连接，根据过滤条件筛选出符合要求的记录。参考SQL如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13  select a.sid, a.course, a.score, b.course, b.score from course a join course b on a.sid = b.sid and a.course = \u0026#39;shuxue\u0026#39; and b.course = \u0026#39;yuwen\u0026#39; where a.score \u0026gt; b.score;   另一种解法，使用开窗函数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  select * from ( select sid, sum( case course when \u0026#34;shuxue\u0026#34; then score else 0 end ) as math, sum( case course when \u0026#34;yuwen\u0026#34; then score else 0 end ) as chinese from course group by sid ) as t1 where t1.math \u0026gt; t1.chinese;   三、附送：科普VirtualBox虚拟机网络 3.1 声明几个名词 一般来说诸如VirtualBox、VMwareWorkstation Pro等虚拟机才叫虚拟机。真正的Linux系统是装在虚拟机中的，但是此文为了方便，把虚拟机中的Linux系统称之为“虚拟机”安装虚拟机（VirtualBox、VMwareWorkstation Pro\u0026hellip;）的机器叫主机。特此声明！\n3.2 VirtualBox中常见的网络接入模式  NAT模式 Host-Only 桥接 Internal  3.3 各种网络接入模式详解 【01 NAT模式的特点】：\n 如果主机可以上网，虚拟机可以上网 虚拟机之间不能ping通 虚拟机可以ping通主机（此时ping虚拟机的网关，即是ping主机） 主机不能ping通虚拟机  NAT模式的应用场景：\n 虚拟机只要求可以上网，无其它特殊要求。  NAT模式下的IP样式：\n IP：10.0.2.15 网关：10.0.2.2  【02 Bridged Adapter桥接模式的特点】：\n 如果主机可以上网，虚拟机可以上网 虚拟机之间可以ping通 虚拟机可以ping通主机 主机可以ping通虚拟机  以上四点都基于一个前提：主机可以上网。由此可以引申出一个很重要的结论：\n 如果在同一个局域网下，多台主机里面的虚拟机是可以互相访问的（特点2），因此在一定条件下可以充分利用多台主机的资源，比如硬盘和内存。想到一个不错的利用方式是用来搭建Hadoop集群~\n桥接很形象的解释是，通过主机网卡，架设一条桥，直接连入到网络中。它使得虚拟机能被分配到一个网络中独立的IP，所有网络功能完全和在网络中的真实机器一样。\n 桥接模式的IP样式：\n IP与本机IP在同一网段内（很重要） 网关与本机网关相同  【03 Host-only Adapter模式的特点】：\n 虚拟机不可以上网 虚拟机之间可以ping通 虚拟机可以ping通主机（注意虚拟机与主机通信是通过主机的名为VirtualBox Host-Only Network的网卡，因此ip是该网卡ip 192.168.56.1，而不是你现在正在上网所用的ip） 主机可以ping通虚拟机  桥接模式的应用场景：\n 在主机无法上网的情况下，也可以搭建一个模拟局域网，因为所有的虚拟机之间都是可以互相访问的。  桥接模式的IP样式：\n IP 与本机VirtualBox Host-Only Network的网卡IP在同一网段内（默认192.168.56.*） 网关 本机VirtualBox Host-Only Network的网卡IP（默认192.168.56.1）  稍微引申一下：\n 在本地搭建大数据集群的时候，一般选择NAT模式+Host-Only模式的组合方式进行网络配置。NAT模式允许虚拟机能够访问外网，做一些软件下载、更新等操作；Host-Only模式下的虚拟机与虚拟机之间可以相互访问，因此可以模拟搭建一个模拟局域网。\n 【04 Internal模式的特点】：\n 虚拟机不可以上网 虚拟机之间可以ping通 虚拟机不能ping通主机 主机不能ping通虚拟机  Internal模式的应用场景：\n 与世隔绝。让各台虚拟机处于隔离的局域网内，只让它们相互通信，与外界（包括主机）隔绝；  Internal模式的IP样式:\n ip 169.254.147.9  不得不说，正经人谁选择内网模式啊！\n附送，在CentOS7环境下，几个网卡的配置文件在：/etc/sysconfig/network-scripts文件夹下。\n1 2 3 4 5 6 7 8 9 10 11  [root@hadoop200m network-scripts]# ll total 236 -rw-r--r--. 1 root root 240 Aug 16 13:48 ifcfg-enp0s3 -rw-r--r--. 1 root root 286 Aug 16 14:49 ifcfg-enp0s8 -rw-r--r--. 1 root root 254 Mar 29 2019 ifcfg-lo lrwxrwxrwx. 1 root root 24 Jan 16 2018 ifdown -\u0026gt; ../../../usr/sbin/ifdown -rwxr-xr-x. 1 root root 654 Mar 29 2019 ifdown-bnep -rwxr-xr-x. 1 root root 6532 Mar 29 2019 ifdown-eth -rwxr-xr-x. 1 root root 781 Mar 29 2019 ifdown-ippp -rwxr-xr-x. 1 root root 4540 Mar 29 2019 ifdown-ipv6 ......   其中ifcfg-enp0s3是NAT模式下的网络配置文件，ifcfg-enp0s8是Host-Only模式下的网络配置文件；\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  [root@hadoop200m network-scripts]# more ifcfg-enp0s3 TYPE=Ethernet PROXY_METHOD=none BROWSER_ONLY=no BOOTPROTO=dhcp DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=yes IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_FAILURE_FATAL=no IPV6_ADDR_GEN_MODE=stable-privacy NAME=enp0s3 DEVICE=enp0s3 ONBOOT=yes [root@hadoop200m network-scripts]# more ifcfg-enp0s8 TYPE=Ethernet PROXY_METHOD=none BROWSER_ONLY=no BOOTPROTO=static DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=yes IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_FAILURE_FATAL=no IPV6_ADDR_GEN_MODE=stable-privacy NAME=enp0s8 DEVICE=enp0s8 ONBOOT=yes IPADDR=192.168.56.200 NETMASK=255.255.255.0   ","description":"聚合函数是SQL的基本函数，其功能是对一组值执行计算，并返回单个值。","id":19,"section":"posts","tags":["Hive",""],"title":"请为Hive开扇窗","uri":"https://niub.link/posts/hive-window-func/"},{"content":"浅谈SQL语句的执行顺序 一、SQL语句执行顺序解析 SQL语句和编程语言的语句有很大的不同，有一点原因在于SQL并不一定是按照你写的SQL语句顺序执行的。因此在写SQL语句的时候很容易出现问题，最主要的问题还是记不住SQL命令，死记硬背效果好像也不是很好。\n需要知道的是，在SQL语句执行的过程中，都会产生一个虚拟表，用来保存SQL语句的执行结果。这些虚拟表对用户来说是透明的，只有最后一步生成的虚拟表才会返回给用户。如果没有再查询中指定某一子句，则将跳过相应的步骤。下面先给出SQL语句的执行顺序，并加以简单的解释。\n1 2 3 4 5 6 7 8 9 10  7) select 8) distinct \u0026lt;select_list\u0026gt; 1) from \u0026lt;left_table\u0026gt; 3) \u0026lt;join_type\u0026gt; join \u0026lt;right_table\u0026gt; 2) on \u0026lt;join_condition\u0026gt; 4) where \u0026lt;where_condition\u0026gt; 5) group by \u0026lt;group_by_list\u0026gt; 6) having \u0026lt;having_condition\u0026gt; 9) order by \u0026lt;order_by_list\u0026gt; 10) limit \u0026lt;limit_number\u0026gt;   1）from：对FROM子句中的左表\u0026lt;left_table\u0026gt;和右表\u0026lt;right_table\u0026gt;执行笛卡儿积（Cartesian product），产生虚拟表VT1。\n2）on： 对虚拟表VT1应用ON筛选，只有那些符合\u0026lt;join_condition\u0026gt;的行才被插入虚拟表VT2中。\n3）join：如果指定了OUTER JOIN（如LEFT OUTER JOIN、RIGHT OUTERJOIN），那么保留表中未匹配的行作为外部行添加到虚拟表VT2中，产生虚拟表VT3。如果FROM子句包含两个以上表，则对上一个连接生成的结果表VT3和下一个表重复执行步骤1）～步骤3），直到处理完所有的表为止。\n 这里出现了两个陌生的名词：“保留表”、“外部行”。\nLEFT OUTER JOIN把左表记为保留表，RIGHT OUTER JOIN把右表记为保留表\u0026hellip;\n一时半会也解释不清这个东西，我自己懂了就好了，先挖个坑，日后再补上具体数据来做详细解释说明。\n 4）where：对虚拟表VT3应用WHERE过滤条件，只有符合\u0026lt;where_condition\u0026gt;的记录才被插入虚拟表VT4中。\n5）group by：根据GROUP BY子句中的列，对VT4中的记录进行分组操作，产生VT5。\n6）having：对虚拟表VT6应用HAVING过滤器，只有符合\u0026lt;having_condition\u0026gt;的记录才被插入虚拟表VT6中。\n7）select：选择指定的列，插入到虚拟表V7中。\n 看到没有，select到第7步才被执行，所以千万别人认为写在第一行的就是第一个被执行的。\n 8）distinct：去除重复数据，产生虚拟表V8。\n9）order by：将虚拟表V8中的记录按照\u0026lt;order_by_list\u0026gt;进行排序操作，产生虚拟表V9。\n ORDER BY 默认是升序排序，如果要指定为降序排序则需要加上 DESC 修饰。\n 10）limit：取出指定行的记录，产生虚拟表V10，并返回给查询用户。\n 值得注意的是：LIMIT n, m 表示从第n条记录开始选择m条记录。少量数据时，使用limit进行分页查询是没有任何问题的，但是对于大量数据而言，LIMIT n, m是很低效的。原因是LIMIT每次都是从头开始扫描，如果要取第100万行开始3条数据的话，就需要先扫描定位到第100万行，然后再取，可见其效率是很低很低的。\n 二、附送：Hive中四个BY的区别 所谓四个BY指的是：\n order by sort by distribute by cluster by  关于order by：\n order by会对输入做全局排序，因此只有一个reducer，然而当只有一个reducer会导致当输入数据规模很大时，消耗较长的计算时间。\n 关于sort by：\n sort by会在数据进入reducer前完成排序，实现的是局部排序。因此，如果用 sort by进行排序并且设置 mapped. reduce. tasks \u0026gt;1，则 sort by只会保证每个 reducer的输出有序，并不保证全局有序。\n所以在使用sort by之前还需要设置reduce的个数：\nset mapreduce.job.reducers=4;\n 关于distribute by：\n distribute by是控制在map端如何拆分数据给 reduce端的。hive会根据 distribute by后面的列，对应 reduce的个数进行分发，默认是采用hash算法。sort by为每个 reduce产生一个排序文件。在有些情况下，你需要控制某个特定行应该到哪个 reducer，这通常是为了进行后续的聚集操作。distribute by刚好可以做这件事。因此， distribute by经常和 sort by配合使用。并且hive规定distribute by 语句要写在sort by语句之前。\n 关于cluster by：\n 当distribute by 和 sort by 所指定的字段相同时，cluster by的效果等同于sort by + distribute by，但是cluster by 指定的列只能是升序，且补鞥呢指定asc和desc。\n 其实本人还有两个疑问，那就是group by和partition by。\ngroup by操作表示按照某些字段的值进行分组，有相同的值放到一起。\npartition by 按照字段对数据进行分组。\n","description":"SQL语句和编程语言的语句有很大的不同，有一点原因在于SQL并不一定是按照你写的SQL语句顺序执行的。","id":20,"section":"posts","tags":["SQL","Hive"],"title":"浅谈SQL语句的执行顺序","uri":"https://niub.link/posts/sql-execution-sequence/"},{"content":"  一、Hive简介 1.1 什么是Hive Hive官网给出的定义是：“The Apache Hive ™ data warehouse software facilitates reading, writing, and managing large datasets residing in distributed storage using SQL. Structure can be projected onto data already in storage. A command line tool and JDBC driver are provided to connect users to Hive.”\n我粗糙的理解是，Hive是一个类似Hadoop（集群）的客户端，所谓客户端在手天下我有。就好比你拿到了电视的遥控器，想怎么操作电视就怎么操作电视，比如换台。实际上Hive使用的是类似SQL的语句去操作（离线数据分析、数据管理\u0026hellip;）HDFS上的数据，本质是将SQL语句转化成MapReduce作业。\n1.2 为什么要使用Hive Hive的本质是将SQL转化成MapReduce作业，那么直接使用MapReduce不就好了，何必转一个弯呢？因为Hive更方便啊，它是遥控器！MapReduce编程模型还是有一定门槛的，代码量多而且只有map和reduce过程，实现复杂的计算逻辑则难度相当之大。\n而，Hive能够使得不会编程的数据开发人员也具备操作分析HDFS上数据的能力，只要你SQL写的好、写的妙。\n1.3 Hive有什么特点 先说缺点，这样记得更牢固。\n首先，慢，而且不是一般的慢。当然这是对少量数据而言，比如查询十多行的数据需要100秒左右的时间，这哪能忍。\n其次，Hive不太支持记录级别的增删改操作。注意是不太支持，你要是真想用还是可以用的，只是要选择对应的Hive版本。\n最后，Hive不支持事务。它主要是用来做OLAP（联机分析处理）的，而传统数据库是用来做OLTP（联机事务处理）的，这也是它俩的本质区别之一。\n优点，我是记不住，正经人谁记某个东西的优点啊。\n首先，延展性好。传统SQL能做的它也能做，传统SQL不能做的它还是能做。比如Hive支持自定义函数UDF，开发人员可以根据自己的需求来实现自定义函数。\n其次，拥有HDFS的优点。HDFS的优点也算是它的优点，比如横向扩展。比如加机器的时候是不会对Hive造成影响的，连重启服务也不需要。\n最后，良好的容错性。这一点是硬凑的，我理解不到这一层。\n稍微总结一下：Hive只适合用来做海量数据离线统计分析，也是数据仓库实现常用的技术之一。\n二、Hive的架构  用户接口：包括CLI、JDBC等方式（也就是客户端） 元数据MetaStore：Hive通常将元数据信息保存在传统关系型数据库中，如MySQL，但默认是放在Derby数据库中（这种数据库不支持多用户同时访问）。元数据信息包括：库名、表名、表所属的库名、表的列名/分区字段，表的属性（是否为外部表）、表中数据所在的HDFS目录等信息。【由此可见，元数据的重要性不言而喻。】 Driver：包括：解释器、编译器、优化器、执行器。Hive SQL语句从词法分析、语法分析、编译、优化以及查询计划生成，查询计划存储在HDFS上，MapReduce负责调用执行；  解释器：将用户输入的Hive SQL转化成抽象语法树（AST） 编译器：将AST编译成逻辑执行计划 优化器：将逻辑执行计划进行优化 执行器：优化后的逻辑执行计划转换成可以运行的物理执行计划    三、Hive中数据组织方式 3.1 数据组织方式概览 Hive的存储结构包括数据库、表、视图、分区、表数据等。库、表、分区在HDFS上体现的是一个目录,表数据对应的是目录下的文件。\nHive实际并不存储数据，数据都是存放在HDFS上，因此也没有专门的数据存储格式。Hive是读模式，可支持TextFile、SequenceFile、RCFile或者自定义格式。\nHive支持的存储格式如下表所示，其中，ORC 和 Parquet 的综合性能突出，使用较为广泛，推荐使用这两种格式。在创建表的时候可指定其存储格式，使用STORED AS 参数指定。\n   格式 说明     TextFile 存储为纯文本文件。 这是 Hive 默认的文件存储格式。这种存储方式数据不做压缩，磁盘开销大，数据解析开销大。   SequenceFile SequenceFile 是 Hadoop API 提供的一种二进制文件，它将数据以\u0026lt;key,value\u0026gt;的形式序列化到文件中。这种二进制文件内部使用 Hadoop 的标准的 Writable 接口实现序列化和反序列化。它与 Hadoop API 中的 MapFile 是互相兼容的。Hive 中的 SequenceFile 继承自 Hadoop API 的 SequenceFile，不过它的 key 为空，使用 value 存放实际的值，这样是为了避免 MR 在运行 map 阶段进行额外的排序操作。   RCFile RCFile 文件格式是 FaceBook 开源的一种 Hive 的文件存储格式，首先将表分为几个行组，对每个行组内的数据按列存储，每一列的数据都是分开存储。   ORC Files ORC 是在一定程度上扩展了 RCFile，是对 RCFile 的优化。   Avro Files Avro 是一个数据序列化系统，设计用于支持大批量数据交换的应用。它的主要特点有：支持二进制序列化方式，可以便捷，快速地处理大量数据；动态语言友好，Avro 提供的机制使动态语言可以方便地处理 Avro 数据。   Parquet Parquet 是基于 Dremel 的数据模型和算法实现的，面向分析型业务的列式存储格式。它通过按列进行高效压缩和特殊的编码技术，从而在降低存储空间的同时提高了 IO 效率。    Hive的列分隔符默认是不常见字符Ctrl + A，\\x01；\nHive的行分隔符默认是换行符 \u0026lsquo;\\n\u0026rsquo; ；\nHive中包含以下数据类型：\n database table：在HDFS上体现的是一个目录 external table：与table类似，但是其数据存放位置可以指定任意HDFS目录路径 partition：体现为HDFS上table目录的子目录 bucket：在 HDFS 中表现为同一个表目录或者分区目录下根据某个字段的值进行 hash 散 列之后的多个文件 view：与传统数据库类似，只读，基于表创建  3.2 内外部表和分桶表 内部表和外部表的区别：\nHive默认创建的表都是内部表，除非加external关键字修饰变成外部表。\n当删除内部表时，表中数据和表元数据都会被删掉；\n当删除外部表时，只删除表元数据，不删除表中数据；\n内部表外部表使用选择：\n大多数情况下它们的区别不明显，如果数据的所有处理都在Hive中进行，则倾向于选择内部表。但如果是Hive和其它工具要对相同的数据集进行处理，则外部表更合适。\n 每天采集的网站日志和埋点日志数据，在存储的时候建议使用外部表，因为日志数据是采集程序实时采集进来的，一旦被误删，恢复起来非常麻烦。而且外部表方便数据的共享。 抽取过来的业务数据，其实用外部表或者内部表问题都不大，就算被误删，恢复起来也是很快的，如果需要对数据内容和元数据进行紧凑的管理, 那还是建议使用内部表。 在做统计分析时候用到的中间表，结果表建议使用内部表，因为这些数据不需要共享。并且很多时候结果分区表只需要保留最近3天的数据，用外部表的时候删除分区时无法删除数据。  四、如何使用Hive 4.1 科普SQL中的几个概念 SQL：Structure Query Language，即结构化查询语言；\nSQL共分为四大类：\n 数据定义语言 DDL（Data Definition Language） 数据操纵语言 DML（Data Manipulation Language） 数据查询语言 DQL（Data Query Language） 数据控制语言 DCL（Data Control Language）  其中还有一个事务控制语言 TCL （Transaction Control Language）。下面一张图很好的展示了各个层面的操作SQL命令：\n因此，可以简单的概括一下DDL、DML、DQL、DCL。\n  DDL：用来创建数据库中的各种对象——表、视图、索引、同义词、聚簇等\nCREATE TABLE/VIEW/INDEX/SYN/CLUSTER # 值得注意的是，DDL操作是隐性提交的，不能Rollback；   DML：最常见的增删改\nINSERT/UPDATE/DELETE   DQL：基本结构是由SELECT子句，FROM子句，WHERE子句组成的查询块\nSELECT \u0026lt;字段名表\u0026gt; FROM \u0026lt;表或视图名\u0026gt; WHERE \u0026lt;查询条件\u0026gt;   DCL：用来授予或者回收访问数据库的权限，并控制数据库操纵事务发生的时间及效果，对数据库实时监视等。\nGRANT：授权 ROLLBACK [WORK] TO [SAVEPOINT]：回退到某一点 ROLLBACK：回滚，回滚命令使数据库状态回到上次最后提交的状态   4.2 继续科普一下Hive中的数据类型 传统关系型数据库支持的基本数据类型Hive基本都支持，比如TINYINT、SMALLINT、INT、BIGINT、FLOAT、DOUBLE、BOOLEAN、STRING、DATE。另外，Hive还支持另外三种复杂的类型：ARRAY、MAP、STRUCT。\n4.3 Hive中库表的相关操作 库相关的操作如下面所示：\n   描述 命令 备注     创建一个新的数据库myhive create database myhive;    使用新的数据库myhive use myhive;    查看当前正在使用的数据库 select current_database();     表相关操作表格所示：\n  新建一张student表\n1 2 3 4 5 6 7  create table student( id int, name string, sex string, age int, department string ) row format delimited fields terminated by \u0026#34;,\u0026#34;;     从本地往表中加载数据\n1  load data local inpath \u0026#34;/data/soft/mydata/student.txt\u0026#34; into table student;     查看表结构信息\n  1 2 3 4  # 三种方式，其中formatted展示的信息最全 desc student; desc extended student; desc formatted student;   4.4 使用Beeline Hive 内置了 HiveServer 和 HiveServer2 服务，两者都允许客户端使用多种编程语言进行连接，但是 HiveServer 不能处理多个客户端的并发请求，因此产生了 HiveServer2。HiveServer2（HS2）允许远程客户端可以使用各种编程语言向 Hive 提交请求并检索结果，支持多客户端并发访问和身份验证。HS2 是由多个服务组成的单个进程，其包括基于 Thrift 的 Hive 服务（TCP 或 HTTP）和用于 Web UI 的 Jetty Web 服务。\nHiveServer2 拥有自己的 CLI 工具——Beeline。Beeline 是一个基于 SQLLine 的 JDBC 客户端。由于目前 HiveServer2 是 Hive 开发维护的重点，所以官方更加推荐使用 Beeline 而不是 Hive CLI。以下主要讲解 Beeline 的配置方式。\n  首先启动hiverser2：nohup hiveserver2 \u0026amp;\n  然后使用beeline：beeline -u jdbc:hive2://hadoop200m:10000 -n root\n    ","description":"Hive是一个类似Hadoop（集群）的`客户端`，所谓客户端在手天下我有。","id":21,"section":"posts","tags":["Hive"],"title":"Hive认识我的第一天","uri":"https://niub.link/posts/hive-meeting/"},{"content":" 手把青秧插满田，低头便见水中天。\n心地清净方为道，退步原来是向前。\n ","description":".tech域名有助于创建被认为是前瞻性思维的尖端品牌","id":22,"section":"","tags":null,"title":"About","uri":"https://niub.link/about/"},{"content":"★0、前言 　我们生活的这个时代充满着前所未有的机会：如果你有雄心，又不乏智慧，那么不管你从何处起步，你都可以沿着自己所选择的道路登上事业的顶峰。\n　不过，有了机会，也就有了责任。今天的公司并不怎么管员工的职业发展；实际上，知识工作者必须成为自己的首席执行官。你应该在公司中开辟自己的天地，知道何时改变发展道路，并在可能长达50年的职业生涯中不断努力、干出实绩。要做好这些事情，你首先要对自己有深刻的认识——不仅清楚自己的优点和缺点，也知道自己是怎样学习新知识和与别人共事的，并且还明白自己的价值观是什么、自己又能在哪些方面做出最大贡献。因为只有当所有工作都从自己的长处着眼，你才能真正做到卓尔不群。\n　历史上的伟人——拿破仑、达芬奇、莫扎特——都很善于自我管理。这在很大程度上也是他们成为伟人的原因。不过，他们属于不可多得的奇才，不但有着不同于常人的天资，而且天生就会管理自己，因而才取得了不同于常人的成就。而我们当中的大多数人，甚至包括那些还算有点天赋的人，都不得不通过学习来掌握自我管理的技巧。\n　我们必须学会自我发展，必须知道把自己放在什么样的位置上，才能做出最大的贡献，而且还必须在长达50年的职业生涯中保持着高度的警觉和投入——也就是说，我们得知道自己应该何时换工作，以及该怎么换。\n★1、我的长处是什么？ **多数人都以为他们知道自己擅长什么，其实不然！**更多的情况是，人们只知道自己不擅长什么——即便是在这一点上，人们也往往认识不清。然而，一个人要有所作为，只能靠发挥自己的长处，而如果从事自己不太擅长的工作是无法取得成就的，更不用说那些自己根本干不了的事情。\n　以前的人没有什么必要去了解自己的长处，因为一个人的出身就决定了他一生的地位和职业：农民的儿子也会当农民，工匠的女儿会嫁给另一个工匠等。但是，现在人们有了选择。我们需要知己所长，才能知己所属。\n　要发现自己的长处，唯一途径就是回馈分析法（feedback analysis）。每当做出重要决定或采取重要行动时，你都可以事先记录下自己对结果的预期。9到12个月后，再将实际结果与自己的预期比较。我本人采用这种方法已有15到20年了，而每次使用都有意外的收获。\n　比如，回馈分析法使我看到，我对专业技术人员，不管是工程师、会计师还是市场研究人员，都容易从直觉上去理解他们。这令我大感意外。它还使我看到，我其实与那些涉猎广泛的通才没有什么共鸣。\n　回馈分析法并不是什么新鲜的东西。早在14世纪，这种方法由一个原本会永远默默无闻的德国神学家发明，大约150年后被法国神学家约翰·加尔文和西班牙神学家圣依纳爵分别采用。他们都把这种方法用于其信徒的修行。事实上，回馈分析法使他们的信徒养成了一种始终注重实际表现和结果的习惯，这也是他们创立的教派——加尔文教会和耶稣会——能够主宰欧洲长达30年的原因。\n　**我们只要持之以恒地运用这个简单的方法，就能在较短的时间内（可能两三年），发现自己的长处——这是你需要知道的最重要的事情。**在采用这种方法之后，你就能知道，自己正在做（或没有做）的哪些事情会让你的长处无法发挥出来。同时，你也将看到自己在哪些方面能力不是特别强。最后，你还将了解到自己在哪些方面完全不擅长，做不出成绩来。\n　根据回馈分析的启示，你需要在几方面采取行动。\n　首先，最重要的是，专注于你的长处，把自己放到那些能发挥长处的地方。\n　其次，加强你的长处。回馈分析会迅速地显示，你在哪些方面需要改善自己的技能或学习新技能。它还将显示你在知识上的差距——这些差距通常都可以弥补。数学家是天生的，但是人人都能学习三角学。\n　第三，发现任何由于恃才傲物而造成的偏见和无知，并且加以克服。有太多的人，尤其是那些术业有专攻的人，往往对其他领域的知识不屑一顾，或者认为聪明的头脑就可取代知识。比如，很多一流的工程师遇上与人相关的事就束手无策，他们还以此为荣——因为他们觉得，对条理清晰的工程师头脑来说，人太混乱无序了。与此形成鲜明对照的是，人力资源方面的专业人员常常以他们连基本的会计知识或数量分析都一无所知而自傲。不过，人们要是对这样的无知还沾沾自喜的话，那无异于自取灭亡。其实，要让自己的长处得到充分发挥，你就应该努力学习新技能、汲取新知识。\n　**另外一点也同样重要——纠正你的不良习惯。所谓不良习惯，是指那些会影响你的工作成效和工作表现的事情。这样的习惯能很快地在回馈中反映出来。**例如，一位企划人员可能发现自己美妙的计划最终落空，原因是他没有把计划贯彻到底。同那些才华横溢的人一样，他也相信好的创意能够移动大山。但是，真正移山的是推土机，创意只不过是为推土机指引方向，让它知道该到何处掘土。这位企划人员必须意识到不是计划做好就大功告成，接下来还得找人执行计划，并向他们解释计划，在付诸行动前须做出及时的调整和修改，最后要决定何时中止计划。\n　与此同时，回馈还会反映出哪些问题是由缺乏礼貌造成的。礼貌是一个组织的润滑剂。两个移动物相互接触时发生摩擦是一个自然规律，不仅无生命的物体是这样，人类也是如此。礼貌，其实也很简单，无非是说声“请”和“谢谢”，记住别人的名字，或问候对方家人这样的小事，但就是这种不起眼的细节，使得两个人能够融洽相处，不管他们彼此之间是否有好感。许多聪明人，尤其是聪明的年轻人，没有意识到这一点。如果回馈分析表明某个人只要一遇到需要别人合作的事就屡屡失败，那么很可能就意味着这个人的举止不大得体——也就是缺乏礼貌。\n　把预期和实际结果进行比较，也会发现自己不擅长做什么。我们每个人都有许多一窍不通、毫无天分的领域，在这些领域我们甚至连平庸的水平都达不到。人们，尤其是知识工作者，就不应该试图去完成这些领域的工作和任务。他们应该尽量少把精力浪费在那些不能胜任的领域上，因为“从无能到平庸”要比“从一流到卓越”需要人们付出多得多的努力。然而，大多数人，尤其是教师，还有组织，都一门心思要把能力低下的人变成合格者。其实，他们还不如把精力、资源和时间花在将称职者培养成佼佼者上。\n★2、我的工作方式是怎样的？ 　令人惊讶的是，很少有人知道自己平时是怎样把事情给做成的。实际上，我们当中的大多数人甚至不知道不同人有着不同的工作方式和表现。许多人不是以他们习惯的方式工作，这当然就容易造成无所作为。对于知识工作者来说，“我的工作方式是怎样的？”可能比“我的长处是什么？”这个问题更加重要。\n　同一个人的长处一样，一个人的工作方式也是独一无二的——这是由人的个性所决定的。不管个性是先天决定的，还是后天培养的，它肯定是早在一个人进入职场前就形成了。正如一个人擅长什么、不擅长什么是既定的一样，一个人的工作方式也基本固定，它可以略微有所调整，但是不可能完全改变——当然也不会轻易改变。而且就像人们从事自己最拿手的工作容易做出成绩一样，他们要是采取了自己最擅长的工作方式也容易取得成就。通常，几个常见的个性特征就决定了一个人的工作方式。\n我属于读者型，还是听者型？\n　首先，你要搞清楚的是，你是读者型（习惯阅读信息）还是听者型（习惯听取信息）的人。绝大多数人甚至都不知道还有“读者型”和“听者型”之说，而且很少有人既是读者型又是听者型。知道自己属于哪种类型的人更少。但是，有一些例子说明了这样的无知可能造成多大的危害。\n　德怀特·艾森豪威尔担任欧洲盟军最高统帅时，一直是新闻媒体的宠儿。他的记者招待会以其独特的风格出名——不管记者提出什么问题，艾森豪威尔将军都从容地对答如流。无论是介绍情况，还是解释政策，他都能够用两三句言简意赅的话就说清楚。十年后，艾森豪威尔当上了总统，当年曾对他十分崇拜的同一批记者，这时却公开瞧不起他。他们抱怨说，他从不正面回答问题，而是喋喋不休地胡侃着其他事情。他们总是嘲笑他回答问题时语无伦次，不合乎语法，糟蹋标准英语。\n　艾森豪威尔显然不知道自己属于读者型，而不是听者型。当他担任欧洲盟军最高统帅时，他的助手设法确保媒体提出的每一个问题至少在记者招待会开始前半小时以书面形式提交。这样，艾森豪威尔就完全掌握了记者提出的问题。而当他就任总统时，他的两个前任都是听者型——富兰克林·罗斯福和哈里·杜鲁门。这两位总统知道自己是听者型的，并且都喜欢举行畅所欲言的记者招待会。艾森豪威尔可能认为他必须去做两位前任所做的事。可是，他甚至连记者们在问些什么都从来没听清楚过。而且，艾森豪威尔并不是个极端的例子。\n　几年后，林登·约翰逊把自己的总统职位给搞砸了，这在很大程度上是因为他不知道自己是听者型的人。他的前任约翰·肯尼迪是个读者型的人，他搜罗了一些出色的笔杆子当他的助手，要求他们每次进行当面讨论之前务必先给他写通报。约翰逊留下了这些人，他们则继续写通报。可是他显然根本看不懂他们写的东西。不过，约翰逊以前当参议员时曾经表现非凡，因为议员首先必须是听者型。\n　**没有几个听者型的人可以通过努力变成合格的读者型——不管是主动还是被动的努力；反之亦然。**因此，试图从听者型转为读者型的人会遭受林登·约翰逊的命运，而试图从读者型转为听者型的人会遭受德怀特·艾森豪威尔的命运。他们都不可能发挥才干或取得成就。\n★3、我如何学习？ 要了解一个人的工作方式，需要弄清的第二点是，他是如何学习的。\n　许多一流的笔杆子都不是好学生——温斯顿·邱吉尔就是一例。在他们的记忆中，上学往往是十足的折磨。然而，他们的同学有这种记忆的却很少。他们可能在学校里得不到什么乐趣，对他们来说上学的最大痛苦是无聊。有关这个问题的解释是，笔头好的人一般不靠听和读来学习，而靠写来学习，这已成了一种规律。学校不让他们以这种方式学习，所以他们的成绩总是很糟糕。\n　所有的学校都遵循这样的办学思路：只有一种正确的学习方式，而且人人都得遵从。但是，对学习方式跟别人不大一样的学生来说，被迫按学校教的方式来学习就是地狱。实际上，学习大概有六七种不同的方式。\n　像邱吉尔这样的人靠写来学习。还有些人以详尽的笔记来学习。例如，贝多芬留下了许多随笔小抄，然而他说，实际上他作曲时从来不看这些随笔小抄。当被问及他为什么还要用笔记下来时，据说他回答道：“如果我不马上写下来的话，我很快就会忘得一干二净。如果我把它们写到小本子上，我就永远不会忘记了，也用不着再看一眼。”有些人在实干中学习。另一些人通过听自己讲话学习。\n　我认识一位公司总经理，他把一个平庸的小家族企业发展成行业领军企业。他是一个通过讲话学习的人。他习惯于每周一次把全体高层管理人员召集到他的办公室，随后对他们讲上两三个小时。他总是提出政策性问题，在每一个问题上提出三种不同观点。但他很少请这帮同事发表意见或提出问题，他只需要听众听他讲话。这就是他的学习方式。虽然他是一个比较极端的例子，但是通过讲话学习绝不是一种少见的方法。成功的出庭律师也以同样的方式学习，许多诊断医师也是如此（我自己也是这样）。\n　在所有最重要的自我认识当中，最容易做到的就是知道自己是怎样学习的。当我问人们：“你怎么学习？”大多数人都知道答案。但是，当我问：“你根据这个认识来调整自己的行为吗？”没有几个人回答“是”。然而，知行合一是取得成就的关键；如果知行不合一，人们就会无所作为。\n　我属于读者型还是听者型？我如何学习？这是你首先要问自己的问题。但是，光这些问题显然不够。要想做好自我管理，你还需要问这样的问题：我能与别人合作得好吗？还是喜欢单枪匹马？如果你确实有与别人进行合作的能力，你还得问问这个问题：我在怎样的关系下与他人共事？\n　有些人适合当部属。二战时期美国的大英雄乔治·巴顿将军是一个很好的例子。巴顿是美军的一名高级将领。然而，当有人提议他担任独立指挥官时，美国陆军参谋长（可能也是美国历史上最成功的伯乐）乔治·马歇尔将军说：“巴顿是美国陆军造就的最优秀的部下，但是，他会成为最差劲的司令官。”\n　一些人作为团队成员工作最出色；另一些人单独工作最出色。一些人当教练和导师特别有天赋；另一些人却没能力做导师。\n　另一个关键的问题是，我如何才能取得成果——是作为决策者还是作为顾问？\n　许多人做顾问时的表现会很出色，但是不能够承担决策的负担和压力。与此相反，也有许多人需要顾问来迫使他们思考，随后他们才能做出决定，接着迅速、自信和大胆地执行决定。\n　顺便说一下，一个组织的二号人物在提升到一号职位时常常失败，也正是因为这个原因。最高职位需要一个决策者，而一个强势的决策者常常把其信赖的人放在二号位置，当他的顾问。顾问在二号位置上往往是很出色的，但是换到一号位置，他就不行了。他虽然知道应该做出什么样的决定，但是不能接受真正做决定的责任。\n　其他有助于认识自我的重要问题包括：\n 1、我是在压力下表现出色，还是适应一种按部就班、可预测的工作环境？\n2、我是在一个大公司还是在一个小公司中工作表现最佳？\n3、在各种环境下都工作出色的人寥寥无几。\n 　我不止一次地看到有些人在大公司中十分成功，换到小公司中则很不顺利。反过来也是如此。下面这个结论值得我们反复强调：**不要试图改变自我，因为这样你不大可能成功。但是，你应该努力改进你的工作方式。**另外，不要从事你干不了或干不好的工作。\n★4、我的价值观是什么？ 　要能够自我管理，你最后不得不问的问题是：我的价值观是什么？这不是一个有关伦理道德的问题。道德准则对每一个人都一样。要对一个人的道德进行测试，方法很简单。我把它称为“镜子测试”。\n　20世纪初，德国驻英国大使是当时在伦敦所有大国中最受尊重的一位外交官。显然，他命中注定会承担重任，即使不当本国的总理，至少也要当外交部长。然而，在1906年，他突然辞职，不愿主持外交使团为英国国王爱德华七世举行的晚宴。这位国王是一个臭名昭著的色鬼，并且明确表示他想出席什么样的晚宴。据有关报道，这位德国大使曾说：“我不想早晨刮脸时在镜子里看到一个皮条客。”——这就是镜子测试。\n　我们所遵从的伦理道德要求你问自己：我每天早晨在镜子里想看到一个什么样的人？在一个组织或一种情形下合乎道德的行为，在另一个组织或另一种情形下也是合乎道德的。但是，道德只是价值体系的一部分——尤其对于一个组织的价值体系来说。\n　如果一个组织的价值体系不为自己所接受或者与自己的价值观不相容，人们就会备感沮丧，工作效力低下。\n　让我们来看看一位十分成功的人力资源主管的经历。这位主管所在的公司被一家大企业收购。收购之后，她得到了提升，从事的是她以前做得最出色的工作，包括为重要职位挑选人才。这位主管深信，在选人时，公司只有在排除内部的所有可能人选后才能从外部招聘人才。但是她的新公司认为应该首先从外部招聘，以吸收新鲜血液。对于这两种方式，需要说明的一点是，根据我的经验，适当的方式是两者兼顾。然而，这两种方式在根本上是互不相容的——表面上是政策不同，实质是价值观的不同。这说明在该公司人们对以下三个问题有着不同看法：组织与员工之间是怎样的关系；组织应该为员工以及员工的发展承担何种责任；一个人对企业最重要的贡献是什么。经过几年挫折，这位主管最终辞职——尽管她的经济损失很大。她的价值观和这个组织的价值观就是无法融合。\n　同样，一家制药公司无论是通过不断的小幅改进，还是通过几次费用高昂、风险巨大的“突破”来取得出色业绩，都不是一个经济问题。这两种战略的结果可能都差不多。实质上，这是两种价值体系之间的冲突。一种价值体系认为公司的贡献是帮助医生把他们已经在做的工作锦上添花，另一种价值体系的取向是进行更多的科学发现。\n　至于一个企业的经营是着眼于短期结果，还是注重长远发展，这同样是价值观问题。财务分析师认为，企业可两者同时兼顾。成功的企业家知道得更清楚。诚然，每一家公司都必须取得短期成果。但是在短期成果与长期增长之间的冲突中，每一家公司都将决定自己所选择的重点。从根本上说，这是一种关于企业职能与管理层责任的价值观冲突。\n　价值观冲突并不限于商业组织。美国发展最快的一个牧师教会，其衡量工作成败的尺度是新教徒的人数。它的领导层认为，重要的是有多少新教徒入会。随后，上帝将满足他们的精神需求，或者至少会满足足够比例的新教徒的需求。另一个福音派牧师教会认为，重要的是人们的精神成长。这个教会慢慢地让那些形式上入会但精神上并没有融入教会生活的新教徒选择了离开。\n　这同样不是一个数量问题。乍一看，第二个教会好像发展较慢。但是，它留住新教徒的比例要远高于第一个。换言之，它的发展比较稳固。这也不是一个神学问题（至少首先并不是神学问题），而是有关价值观的问题。在一次公开辩论中，一位牧师这样说：“除非你先加入教会，否则你永远找不到天国之门。”而另一位牧师反驳说：“不，除非你先有心寻找天国之门，否则你就不属于教会。”\n　**组织和人一样，也有价值观。为了在组织中取得成效，个人的价值观必须与这个组织的价值观相容。两者的价值观不一定要相同，但是必须相近到足以共存。**不然，这个人在组织中不仅会感到沮丧，而且做不出成绩。\n　一个人的工作方式和他的长处很少发生冲突，相反，两者能产生互补。但是，一个人的价值观有时会与他的长处发生冲突。一个人做得好甚至可以说是相当好、相当成功的事情——可能与其价值体系不吻合。在这种情况下，这个人所做的工作似乎并不值得贡献毕生的精力（甚至没必要贡献太多的精力）。\n　如果可以，请允许我插入一段个人的故事。多年前，我也曾不得不在自己的价值观和做得很成功的工作之间做出选择。20世纪30年代中期，我还是一个年轻人，在伦敦做投资银行业务，工作非常出色。这项工作显然能发挥我的长处。然而，我并不认为自己担任资产管理人是在做贡献。我认识到，我所重视的是对人的研究。我认为，一生忙于赚钱、死了成为墓地中的最大富翁没有任何意义。当时我没有钱，也没有任何就业前景。尽管当时大萧条仍在持续，我还是辞去了工作。这是一个正确的选择。换言之，价值观是并且应该是最终的试金石。\n★5、我属于何处？ 　少数人很早就知道他们属于何处。比如，数学家、音乐家和厨师，通常在四五岁的时候就知道自己会成为数学家、音乐家和厨师了。物理学家通常在十几岁甚至更早的时候就决定了自己的工作生涯。但是，**大多数人，尤其是很有天赋的人，至少要过了二十五六岁才知道他们将身属何处。**然而，到这个时候，他们应该知道上面所谈的三个问题的答案：\n 1、我的长处是什么？\n2、我的工作方式是怎样的？\n3、我的价值观是什么？\n 随后，他们就能够决定自己该向何处投入精力。或者，他们应该能够决定自己不属于何处。\n　已经知道自己在大公司里干不好的人，应该学会拒绝在一个大公司中任职。已经知道自己不适合担任决策者的人，应该学会拒绝做决策工作。巴顿将军（他自己大概永远不知道这一点）本来应该学会拒绝担任独立总指挥的。\n　同样重要的是，知道上述三个问题的答案，也使得一个人能够坦然接受一个机会、一个邀请或一项任务。他们会说：“是的，我将做这件事。但是，我将按照我自己的特点，采取这样的方式来做这件事，进行这样的组织安排，这样来处理当中所牵涉的关系。这是我在这个时间范围内应该会取得的成果，因为这就是我。”\n　**成功的事业不是预先规划的，而是在人们知道了自己的长处、工作方式和价值观后，准备把握机遇时水到渠成的。**知道自己属于何处，可使一个勤奋、有能力但原本表现平平的普通人，变成出类拔萃的工作者。\n★6、我该做什么贡献？ 　综观人类的发展史，绝大多数人永远都不需要提出这样一个问题：我该做出什么贡献？因为他们该做出什么贡献是由别人告知的，他们的任务或是由工作本身决定的（例如农民或工匠的任务），或是由主人决定的（例如佣人的任务）。\n　以前的人大多都处于从属地位，别人吩咐他们做什么，就做什么，这被认为是理所当然的。甚至到了20世纪50年代和60年代，那时涌现出的知识工作者（即所谓的“组织人”，organization man）还指望公司的人事部为他们做职业规划。\n　随后，到20世纪60年代末，就再没有人想让别人来安排自己的职业生涯了。年轻的男男女女开始提出这个问题：我想做什么？而他们所听到的答案就是“你们自行其是吧”。但是，这种回答同“组织人”听命公司的做法一样错误。那些相信自行其是就能做出贡献、实现抱负、取得成功的人，一般连三点中的任何一点都做不到。\n　尽管如此，我们还是不能走回头路，让别人来吩咐、安排自己要干什么。对于知识工作者来说，他们还不得不提出一个以前从来没有提出过的问题：我的贡献应该是什么？要回答这个问题，他们必须考虑三个不同的因素：\n 1、当前形势的要求是什么？\n2、鉴于我的长处、我的工作方式以及我的价值观，我怎样才能对需要完成的任务做出最大贡献？\n3、必须取得什么结果才能产生重要影响？\n 　请看一位新任命的医院院长的经历。这是一所享有盛名的大医院，30年来一直就靠名气顺利经营着。新院长上任后决定了自己应做的贡献：两年内在医院的某个重要领域建立起卓越服务的标准。他决定以急诊室为重点，因为该院的急诊室地方比较大，受人注意，而又秩序混乱。他决定，到急诊室就诊的每一个患者必须在60秒钟之内由一名合格的护士接待。一年之内，该医院的急诊室变成了美国所有医院的样板，又过了两年，整个医院的面貌焕然一新。\n　正如这个事例所表明的，把眼光放得太远是不大可能的——甚至不是特别有效。一般来说，一项计划的时间跨度如果超过了18个月，就很难做到明确和具体。因此，在多数情况下我们应该提出的问题是：\n 1、我在哪些方面能取得将在今后一年半内见效的结果？\n2、如何取得这样的结果？\n 　回答这个问题时必须对几个方面进行权衡：\n　首先，这些结果应该是比较难实现的——用当前的一个时髦词说，就是要有“张力”（stretching）。但是，这些结果也应该是能力所及的。设定一个不能实现的目标或者只能在可能性微乎其微的情况下实现的目标，根本不能叫雄心勃勃，简直就是愚蠢。\n　其次，这些结果应该富有意义，要能够产生一定影响。\n　最后，结果应该明显可见，如果可能的话，还应当能够衡量。确定了要实现的结果之后，接着就可以制订行动方针：做什么，从何处着手，如何开始，目标是什么，在多长时间内完成。\n★7、我要如何处理人际关系？ 　除了少数伟大的艺术家、科学家和运动员，很少有人是靠自己单枪匹马而取得成果的。不管是组织成员还是个体职业者，大多数人都要与别人进行合作，并且是有效的合作。要实现自我管理，你需要对自己的人际关系负起责任。这包括两部分内容。\n　首先是要接受：别人是和你一样的个体这个事实。\n　每个人都会执意展现自己作为人的个性。这就是说，**每个人都有自己的长处，自己的做事方式和自己的价值观。因此，要想卓有成效，你就必须知道共事者的长处、工作方式和价值观。**这个道理听起来让人很容易明白，但是没有几个人真正会去注意。\n　一个习惯于写报告的人就是个典型的例子——他在第一份工作时就培养起写报告的习惯，因为他的老板是一个读者型的人，而即使下一个老板是个听者型，此人也会继续写着那肯定没有任何结果的报告。这位老板因此肯定会认为这个员工愚蠢、无能、懒惰，肯定干不好工作。但是，如果这个员工事先研究过新老板的情况，并分析过这位老板的工作方式，这种情况本来可以避免。\n　老板既不是组织结构图上的一个头衔，也不是一个“职能”。他们是有个性的人，他们有权以自己最得心应手的方式来工作。与他们共事的人有责任观察他们，了解他们的工作方式，并做出相应的自我调整，以适应老板最有效的工作方式。事实上，这就是“管理”上司的秘诀。\n　这种方法适用于所有与你共事的人。每个人都有他自己的做事方法，也有权按照自己的方式来工作，而不是按你的方法来工作。重要的是，他们能否有所作为以及他们持有什么样的价值观。至于工作方式，人各有别。提高效力的第一个秘诀是了解跟你合作和你要依赖的人，以利用他们的长处、工作方式和价值观。工作关系应当既以工作为基础，也以人为基础。\n　人际关系责任的第二部分内容是沟通责任。\n　在我或是其他人开始给一个组织做咨询时，我们听到的第一件事都与个性冲突有关。其中大部分冲突都是因为：人们不知道别人在做什么，他们又是采取怎样的工作方式，专注于做出什么样的贡献以及期望得到怎样的结果。而这些人不了解情况的原因是，他们没有去问，结果也就不得而知。这种不去问明情况的做法，与其说是反映了人类的愚蠢，倒不如说是历史使然。\n　在以前，人们没必要把这些情况告诉任何人。比如在中世纪的城市，一个区的每一个人从事的行业都一样。在乡村，土地刚一解冻，山谷里的每一个人就开始播种同一种农作物。即使有少数人做的事情和大家不一样，他们也是单独工作，因此不需要告诉任何人他们在做什么。\n　而现在，大多数人都与承担着不同任务和责任的人一道工作。市场营销副总裁可能是销售出身，知道有关销售的一切，但是，对于自己从未做过的事情，比如定价、广告、包装等等，就一无所知了。所以，那些正在做这些工作的人必须确保营销副总裁懂得他们设法做的是什么、他们为什么要做这件事、他们将如何去做以及期望取得什么结果。\n　如果营销副总裁不懂得这些高层次的、知识型的专业人士在做什么，错主要在后者身上，而不在自己。反过来说，营销副总裁的责任则是确保他的所有同事都知道自己是怎样看待营销这项工作的：他的目标是什么、他如何工作，以及他对他本人和他的每一个同事有什么期望。\n　即使一些人懂得负起人际关系责任的重要性，他们和同事的交流也往往不够。他们总是有所顾虑，怕别人把自己看成是一个冒昧、愚蠢、爱打听的人。他们错了。因为我们看到，每当有人找到他的同事说“这是我所擅长的工作。这是我的做事方式。这是我的价值观。这是我计划做出的贡献和应当取得的成果”，这个人总会得到如此回答：“这太有帮助了，可你为什么不早点告诉我？”\n　如果一个人继续问道：“那么，关于你的长处、你的工作方式、你的价值观以及你计划做出的贡献，我需要知道什么？”他也会得到类似的答复——据我的经验，无一例外。事实上，知识工作者应该向与他们共事的每一个人，不管是下属、上司、同事还是团队成员，都发出这样的疑问。而且，每次提出此类问题，都会得到这样的回答：“谢谢你来问我。但是，你为什么不早点问我？”\n　**组织已不再建立在强权的基础上，而是建立在信任的基础上。人与人之间相互信任，不一定意味着他们彼此喜欢对方，而是意味着彼此了解。**因此，人们绝对有必要对自己的人际关系负责。这是一种义务。不管一个人是公司的一名成员，还是公司的顾问、供应商或经销商，他都需要对他的所有共事者负起这种责任。所谓共事者，是指在工作上他所依赖的同事以及依赖他的同事。\n★8、我该如何管理后半生？ 　当多数人的工作是体力劳动时，你不必为自己的后半生担心。你只要继续从事你一直在做的工作就行了。如果你够幸运，能在工厂或铁路辛勤工作40年后撑下来，你就可以快乐地度过余生，什么也用不着干。然而，现在的多数工作都是知识工作，而知识工作者在干了40年后，仍能发挥余热，他们只是有些厌倦。\n　我们听到了许多有关经理人中年危机的谈论，“厌倦”这个词在其中频频出现。45岁时，多数经理人的职业生涯达到了顶峰，他们也知道这一点。在做了20年完全相同的工作之后，他们已经得心应手。但是他们学不到新东西，也没有什么新贡献，从工作中得不到挑战，因而也谈不上满足感。然而，在他们面前，还有20到25年的职业道路要走。这就是为什么经理人在进行自我管理后，越来越多地开始发展第二职业的原因。\n　发展第二职业有三种方式：\n　第一种是完全投身于新工作。\n　这常常只需要从一种组织转到另一种组织。例如，一家大公司某事业部的会计师成为一家中型医院的财务总监。但是也有越来越多的人转入完全不同的职业。例如，公司经理在45岁时进入政府内阁；或者中层管理人员在公司工作20年后离职，到法学院进修，成为一个小镇的律师。还有许多人在第一份职业中取得的成功有限，于是改行从事第二职业。这样的人有很多技能，他们也知道该如何工作。而且，他们需要一个社群——因为孩子已长大单飞，剩下一座空屋。他们也需要收入。但最重要的是，他们需要挑战。\n　为后半生做准备的第二种方式是，发展一个平行的职业。\n　许多人的第一职业十分成功，他们还会继续从事原有工作，或全职或兼职，甚至只是当顾问。但是，除此之外，他们会开创一项平行的工作，通常是在非营利机构，每周占用10个小时。例如，他们可能接手教会的管理，或者担任当地女童子军顾问委员会主席。他们也可能管理受虐妇女庇护所，担任当地公共图书馆的儿童图书管理员，或在学校董事会任职等。\n　最后一种方法是社会创业。\n　社会创业者通常是在第一职业中非常成功的人士。他们都热爱自己的工作，但是这种工作对他们已经不再有挑战性。在许多情况下，他们虽然继续做着原来的工作，但在这份工作上花的时间越来越少。他们同时开创了另一项事业，通常是非营利性活动。例如，我的朋友鲍勃·布福德创办了一个非常成功的电视公司，现在他仍然经营着。但与此同时，他还创建了一个与新教教会合作的非营利组织，也做得非常成功。现在他又创建了一个组织，专门指导社会创业者在经营原有业务的同时，如何管理自己另外创办的非营利机构。\n　**能管理好自己后半生的人总是少数。多数人可能“一干到底”，数着年头一年一年过去，直至退休。**但是，正是这些少数人，这些把漫长的工作寿命看做是自己和社会之机会的男男女女，才会成为领袖和模范。\n　**管理好后半生有一个先决条件：你必须早在你进入后半生之前就开始行动。**当30年前人们首次认识到工作寿命正在迅速延长时，许多观察家（包括我自己）认为，退休人员会越来越多地成为非营利机构的志愿者。可是，这种情况并没有发生。一个人如果不在40岁之前就开始做志愿者，那他60岁之后也不会去做志愿者。\n　同样，我认识的所有社会创业者，都是早在他们原有的事业达到顶峰之前就开始从事他们的第二事业。请看一名成功律师的例子。这位律师是一家大公司的法律顾问，他同时在自己所在的州开办了模特培训学校。早在他35岁左右的时候，他就开始志愿为学校提供法律咨询。40岁时被推选为一家学校的董事会成员。50岁时，他积累起了一笔财富，办起了自己的企业——建立并经营模特培训学校。然而此时，他依旧在那家他年轻时参与创建的公司里担任首席法律顾问，而且几乎是全职工作。\n　发展第二兴趣（而且是趁早发展）还有一个原因：任何人都不能指望在生活或工作中很长时间都不遭遇严重挫折。有一位很能干的工程师在45岁时错过了晋升的机会。另一位也很能干的普通学院的教授在42岁时认识到，即使她完全具备担任教授的资格，她永远也不会在一所有名的大学里获得教授职位。还有一位则是在家庭生活里出现了悲剧：婚姻破裂或者痛失子女。在这样的时刻，第二兴趣——不仅仅是业余爱好——还可能发挥重要作用。例如，这位工程师现在知道他在工作上并不十分成功。但是，在公司以外的活动中，例如负责教会资金的管理，他是成功的。一个人可能家庭破碎，但是他能在第二兴趣的活动中发现还有社区这个大“家庭”。\n　在一个崇尚成功的社会里，拥有各种选择变得越来越重要。从历史上来看，却没有“成功”一说。绝大多数人只期望坚守“适当的位置”。唯一的流动性是向下的流动性。然而，在知识社会里，我们期望每一个人都能取得成功。这显然是不可能的。对许多人来说，能避免失败就行。可是有成功的地方，就会有失败。因此，有一个能够让人们做出贡献、发挥影响力或成为“大人物”的领域，这不仅对个人十分重要，对个人的家庭也同样重要。这意味着人们需要找到一个能够有机会成为领袖、受到尊重、取得成功的第二领域——可能是第二份职业，也可能是平行的职业或社会创业。\n　自我管理中面临的挑战看上去比较明显，甚至非常基本，其答案可能不言自明，甚至近乎幼稚。但是，自我管理需要个人，尤其是知识工作者，做出以前从未做过的事情。实际上，自我管理需要每一个知识工作者在思想和行动上都要成为自己的首席执行官。更进一步来看，这样的转变——从一切听从别人吩咐的体力劳动者到不得不自我管理的知识工作者——也使得社会结构发生了深刻变化。\n　历史上每一个社会，甚至是个人主义倾向最强的社会，都认为（即使只是下意识地认为）两件事情是理所当然的：\n 1、组织比员工更长寿；\n2、大多数人从不挪地方。\n 　如今，情况恰恰相反。知识工作者的寿命超过了组织寿命，而且他们来去自如。于是，人们对自我管理的需要在人类事务中掀起了一场革命。\n","description":"据说，这篇长文对每个人都很有帮助。通过此文的借鉴，可以帮助你更好地规划自己的职业生涯和人生。","id":23,"section":"reproduced","tags":["转载",""],"title":"转载：自我管理","uri":"https://niub.link/reproduced/managing-oneself/"},{"content":"★《爱因斯坦：我的世界观》 　我们这些总有一死的人，命运是多么的奇特！我们每个人在这个世界上都只作一个短暂的逗留；目的何在，却无从知道，尽管有时自以为对此若有所感。但是，不必深思，只要从日常生活中就可以明白：人是为别人而生存的──首先是为那样一些人，我们的幸福全部依赖于他们的喜悦和健康；其次是为许多我们所不认识的人，他们的命运通过同情的纽带同我们密切结合在一起。我每天上百次的提醒自己：我的精神生活和物质生活都是以别人（包括生者和死者）的劳动为基础的，我必须尽力以同样的分量来报偿我所领受了的和至今还在领受着的东西。我强烈地向往着俭朴的生活。并且时常发觉自己占用了同胞的过多劳动而难以忍受。我认为阶级的区分是不合理的，它最后所凭借的是以暴力为根据。我也相信，简单淳朴的生活，无论在身体上还是在精神上，对每个人都是有益的。\n　我完全不相信人类会有那种在哲学意义上的自由。每个人的行为不仅受着外界的强制，而且要适应内在的必然。叔本华说：“人虽然能够做他所想做的，但不能要他所想要的。”这句格言从我青年时代起就给了我真正的启示；在我自己和别人的生活面临困难的时候，它总是使我们得到安慰，并且是宽容的持续不断的源泉。这种体会可以宽大为怀地减轻那种容易使人气馁的责任感，也可以防止我们过于严肃地对待自己和别人；它导致一种特别给幽默以应有地位的人生观。\n　要追究一个人自己或一切生物生存的意义或目的，从客观的角度来看，我总觉得是愚蠢可笑的。可是每个人都有一些理想，这些理想决定着他的努力和判断的方向。就在这个意义上，我从来不把安逸和享乐看作生活目的本身──我把这种伦理基础叫做“猪栏的理想”。照亮我的道路，是善、美和真。要是没有志同道合者之间的亲切感情，要不是全神贯注于客观世界──那个在艺术和科学工作领域里永远达不到的对象，那么在我看来，生活就会是空虚的。我总觉得，人们所努力追求的庸俗目标──财产、虚荣、奢侈的生活──都是可鄙的。\n　我有强烈的社会正义感和社会责任感，但我又明显地缺乏与别人和社会直接接触的要求，这两者总是形成古怪的对照。我实在是一个“孤独的旅客”，我未曾全心全意地属于我的国家、我的家庭、我的朋友，甚至我最为接近的亲人；在所有这些关系面前，我总是感觉到有一定距离而且需要保持孤独──而这种感受正与年俱增。人们会清楚地发觉，同别人的相互了解和协调一致是有限度的，但这不值得惋惜。无疑，这样的人在某种程度上会失去他的天真无邪和无忧无虑的心境；但另一方面，他却能够在很大程度上不为别人的意见、习惯和判断所左右，并且能够避免那种把他的内心平衡建立在这样一些不可靠的基础之上的诱惑。\n　我的政治理想是民主政体。让每一个人都作为个人而受到尊重，而不让任何人成为被崇拜的偶像。我自己一直受到同代人的过分的赞扬和尊敬，这不是由于我自己的过错，也不是由于我自己的功劳，而实在是一种命运的嘲弄。其原因大概在于人们有一种愿望，想理解我以自已微薄的绵力，通过不断的斗争所获得的少数几个观念，而这种愿望有很多人却未能实现。我完全明白，一个组织要实现它的目的，就必须有一个人去思考，去指挥、并且全面担负起责任来。但是被领导的人不应当受到强迫，他们必须能够选择自己的领袖。在我看来，强迫的专制制度很快就会腐化堕落。因为暴力所招引来的总是一些品德低劣的人；而且我相信，天才的暴君总是由无赖来继承的，这是一条千古不易的规律。就是由于这个缘故，我总强烈地反对今天在意大利和俄国所见到的那种制度。像欧洲今天所存在的情况，已使得民主形式受到怀疑，这不能归咎于民主原则本身，而是由于政府的不稳定和选举制度中与个人无关的特征。我相信美国在这方面已经找到了正确的道路。他们选出了一个任期足够长的总统，他有充分的权力来真正履行他的职责。另一方面，在德国政治制度中，为我所看重的是它为救济患病或贫困的人作出了可贵的广泛的规定。在人生的丰富多彩的表演中，我觉得真正可贵的，不是政治上的国家，而是有创造性的、有感情的个人，是人格；只有个人才能创造出高尚的和卓越的东西，而群众本身在思想上总是迟钝的，在感觉上也总是迟钝的。\n　讲到这里，我想起了群众生活中最坏的一种表现，那就是使我厌恶的军事制度。一个人能够洋洋得意的随着军乐队在四列纵队里行进，单凭这一点就足以使我对他鄙夷不屑。他所以长了一个大脑，只是出于误会；光是骨髓就可满足他的全部需要了。文明的这种罪恶的渊薮，应当尽快加以消灭。任人支配的英雄主义、冷酷无情的暴行，以及在爱国主义名义下的一切可恶的胡闹，所有这些都使我深恶痛绝！在我看来，战争是多么卑鄙、下流！我宁愿被千刀万剐，也不愿参与这种可憎的勾当。尽管如此，我对人类的评价还是十分高的。我相信，要是人民的健康感情没有遭到那些通过学校和报纸而起作用的商业利益和政治利益的蓄意败坏，那么战争这个妖魔早就该绝迹了。\n　我们能拥有的最美好的体验是探求奥秘的体验。它是坚守在真正艺术和真正科学发源地上的基本感情。谁要是体会不到它，谁要是不再有好奇心，也不再有惊讶的感觉，谁就无异于行尸走肉，他的眼睛便是模糊不清的。就是这种奥秘的体验──虽然掺杂着恐惧──产生了宗教。我们认识到有某种为我们所不能洞察的东西存在，感觉到那种只能以其最原始的形式接近我们的心灵的最深奥的理性和最灿烂的美──正是这种认识和这种情感构成了真正的宗教感情；在这个意义上，而且也只是在这个意义上，我才是一个具有深挚的宗教感情的人。我无法想象存在这样一个上帝，它会对自己的创造物加以赏罚，会具有我们在自己身上所体验到的那种意志。我不能也不愿去想象一个人在肉体死亡以后还会继续活着；让那些脆弱的灵魂，由于恐惧或者由于可笑的唯我论，去拿这种思想当宝贝吧！我自己只求满足于生命永恒的奥秘，满足于觉察现存世界的神奇结构，窥见它的一鳞半爪，并且以诚挚的努力去领悟在自然界中显示出来的那个理性的一部分，倘若真能如此，即使只领悟其极小的一部分，我也就心满意足了。\n★《乔布斯：在斯坦福大学的演讲》 　我十七岁的时候，读到了一句话：“如果你把每一天都当作生命中最后一天去生活的话，那么有一天你会发现自己是正确的。”这句话给我留下了深刻的印象。从那时开始，过了33年，我在每天早晨都会对着镜子问自己：“如果今天是我生命中的最后一天，我还会做今天要做的事情吗？”如果连续很多天得到否定的回答，那我就需要作出一些改变了。\n　“记住你即将死去”是我一生中遇到的最重要箴言。它帮我指明了生命中重要的选择。因为几乎所有的事情（包括所有的荣誉、所有的骄傲、所有对难堪和失败的恐惧），在死亡面前都会消失。我看到的是留下的真正重要的东西。\n　你有时候会思考你将要失去的东西，“记住你即将死去”是我知道的避免这些想法的最好办法。你已经赤身裸体了，你没有理由不去跟随自己的心一起跳动。\n　大概一年以前，我的一次体检结果清楚的显示在我的胰腺有一个肿瘤。医生告诉我那很可能是一种无法治愈的癌症，我还有三到六个月的时间活在这个世界上。我的医生叫我回家，然后整理好我的一切，那就是医生准备死亡的程序。那意味着你将要把未来十年对你小孩说的话在几个月里面说完；那意味着把每件事情都搞定，让你的家人会尽可能轻松的生活；那意味着你要说“再见了”。我整天和那个诊断书一起生活。后来有一天早上医生将一个内窥镜从我的喉咙伸进去，通过我的胃，然后进入我的肠子，用一根针在我的胰腺上的肿瘤上取了几个细胞。我当时很镇静，因为我被注射了镇定剂。但是我的妻子在那里，后来告诉我，当医生在显微镜地下观察这些细胞的时候他们开始尖叫，因为这些细胞最后竟然是一种非常罕见的、可以用手术治愈的胰腺癌细胞。我做了这个手术，现在我痊愈了。\n　那是我最接近死亡的时候，我还希望这也是以后的几十年最接近的一次。从死亡线上又活了过来，死亡对我来说，只是一个有用但是纯粹是知识上的概念的时候，我可以更肯定一点地对你们说：没有人愿意死，即使人们想上天堂，人们也不会为了去那里而死。但是死亡是我们每个人共同的终点。从来没有人能够逃脱它，也应该如此。因为死亡是生命中最好的一个发明。它把旧的清除以便给新的让路。你们现在是新的，但是从现在开始不久以后，你们将会逐渐的变成旧的然后被清除。这很有戏剧性，而事实就是如此。\n　你们的时间有限，所以不要浪费时间去重复别人的生活。不要被教条束缚，那意味着你和其他人思考的结果一起生活。不要被其他人喧嚣的观点掩盖你内心真正的想法。还有最重要的是，拥有追随自己内心与直觉的勇气——你的内心与直觉多少已经知道你真正想要成为什么样的人。与之相比，所有其它事情都是次要的。\n　当我年轻的时候，有一本振聋发聩的杂志叫做《全球概览》——它是我们那代人的圣经之一。一个叫 Stewart Brand 的家伙神奇地将这本杂志带到这个世界上。当时还是60年代末，所以这本书全部是用打字机、剪刀还有偏光镜制作的。Stewart 和他的伙伴出版了几期《全球概览》，当它完成了自己使命的时候，他们出了最后一期。在最后一期的封底上是清晨乡村公路的照片（如果你有冒险精神的话，你可以自己找到这条路的），在照片之下有这样一段话：“Stay Hungry, Stay Foolish”。这是他们停止了发刊的告别语。“Stay Hungry, Stay Foolish”，我总是希望自己能够那样。现在，在你们即将毕业，开始新的旅程的时候。我也希望你们能做到：Stay Hungry, Stay Foolish。\n★《王小波：工作与人生》 　我现在已经活到了人生的中途，拿一日来比喻人的一生，现在正是中午。人在童年时从朦胧中醒来，需要一些时间来克服清晨的软弱，然后就要投入工作；在正午时分，他的精力最为充沛，但已隐隐感到疲惫；到了黄昏时节，就要总结一日的工作，准备沉入永恒的休息。按我这种说法，工作是人一生的主题。这个想法不是人人都能同意的。我知道在中国，农村的人把生儿育女看作是一生的主题。把儿女养大，自己就死掉，给他们空出地方来——这是很流行的想法。在城市里则另有一种想法，但不知是不是很流行：它把取得社会地位看作一生的主题。站在北京八宝山的骨灰墙前，可以体会到这种想法。我在那里看到一位已故的大叔墓上写着：副系主任、支部副书记、副教授、某某教研室副主任，等等。假如能把这些“副”字去掉个把，对这位大叔当然更好一些，但这些“副”字最能证明有这样一种想法。顺便说一句，我到美国的公墓里看过，发现他们的墓碑上只写两件事：一是生卒年月，二是某年至某年服兵役；这就是说，他们以为人的一生只有这两件事值得记述：这位上帝的子民曾经来到尘世，以及这位公民曾去为国尽忠，写别的都是多余的，我觉得这种想法比较质朴……恐怕在一份青年刊物上写这些墓前的景物是太过伤感，还是及早回到正题上来罢。\n　我想要把自己对人生的看法推荐给青年朋友们：人从工作中可以得到乐趣，这是一种巨大的好处。相比之下，从金钱、权力、生育子女方面可以得到的快乐，总要受到制约。举例来说，现在把生育作为生活的主题，首先是不合时宜；其次，人在生育力方面比兔子大为不如，更不要说和黄花鱼相比较；在这方面很难取得无穷无尽的成就。我对权力没有兴趣，对钱有一些兴趣，但也不愿为它去受罪——做我想做的事（这件事对我来说，就是写小说），并且把它做好，这就是我的目标。我想，和我志趣相投的人总不会是一个都没有。\n　根据我的经验，人在年轻时，最头疼的一件事就是决定自己这一生要做什么。在这方面，我倒没有什么具体的建议：干什么都可以，但最好不要写小说，这是和我抢饭碗。当然，假如你执意要写，我也没理由反对。总而言之，干什么都是好的；但要干出个样子来，这才是人的价值和尊严所在。人在工作时，不单要用到手、腿和腰，还要用脑子和自己的心胸。我总觉得国人对这后一方面不够重视，这样就会把工作看成是受罪。失掉了快乐最主要的源泉，对生活的态度也会因之变得灰暗……\n　人活在世上，不但有身体，还有头脑和心胸——对此请勿从解剖学上理解。人脑是怎样的一种东西，科学还不能说清楚。心胸是怎么回事就更难说清。对我自己来说，心胸是我在生活中想要达到的最低目标。某件事有悖于我的心胸，我就认为它不值得一做；某个人有悖于我的心胸，我就觉得他不值得一交；某种生活有悖于我的心胸，我就会以为它不值得一过。罗素先生曾言，对人来说，不加检点的生活，确实不值得一过。我同意他的意见：不加检点的生活，属于不能接受的生活之一种。人必须过他可以接受的生活，这恰恰是他改变一切的动力。人有了心胸，就可以用它来改变自己的生活。\n　中国人喜欢接受这样的想法：只要能活着就是好的，活成什么样子无所谓。从一些电影的名字就可以看出来：《活着》、《找乐》……我对这种想法是断然地不赞成，因为抱有这种想法的人就可能活成任何一种糟糕的样子，从而使生活本身失去意义。高尚、清洁、充满乐趣的生活是好的，人们很容易得到共识。卑下、肮脏、贫乏的生活是不好的，这也能得到共识。但只有这两条远远不够。我以写作为生，我知道某种文章好，也知道某种文章坏。仅知道这两条尚不足以开始写作。还有更加重要的一条，那就是：某种样子的文章对我来说不可取，绝不能让它从我笔下写出来，冠以我的名字登在报刊上。以小喻大，这也是我对生活的态度。\n","description":"转载三篇有关于爱因斯坦对人生、政治、宗教的看法的著名演讲以及乔布斯在斯坦福大学的演讲、王小波对工作与人生的看法相关文章。","id":24,"section":"reproduced","tags":["转载",""],"title":"转载：关于人生","uri":"https://niub.link/reproduced/my-worldview/"},{"content":"Sample images from Pixabay\n","description":"cartoon gallery","id":25,"section":"gallery","tags":null,"title":"Cartoon","uri":"https://niub.link/gallery/cartoon/"}]