[{"content":"一、关于HBase建表时的几个设计原则 1.1 预分区 背景：HBase默认建表时有一个Region，且这个Region是没有RowKey边界的，所有数据在写入时都是往这个默认的Region中存入数据。随着数据量的不断增加，Region达到一定大小后会自动Split，而Split过程中会产生两个问题：\n 数据可能只会往一个Region里面写，造成热点问题； Split是昂贵的操作，会消耗宝贵的集群IO资源；  对策：在创建表的时候，创建多个空Region，并确定每个Region的StartRowKey和EndRowKey，通过RowKey的合理设计使得数据均匀的落在各个Region上，不会存在热点问题；\n1.2 RowKey的设计原则 （1）RowKey长度越短越好。HBase中的底层数据是以HFile文件形式组织的，而HFile中是安装KV存储的，如果K过大会极大的影响存储效率；写入数据时会经过MemStore，如果K过长所占空间过大，内存的有效利用就会降低。\n（2）RowKey尽量散列。建议将RowKey的高位作为散列字段，使得数据均衡分布在每个RegionServer，提高负载均衡的几率，避免热点问题；\n（3）保证RowKey的唯一性\n1.3 列族的设计原则 （1）列族名不宜过长\n（2）建表时至少指定一个列族，列族一般不超过五个\n（3）不同列族的记录数据集不应相差太大\n二、关于HBase的常用优化方法 2.1 调优从如下几方面着手 （1）Master高可用：在HBase中Master负责监控RegionServer的生命周期，均衡RegionServer的负载，如果Master宕机则HBase集群将无法使用。\n（2）RegionServer预分区：提前大致规划好RegionServer的分区，因为每一个Region维护着StartRowKey和EndRowKey，如果加入的数据RowKey符合某个范围，则把该数据提交给Region。\n（3）优化RowKey的设计：RowKey是数据的唯一表示，数据存储在哪个Region取决于RowKey在哪一个预分区区间内，所以合理设计RowKey可在一定程度上防止数据倾斜。\n（4）内存优化：HBase操作的过程中需要大量的内存开销，一般会分配整个可用内存的70%给HBase的Java堆，如果配置太大则GC过程持续太久会导致RegionServer长期处于不可用状态。\n（5）减少Region分裂次数，给HFile设置合理大小；\n2.2 各种减少 （1）关闭Compation操作，合并操作在业务低峰时手动进行；\n（2）减少数据量，开启布隆过滤器可提高查询速度，降低网络I/O\n（3）数据存储时使用压缩，如Snappy、LZO、GZip等压缩方式\n2.3 HMaster和HRgionserver职责 HMaster和HRegionServer分别是Master和RegionServer在操作系统层面上的具体实现，体现的是两个HBase进程；\nHMaster的职责：\n（1）记录Region在哪台RegionServer服务器上；\n（2）新机器加入时负责RegionServer的负载均衡；\n（3）Region满足一定大小后需要Split后，HMaster负责Region的分配；\n（4）RegionServer宕机之后，负责迁移n多个Region到其它RegionServer；\n（5）管理用户对Table表的增删改操作；\nHRegionServer的职责：\n（1）负责响应用户的IO请求，比如读写HDFS上的数据；\n（2）管理多个Region分区；\n三、附送：Hive和HBase的区别 3.1 HBase和Hive的区别 共同点：HBase和Hive都是基于Hadoop的，都是使用HDFS作为底层存储。\nHive是基于Hadoop的数据仓库分析工具，其作用是对海量的数据进行离线分析、计算，本质是将Hive SQL转化成MapReduce任务。\nHive不支持索引，所进行的操作都是全表扫描；而HBase支持索引，支持海量数据的随机读操作，一定程度上弥补了HDFS对准实时查询操作的缺陷。\nHive中的表是纯逻辑概念，它本身不存储和计算数据，而HBase中的表是物理表，而且都是以列存储数据的。其内部有一个超大内存的Hash表，用来存储数据的索引，支持随机访问；\nHBase负责组织HDFS上的文件（HDFS只负责存储）；\n","description":"HBase中的底层数据是以HFile文件形式组织的，而HFile中是安装KV存储的，如果K过大会极大的影响存储效率...","id":2,"section":"posts","tags":["HBase",""],"title":"HBase建表设计原则和优化","uri":"http://blog.langchao2020.tech/posts/hbase-table-and-optimize/"},{"content":"一、前言 1.1 关于HBase我早就想学了 刚接触大数据的时候就听说过这些名词，Hadoop、HDFS、MapReduce、YARN、Hive、Spark、Flink\u0026hellip;.等，其中也听说过今天的主角——HBase。看到它的简要介绍时不禁发出感叹，好吊啊！能够存储几亿行*几百万列的数据量，当时截图给网友看的时候我都惊呆了。\n后面也陆续看了一些入门级别的HBase的教程，脑子里也有一些关于它的印象，什么RegionServer啊，Master啥的，心里也惦记着什么时候来学一学它。\n1.2 之前做了些什么？ 相比于其它组件，我还是算比较早接触到HBase的，从安装好了Hadoop集群之后就把HBase分布式数据库也给安装起来了，安装好了之后打开Web监控页面，写个test表建表语句，Web端看看瞧瞧也就算完成任务了。后面就去学习其他大数据组件去了，什么Hive、Spark、Flink、数据仓库、Kafka轮着来，就是没有轮到HBase，于是HBase的学习就一拖再拖\u0026hellip;\n1.3 为什么放缓学习HBase的进度？ 偶然的机会进入了一位网课老师的QQ学习内部群，是关于入行大数据的课程的学习群。我在群里有问到他课程体系中怎么没有HBase，他说HBase在这个系列课程中用的不是很多，追求精简就直接把HBase这块的内容给删减掉了。还有一个原因是传统JavaWeb方向也有用到HBase服务的，所以给我的感觉是HBase也重要但是不如其它大数据组件重要，于是就没有把重心放在HBase的学习上，不过我倒是也有在无聊的时候看看它，有时候技术交流群里面也会谈到HBase，也能顺便学到一些知识。\n1.4 今天开始学习HBase 昨天晚上躺床上我就想着今天应该把HBase给学了，因为看到很多小伙伴在群里讨论HBase的相关技术，我一句话也插不上，简直白瞎，哈哈( • ̀ω•́ )✧。在慕课网找了两门关于HBase的免费课程，一个偏入门，一个偏存储原理，而今天的这则笔记主要摘自HBase入门的视频课程。\n二、HBase入门 2.0 重要的事情才标0 今天在视频中听到老师说了这么一句话“学习任何一门技术之前需要搞清楚意义在哪里，学完之后它能帮助我们解决什么问题，和其它相类似的技术有什么区别。”，这句话很快就被我捕捉到了，我觉得这句话对我帮助很大很大。目前为止也学了蛮多技术了，从前端到后端再到大数据，每个框架每门语言都有着特定的用途，这也是它们在软件开发中的定位。比如Python虽然也能搞Web后端，但是远不如Java搞后端；比如JavaScript天生为Web页面而生，Go语言优秀的性能使得它完美的适合用于处理高并发、区块链的开发之中\u0026hellip;.\n于是我又想到了——HBase在Hadoop大数据体系的定义和定位。为什么要考虑这个，换个思路，你是否也要考虑你在这个世界的定义和定位？\n2.1 HBase的应用场景及特点  面向列：HBase是面向列的存储，支持独立检索 多版本存储：每一个列的数据存储有多个Version 稀疏性：表中为空的列并不占用存储空间，因此表可以设计的非常稀疏 良好的扩展性：数据底层依赖于HDFS 高可靠性：WAL预写日志机制保证了数据写入时不会因为集群出现异常而导致数据丢失或损坏 高性能：底层的LSM日志合并树和RowKey有序排序的独特架构特性，使得HBase具有非常高的写入性能  2.2 HBase架构体系与设计模型 HBase强烈依赖于两个外部服务：HDFS和Zookeeper。主要包含两个进程：Master、RegionServer（在Linux系统上实际实现的进程分别是：HMaster、HRegionServer；\n（本想在这里插入一张HBase体系架构图，但是考虑到Typora插入图片并发布到网上可能会耗费我很多时间，而且今天的时间已经不多了，所以打算明天再来解决插入图片的问题）。\n 利用Gitee+PicGo搞了一个免费的Hugo博客图床服务，不得不说Gitee真的很良心，免费提供5G存储空间，大赞！在Typora中设置图床服务为PicGo，在你把图片粘贴到编辑器中时Typora会通过PicGo自动把图片上传到Gitee上，图片链接全网可访问！\n 在HBase中有一个Master和多个RegionServer服务，其中RegionServer管理多个Region，Region是HBase实现高性能和负载均衡的基本单位。一个Region含有多个列族，每个列族下有多个列。\n关于HBase更多的底层存储细节今天在此不表，打算明天在写一则关于HBase存储原理的博客，进一步强化自己对HBase的理解。比如为什么HBase插入性能很高，为什么随机读的速度很快等常见问题都可以被轻松的回答\u0026hellip;\u0026hellip;(给自己挖坑)！\n2.3 HBase数据模型举例说明 关于列族：\n 一张表的列族不会超过5个 每个列族中的列数没有限制 列只有插入数据后存在 列在列族中是有序的（字典序）  关于Region：\n 每个Region管理若干条数据记录 一个RegionServer中有多个Region，且不同的Region可能会分不到不同的RegionServer上 Region中的数据和其它Region中的数据是互斥的  2.4 HBase表和传统关系型数据表结构的对比 在HBase中，列可以动态增加、数据可自动切分（一个Region达到阈值大小会自动切分成多个Region）、高并发读写，但不支持条件查询。\n而传统关系型数据库支持复杂的条件查询，对事务的支持很好，但是不具备HBase所具有的优点。\n2.5 HBase的安装部署 安装部署就不赘述了，右手就能做，正经人谁去老老实实的把安装部署的全过程贴出来啊！不过需要值得注意的是安装HBase之前需要做这么几件事：\n JDK1.8以上的安装 Hadoop的安装 Zookeeper的安装 hbase-env.sh的配置 hbase-site.xml的配置 别忘记了，web监控页面端口是16010  2.6 HBase常用命令 正经人一般不贴这玩意儿，什么诸如list、scan、drop、create、delete、enable、disable、describe、is_enabled\u0026hellip;啥的，就不一一列举出来了，在HBase shell中敲一个help就有一大坨指导你怎么用的东西了，很简单。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  hbase(main):024:0\u0026gt; help \u0026#39;create\u0026#39; Creates a table. Pass a table name, and a set of column family specifications (at least one), and, optionally, table configuration. Column specification can be a simple string (name), or a dictionary (dictionaries are described below in main help output), necessarily including NAME attribute. Examples: Create a table with namespace=ns1 and table qualifier=t1 hbase\u0026gt; create \u0026#39;ns1:t1\u0026#39;, {NAME =\u0026gt; \u0026#39;f1\u0026#39;, VERSIONS =\u0026gt; 5} Create a table with namespace=default and table qualifier=t1 hbase\u0026gt; create \u0026#39;t1\u0026#39;, {NAME =\u0026gt; \u0026#39;f1\u0026#39;}, {NAME =\u0026gt; \u0026#39;f2\u0026#39;}, {NAME =\u0026gt; \u0026#39;f3\u0026#39;} hbase\u0026gt; # The above in shorthand would be the following: hbase\u0026gt; create \u0026#39;t1\u0026#39;, \u0026#39;f1\u0026#39;, \u0026#39;f2\u0026#39;, \u0026#39;f3\u0026#39; hbase\u0026gt; create \u0026#39;t1\u0026#39;, {NAME =\u0026gt; \u0026#39;f1\u0026#39;, VERSIONS =\u0026gt; 1, TTL =\u0026gt; 2592000, BLOCKCACHE =\u0026gt; true} hbase\u0026gt; create \u0026#39;t1\u0026#39;, {NAME =\u0026gt; \u0026#39;f1\u0026#39;, CONFIGURATION =\u0026gt; {\u0026#39;hbase.hstore.blockingStoreFiles\u0026#39; =\u0026gt; \u0026#39;10\u0026#39;}} hbase\u0026gt; create \u0026#39;t1\u0026#39;, {NAME =\u0026gt; \u0026#39;f1\u0026#39;, IS_MOB =\u0026gt; true, MOB_THRESHOLD =\u0026gt; 1000000, MOB_COMPACT_PARTITION_POLICY =\u0026gt; \u0026#39;weekly\u0026#39;} Table configuration options can be put at the end. Examples: hbase\u0026gt; create \u0026#39;ns1:t1\u0026#39;, \u0026#39;f1\u0026#39;, SPLITS =\u0026gt; [\u0026#39;10\u0026#39;, \u0026#39;20\u0026#39;, \u0026#39;30\u0026#39;, \u0026#39;40\u0026#39;] hbase\u0026gt; create \u0026#39;t1\u0026#39;, \u0026#39;f1\u0026#39;, SPLITS =\u0026gt; [\u0026#39;10\u0026#39;, \u0026#39;20\u0026#39;, \u0026#39;30\u0026#39;, \u0026#39;40\u0026#39;] hbase\u0026gt; create \u0026#39;t1\u0026#39;, \u0026#39;f1\u0026#39;, SPLITS_FILE =\u0026gt; \u0026#39;splits.txt\u0026#39;, OWNER =\u0026gt; \u0026#39;johndoe\u0026#39; hbase\u0026gt; create \u0026#39;t1\u0026#39;, {NAME =\u0026gt; \u0026#39;f1\u0026#39;, VERSIONS =\u0026gt; 5}, METADATA =\u0026gt; { \u0026#39;mykey\u0026#39; =\u0026gt; \u0026#39;myvalue\u0026#39; } hbase\u0026gt; # Optionally pre-split the table into NUMREGIONS, using hbase\u0026gt; # SPLITALGO (\u0026#34;HexStringSplit\u0026#34;, \u0026#34;UniformSplit\u0026#34; or classname) hbase\u0026gt; create \u0026#39;t1\u0026#39;, \u0026#39;f1\u0026#39;, {NUMREGIONS =\u0026gt; 15, SPLITALGO =\u0026gt; \u0026#39;HexStringSplit\u0026#39;} hbase\u0026gt; create \u0026#39;t1\u0026#39;, \u0026#39;f1\u0026#39;, {NUMREGIONS =\u0026gt; 15, SPLITALGO =\u0026gt; \u0026#39;HexStringSplit\u0026#39;, REGION_REPLICATION =\u0026gt; 2, CONFIGURATION =\u0026gt; {\u0026#39;hbase.hregion.scan.loadColumnFamiliesOnDemand\u0026#39; =\u0026gt; \u0026#39;true\u0026#39;}} hbase\u0026gt; create \u0026#39;t1\u0026#39;, \u0026#39;f1\u0026#39;, {SPLIT_ENABLED =\u0026gt; false, MERGE_ENABLED =\u0026gt; false} hbase\u0026gt; create \u0026#39;t1\u0026#39;, {NAME =\u0026gt; \u0026#39;f1\u0026#39;, DFS_REPLICATION =\u0026gt; 1} You can also keep around a reference to the created table: hbase\u0026gt; t1 = create \u0026#39;t1\u0026#39;, \u0026#39;f1\u0026#39; Which gives you a reference to the table named \u0026#39;t1\u0026#39;, on which you can then call methods.   没错，我就是凑字数的，不服来打我啊ヾ(•ω•`。)\n三、小结一下 3.1 关于实操性的东西 比如常见命令的时候真的没有必要去死记硬背，要智慧的借助工具来完成自己的目的。比如前面提到的shell界面敲一个help就能够解决我们很多关于操作性的命令。我们应该把有限的精力和时间投入到无限的学习之中，学习什么呢？学习如何学习，也就是学习智慧。\n3.2 思考 \u0026gt; 动手 以前我学习的时候喜欢边学边做笔记，所以打字速度算是比较快的，但是学完某个东西之后却发现除了留下死水一般的笔记之外什么也没有得到。什么原因？我觉得这是思维上的懒惰所导致的，大脑不去思考只喜欢做机械性的事情，比如抄笔记。其实学习更重要的是体会与理解，体会老师说的理解书上写的视频中放的\u0026hellip;，正所谓笔记易得，知识难学。\n3.3 自顶向下，由外而内的学习方法 学过计算机网络的boys肯定知道有一本很有名的书，叫《计算机网络——自顶向下方法》。很多年过去了，现在突然觉得自顶向下的学习方法真的很受用，它能使你以一种俯视的角度去看待某个东西。越顶层越接近用户，越底层越接近计算机，如果一开始就是学习距离用户很遥远的东西会产生很强烈的挫败感。因为你没法和知识产生共鸣，觉得这个东西学了对我好像也没什么用处，死记硬背记住它那更是生不如死，着实痛苦。\n比如关于HBase采用自顶向下，由外而内的学习方法，你可以学到：从LSM日志合并树这一条主线，分层次的去学习HBase的存储原理，你会豁然开朗。（比如Level 0,就引申出了Store、MemStore、WAL、StoreFile等重要的概念。）因为学习的自始至终过程你都是抓住了主线的，一层一层的剥开它的心，彻底走进它的心房。这个过程是很自然的，很舒畅的甚至是很开心的，并不会产生一种强烈的不愉快感。\n在此引用视频中老师的几句话，我觉得对我的启发很大对我十分有帮助：\n  首先从高层次的思想上来看HBase 的存储思想。(LSM存储思想） 看似很复杂的工作流程经过拆分讲解其实也不是特别的难懂；   3.4 该止笔了 今天只剩下20分钟不到的时间了，等会还要把写好的文章编译上传到Github，那今天的任务就算完成了。这篇博客居然差不多有3000千字，写了一个多小时，侧重点还是关于学习的感悟上，具体知识点的记录还是比较少。考虑到时间的问题，打算明天在写一篇更加深入的HBase文章——关于其存储原理的具体剖析。当然了，这些也是我看视频学习整理之后的笔记，并加上自己的学习感悟和理解，对自己学习如何学习肯定有很大的帮助的~\n最后来点颜文字表情吧：）\n＃〓§〓〓〓〓〓§〓〓〓〓〓〓§〓〓〓〓〓§〓＃\n↓　↓　↓　↓\n☆★☆　☆★☆　☆★☆　☆★☆\n☆　祝　☆　☆　你　☆　☆　幸　☆　☆　福　☆\n☆★☆　☆★☆　☆★☆　☆★☆\n↓　↓　↓　↓\n※　※　※　※\n","description":"学习任何一门技术之前需要搞清楚意义在哪里，学完之后它能帮助我们解决什么问题，和其它相类似的技术有什么区别。","id":3,"section":"posts","tags":["HBase",""],"title":"浅谈HBase入门以及一些学习感悟","uri":"http://blog.langchao2020.tech/posts/talk-about-hbase01/"},{"content":"一、回顾Hive的架构 1.1 Hive的基本结构 在Hadoop 2.x版本以后，Hive所有运行的任务都是交由YARN来统一管理。下图所示为Hive作业的工作流程：\n客户端提交SQL作业到HiveServer2, HiveServer2会根据用户提交的SQL作业及数据库中现有的元数据信息（实际生产中存放在MySQL中）生成一份可供计算引擎执行的计划。每个执行计划对应若干MapReduce作业，Hive会将所有的MapReduce作业都一一提交到YARN中，由YARN去负责创建MapReduce作业对应的子任务任务，并协调它们的运行。YARN创建的子任务会与HDFS进行交互，获取计算所需的数据，计算完成后将最终的结果写入HDFS或者本地。\n从整个Hive运行作业的过程我们可以知道Hive自身主要包含3个部分：\n 第一部分是客户端（Client） 第二部分是HiveServer2 第三部分是元数据以及元数据服务。  1.2 关于Hive的元数据 Hive的元数据保存在Hive的metastore数据中，里面记录着Hive数据库、表、分区和列的一些当前状态信息，通过收集这些状态信息，可以帮助我们更好地监控Hive 数据库当前的状态，提前感知可能存在的问题；可以帮助基于成本代价的SQL 查询优化，做更为正确的自动优化操作。\nHive的元数据主要分为5个大部分：\n 数据库相关的元数据 表相关的元数据 分区相关的元数据 文件存储相关的元数据 其他（事务信息、锁信息以及权限相关信息）  1.3 Hive的知识体系 下面一张图摘自《Hive性能调优实战》，全面的展示了Hive的知识体系，其实这篇文章算是我阅读这本书的读书笔记吧，很多知识点讲的比较详细我就直接摘抄下来了。\n二、YARN详解 2.1 传统多线程编程和调度框架的对比 在单机程序设计中， 为了快速处理一个大的数据集， 通常采用多线程并行编程。大体流程如下 ：\n先由操作系统启动一个主线程， 由它负责数据切分、 任务分配、 子线程启动和销毁等工作， 而各个子线程只负责计算自己的数据， 当所有子线程处理完数据后， 主线程再退出。\n而，在生产环境中的大数据集群，所有作业或系统运行所需的资源，都不是直接向操作系统申请，而是交由资源管理器和调度框架代为申请。每个作业或系统所需的资源都是由资源管理和调度框架统一分配、协调。在业界中扮演这一角色的组件有YARN、Mesos等。\n2.2 YARN的优点 YARN作为资源调用框架有着如下优点：\n 提高系统的资源利用率。不同系统和不同业务在不同的时间点对硬件资源的需求是不一样的，例如一些离线业务通常在凌晨时间启动，除了这个阶段的离线业务对资源的占用比较高，其他时间段基本是空闲的，通过统一资源调度和协调，将这些时间段的资源分配给其他系统。不仅计算资源可以共享，由于允许多套系统部署在一个集群，也能增加系统存储资源的利用率。 协调不同作业/不同系统的资源，减少不同作业和不同系统之间的资源争抢。例如通过资源管理和调度框架并通过一定的资源分配策略，能够保证在多作业情况下，各个作业都能够得到足够的资源得以运行，而不会出现一个作业占用所有资源，导致其他作业全部阻塞的情况。 增强系统扩展性。资源管理和调度框架，允许硬件资源的动态伸缩，而不会影响作业的运行。 资源调度与管理工具把控着资源的分配和任务的调度，直接影响程序的运行效率。如果任务得到资源少了，必将影响自身的程序运行效率，如果任务占用过多资源，在集群任务运行高峰期，必然导致挤占其他任务运行所需的资源。  那么如何利用资源与调度管理工具？作为大数据集群的使用者，基于Hive 做业务的开发者要高效地利用资源与调度管理工具，需要知道两方面的内容：\n YARN运行的基本组成和工作原理，能够基本理清程序运行的整体流程，知道哪些过程或者配置可能成为瓶颈，可以先不用了解，但一定要有意识。 YARN资源调度与分配算法。   这里有个感触就是，对学习任何一个大数据组件是不是也应该采用这种方式呢？第一要熟悉该组件的基本组成和工作原理，对其大体的工作流程要熟悉。当然了看一遍是不可能全部记住以及全部消化和理解的。不如多看几遍，很多陌生的名词头一次看或许印象不深，但是如果多看几遍甚至发到技术群讨论一下，印象和理解或许更加深刻，也有助于对该技术组件的学习。\n由此引申HDFS、MapReduce、Kafka、HBase、Spark、Flink\u0026hellip;都按照这种套路来学，会不会有触类旁通的效果呢？\n 2.3 YARN的基本组成 YARN的基本结构由一个ResourceManager与多个NodeManager组成。ResourceManager负责对NodeManager所持有的资源进行统一管理和调度。当在处理一个作业时ResourceManager会在NodeManager所在节点创建一全权负责单个作业运行和监控的程序ApplicationMaster。\n  ResouceManager（简称RM）\n 资源管理器负责整个集群资源的调度，该组件由两部分构成：调度器（Scheduler）和ApplicationsMaster（简称ASM）。调度器会根据特定调度器实现调度算法，结合作业所在的队列资源容量，将资源按调度算法分配给每个任务。分配的资源将用容器（container）形式提供，容器是一个相对封闭独立的环境，已经将CPU、内存及任务运行所需环境条件封装在一起。通过容器可以很好地限定每个任务使用的资源量。YARN调度器目前在生产环境中被用得较多的有两种：能力调度器（CapacityScheduler）和公平调度器（Fair Scheduler）。（还有一种FIFO Scheduler）\n   ApplicationMaster（简称AM）\n 每个提交到集群的作业（job）都会有一个与之对应的AM 来管理。它负责进行数据切分，并为当前应用程序向RM 去申请资源，当申请到资源时会和NodeManager 通信，启动容器并运行相应的任务。此外，AM还负责监控任务（task）的状态和执行的进度。\n   NodeManage（简称NM）\n NodeManager负责管理集群中单个节点的资源和任务，每个节点对应一个NodeManager, NodeManager负责接收ApplicationMaster的请求启动容器，监控容器的运行状态，并监控当前节点状态及当前节点的资源使用情况和容器的运行情况，并定时回报给ResourceManager。\n   2.4 YARN工作流程 YARN在工作时主要会经历3个步骤：\n（1）ResourceManager收集NodeManager反馈的资源信息，将这些资源分割成若干组，在YARN中以队列表示。（2）当YARN接收用户提交的作业后，会尝试为作业创建一个代理ApplicationMaster。\n（3）由ApplicationMaster将作业拆解成一个个任务（task），为每个任务申请运行所需的资源，并监控它们的运行。\nYARN在处理任务时的工作流程如下图所示。经历了以下几个步骤：\n（1）客户端向YARN提交一个作业（Application）。\n（2）作业提交后，RM根据从NM收集的资源信息，在有足够资源的节点分配一个容器，并与对应的NM进行通信，要求它在该容器中启动AM。\n（3）AM创建成功后向RM中的ASM注册自己，表示自己可以去管理一个作业（job）。\n（4）AM注册成功后，会对作业需要处理的数据进行切分，然后向RM申请资源，RM会根据给定的调度策略提供给请求的资源AM。\n（5）AM申请到资源成功后，会与集群中的NM通信，要求它启动任务。\n（6）NM接收到AM的要求后，根据作业提供的信息，启动对应的任务。\n（7）启动后的每个任务会定时向AM提供自己的状态信息和执行的进度。\n（8）作业运行完成后AM会向ASM注销和关闭自己。\n三、再谈MapReduce 3.1 移动数据不如移动计算的大数据计算思想 一个完整的MapReduce任务提交到Hadoop集群，Mapper中的逻辑会被分发到集群中的各个节点，并读取该节点的本地数据进行处理，最后写入到本地。这种模式就是所谓的不移动数据，而只移动计算逻辑的模式。目前绝大部分的分布式计算引擎，相比于移动计算，移动数据需要消耗更多的网络I/O和磁盘I/O的资源。在进行调优时，我们借鉴这种设计方法，尽可能地减少数据在节点之间的传输。\n3.2 Map和Reduce的工作流程 Map 在读取数据时，先将数据拆分成若干数据，并读取到Map 方法中被处理。数据在输出的时候，被分成若干分区并写入内存缓存（buffer）中，内存缓存被数据填充到一定程度会溢出到磁盘并排序（缓冲区大小默认100M，数据超过80M时进行溢写操作），当Map 执行完后会将一个机器上输出的临时文件进行归并存入到HDFS中。\n当Reduce 启动时，会启动一个线程去读取Map 输出的数据，并写入到启动Reduce机器的内存中，在数据溢出到磁盘时会对数据进行再次排序（由此可见Reduce阶段是会有排序的）。当读取数据完成后会将临时文件进行合并，作为Reduce函数的数据源。整个过程如下图所示。\n3.3 MapReduce整体环节的浅析 下面这张图体现的是MapReduce整体工作流程：\n一个完整的MapReduce任务提交到Hadoop集群，Reducer中的逻辑会被分发到集群中的各个节点。但是不同于Mapper读取本地文件，Reducer会去拉取远程Map节点产生的数据，这里必然也会涉及网络I/O 和磁盘I/O。从这里我们可以看到，如非需要对数据进行全局处理，例如全局排序，就关掉Reduce阶段的操作，可以提升程序性能。\n在写入到HDFS的过程中，为了下游Reducer任务顺序快速拉取数据，会将数据进行排序后再写入临时文件中，当整个Map 执行结束后会将临时文件归并成一个文件。如果不进行文件的排序归并，意味着下游Reducer任务拉取数据会频繁地搜索磁盘，即将顺序读变为随机读，这会对磁盘I/O产生极大的负载。\nReducer任务启动后，会启动拉取数据的线程，从HDFS拉取所需要的数据。为什么不选用Mapper任务结束后直接推送到Reducer节点，这样可以节省写入到磁盘的操作，效率更高？因为采用缓存到HDFS，让Reducer主动来拉，当一个Reducer任务因为一些其他原因导致异常结束时，再启动一个新的Reducer依然能够读取到正确的数据。\n从HDFS拉取的数据，会先缓存到内存缓冲区，当数据达到一定的阈值后会将内存中的数据写入内存或者磁盘中的文件里。当从HDFS 拉取的数据能被预先分配的内存所容纳，数据会将内存缓存溢出的数据写入该内存中，当拉取的数据足够大时则会将数据写入文件，文件数量达到一定量级进行归并。\n3.4 关于Combiner Combiner用于处理数据的聚合，但是其只发生在本地的Mapper任务阶段，因此也被称为Map端的Reducer任务。使用Combiner的初衷是为了减少Shuffle过程的数据量，减轻系统的磁盘和网络压力。（Shuffle是一项昂贵的操作）\nHive中提供了另外一种聚合方式——使用散列表，每个Mapper中直接使用散列表进行聚合，而不是另起Combiner聚合任务，这样避免另外起一个任务和额外的数据读写所带来的开销。散列表，可以类比Java中的HashMap。\n 通常使用Map聚合往往是为了减少Map任务的输出，减少传输到下游任务的Shuffle数据量，但如果数据经过聚合后不能明显减少，那无疑就是浪费机器的I/O资源。\n 四、HDFS的基本组成 偷个懒，不想写了\u0026hellip;ಠ╭╮ಠ\n(；´д｀)ゞ\n༼༎ຶᴗ༎ຶ༽\n(′へ`、)\n五、附送：今天下午骑单车去了 双脚一蹬就是13.7公里，骄傲！ㄟ( ▔, ▔ )ㄏ\n","description":"这篇文章很多内容都是直接摘自上午看的《Hive性能调优实战》一书，主要内容是梳理了一下关于Hive、YARN以及MapReduce等知识点。","id":4,"section":"posts","tags":["Hive","Hadoop"],"title":"关于Hive和YARNの读书笔记","uri":"http://blog.langchao2020.tech/posts/helloyarn/"},{"content":"一、求每一年最高气温的那一天以及温度 1.1 数据准备 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  2014010114 2014010216 2014010317 2014010410 2014010506 2012010609 2012010732 2012010812 2012010919 2012011023 2001010116 2001010212 2001010310 2001010411 2001010529 2013010619 2013010722 2013010812 2013010929 2013011023 2008010105 2008010216 2008010337 2008010414 2008010516 2007010619 2007010712 2007010812 2007010999 2007011023 2010010114 2010010216 2010010317 2010010410 2010010506 2015010649 2015010722 2015010812 2015010999 2015011023   数据的含义是：2010012325表示在2010年01月23日的气温为25度。\n建表、导入数据：\n1 2 3  create table tempertrue(data string); load data local inpath \u0026#34;/data/soft/hive-3.2.1/mydata/tempertrue.txt\u0026#34; into table tempertrue;   ※ 1.2 求每一年最高气温的那一天以及温度 首先，先创建一个临时视图，把data分割日期和温度两个字段。\n1 2 3 4 5 6  create view temp as select substr(data, 1, 8) as ttime, substr(data, 9) as tep from tempertrue;   利用开窗函数、substr函数对data分割后分组并排序：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  select ttime, tep from ( select ttime, tep, rank() over( partition by substr(ttime, 1, 4) order by tep desc ) as num from temp ) as t1 where t1.num = 1;   结果：\n1 2 3 4 5 6 7 8 9 10 11 12  +-----------+------+ | ttime | tep | +-----------+------+ | 20010105 | 29 | | 20070109 | 99 | | 20080103 | 37 | | 20100103 | 17 | | 20120107 | 32 | | 20130109 | 29 | | 20140103 | 17 | | 20150109 | 99 | +-----------+------+    关于这题，我的启发是，substr函数可以将表中某个字段列的值分割，然后再利用开窗函数对分割后的子字符串进行分组、排序。分组用的是partition by，排序用的是order by。\n还有，关于临时视图，好像很有用的样子。其实就是一个中间表，引入中间表我想是为了简化SQL语句的编写。\n 二、SQL中常见的几个字符分割函数：   SUBSTR(str, pos, len): 从pos开始的位置，截取len个字符\n  SUBSTR(str, pos): pos开始的位置，一直截取到最后\n  substr(string ,1,3) ：取string左边第1位置起，3字长的字符串。所以结果为： strsubstr(string, -1,3)：取string右边第1位置起，3字长的字符串。显然右边第一位置起往右不够3字长。结果只能是： gsubstr(string, -3,3)：取string右边第3位置起，3字长的字符串。结果为: ing\nHive中在group by查询的时候要求出现在select后面的列都必须是出现在group by后面的，即select列必须是作为分组依据的列\nHive中collect相关的函数有collect_list和collect_set。它们都是将分组中的某列转为一个数组返回，不同的是collect_list不去重而collect_set去重。\n","description":"求每一年最高气温的那一天以及温度","id":5,"section":"posts","tags":["Hive",""],"title":"再来一道SQL题","uri":"http://blog.langchao2020.tech/posts/keep-water-for-hive/"},{"content":"一、Hive中的开窗函数 1.1 关于开窗函数 什么是开窗函数？\n回答这个问题之前先要了解一下什么是聚合函数。聚合函数是SQL的基本函数，其功能是对一组值执行计算，并返回单个值。再说一遍，聚合函数是SQL的基本函数，其功能是对一组值执行计算，并返回单个值。\n常见的聚合函数有：sum()，count()，max()，min()， avg()等，这些聚合函数通常与group by 子句连用，除了count以外，聚合函数忽略空值；\n上面有说到，聚合函数只返回单个值，而开窗函数则可为窗口中的每行都返回一个值。更简单的理解就是，对查询的结果多出一列或者多列，列中可以是聚合值也可以试排序值。\n一般地，开窗函数也叫分析函数，有两类：聚合开窗函数、排序开窗函数。\n另外：\n SQL标准运行将所有的聚合函数用作开窗函数，用OVER关键字区分开窗函数和聚合函数。 聚合函数每组只返回一个值，开窗函数每组（每个窗口）可返回多个值。（上面也有说到过为每行都返回一个值）  1.2 举个不太熟栗子 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  [root@hadoop200m mydata]# more student_score.data 1 zs1 chinese 80 2 zs1 math 90 3 zs1 english 89 4 zs2 chinese 60 5 zs2 math 75 6 zs2 english 80 7 zs3 chinese 79 8 zs3 math 83 9 zs3 english 72 10 zs4 chinese 90 11 zs4 math 76 12 zs4 english 80 13 zs5 chinese 98 14 zs5 math 80 15 zs5 english 70   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  select * from student_score; +-------------------+---------------------+--------------------+----------------------+ | student_score.id | student_score.name | student_score.sub | student_score.score | +-------------------+---------------------+--------------------+----------------------+ | 1 | zs1 | chinese | 80 | | 2 | zs1 | math | 90 | | 3 | zs1 | english | 89 | | 4 | zs2 | chinese | 60 | | 5 | zs2 | math | 75 | | 6 | zs2 | english | 80 | | 7 | zs3 | chinese | 79 | | 8 | zs3 | math | 83 | | 9 | zs3 | english | 72 | | 10 | zs4 | chinese | 90 | | 11 | zs4 | math | 76 | | 12 | zs4 | english | 80 | | 13 | zs5 | chinese | 98 | | 14 | zs5 | math | 80 | | 15 | zs5 | english | 70 | +-------------------+---------------------+--------------------+----------------------+   ※ 需求是：计算出班级中单科排名前三的学生姓名以及成绩信息。\n这题的思路大概是使用开窗函数并按照sub划分窗口，且按照score排序。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  select * from ( select *, row_number() over( partition by sub order by score desc ) as rank from student_score ) as ss where ss.rank \u0026lt;= 3;    row_number()，对数据进行编号，从1开始 over()函数将数据划分到一个窗口内 partition by表示按照字段对数据进行分组 order by对分组内的数据按照某个字段进行排序  得到的结果如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  +--------+----------+----------+-----------+----------+ | ss.id | ss.name | ss.sub | ss.score | ss.rank | +--------+----------+----------+-----------+----------+ | 13 | zs5 | chinese | 98 | 1 | | 10 | zs4 | chinese | 90 | 2 | | 1 | zs1 | chinese | 80 | 3 | | 3 | zs1 | english | 89 | 1 | | 6 | zs2 | english | 80 | 2 | | 12 | zs4 | english | 80 | 3 | | 2 | zs1 | math | 90 | 1 | | 8 | zs3 | math | 83 | 2 | | 14 | zs5 | math | 80 | 3 | +--------+----------+----------+-----------+----------+   其中关于排序（排名先后顺序问题）\n row_number() over() 正常顺序 rank() over() 跳跃排序，有两个第一名时接下来就是第三名（在各个分组内） dense_rank() over() 连续排序，有两个第一名时接下来是二名（在各个分组内）  比如dense_rank() over() 连续排序（个人认为这种还是比较符合实际的情况，并列第一也是第一！）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  +--------+----------+----------+-----------+----------+ | ss.id | ss.name | ss.sub | ss.score | ss.rank | +--------+----------+----------+-----------+----------+ | 13 | zs5 | chinese | 98 | 1 | | 10 | zs4 | chinese | 90 | 2 | | 1 | zs1 | chinese | 80 | 3 | | 3 | zs1 | english | 89 | 1 | | 12 | zs4 | english | 80 | 2 | | 6 | zs2 | english | 80 | 2 | | 9 | zs3 | english | 72 | 3 | | 2 | zs1 | math | 90 | 1 | | 8 | zs3 | math | 83 | 2 | | 14 | zs5 | math | 80 | 3 | +--------+----------+----------+-----------+----------+   总结一下：从写的Hive SQL来看，开窗函数的调用格式为：\n 函数名(列名) over(partition by 列名 order by 列名)。\n 二、几道关于Hive SQL的题 2.1 单月访问次数和总访问次数 数据是这样的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  +-----------------+------------------+------------------+ | t_access.uname | t_access.umonth | t_access.ucount | +-----------------+------------------+------------------+ | A | 2015-01 | 5 | | A | 2015-01 | 15 | | B | 2015-01 | 5 | | A | 2015-01 | 8 | | B | 2015-01 | 25 | | A | 2015-01 | 5 | | A | 2015-02 | 4 | | A | 2015-02 | 6 | | B | 2015-02 | 10 | | B | 2015-02 | 5 | | A | 2015-03 | 16 | | A | 2015-03 | 22 | | B | 2015-03 | 23 | | B | 2015-03 | 10 | | B | 2015-03 | 1 | +-----------------+------------------+------------------+   ※ 需求是：求出每个用户截止到每月为止的最大单月访问次数、累计到该月的总访问次数和当月访问次数。大概长这样：\n1 2 3 4 5 6 7 8 9 10 11  +-----------+------------+------------+--------------+------------+ | t1.uname | t1.umonth | t1.ucount | current_max | total_cnt | +-----------+------------+------------+--------------+------------+ | A | 2015-01 | 33 | 33 | 33 | | A | 2015-02 | 10 | 33 | 43 | | A | 2015-03 | 38 | 38 | 81 | | B | 2015-01 | 30 | 30 | 30 | | B | 2015-02 | 15 | 30 | 45 | | B | 2015-03 | 34 | 34 | 79 | +-----------+------------+------------+--------------+------------+   这题的关键是求出当月的访问次数，然后再使用开窗函数累加截止到本月的总访问次数以及最大访问次数。\n求出当月访问次数，很简单，使用如下命令：\n1 2 3 4 5 6 7 8 9  select uname, umonth, sum(ucount) as ucount from t_access group by uname, umonth;   得到的结果是：\n1 2 3 4 5 6 7 8 9 10 11  +--------+----------+---------+ | uname | umonth | ucount | +--------+----------+---------+ | A | 2015-01 | 33 | | A | 2015-02 | 10 | | A | 2015-03 | 38 | | B | 2015-01 | 30 | | B | 2015-02 | 15 | | B | 2015-03 | 34 | +--------+----------+---------+    紧接着，使用开窗函数累加截止到本月的总访问次数以及最大访问次数。贴上参考SQL：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  select *, max(ucount) over( partition by uname order by umonth ) as current_max, sum(ucount) over( partition by uname order by umonth ) as total_cnt from ( select uname, umonth, sum(ucount) as ucount from t_access group by uname, umonth ) as t1;   2.2 学生课程成绩 数据是这样的：\n1 2 3 4 5 6 7 8 9 10 11  +------------+-------------+----------------+---------------+ | course.id | course.sid | course.course | course.score | +------------+-------------+----------------+---------------+ | 1 | 1 | yuwen | 43 | | 2 | 1 | shuxue | 55 | | 3 | 2 | yuwen | 77 | | 4 | 2 | shuxue | 88 | | 5 | 3 | yuwen | 98 | | 6 | 3 | shuxue | 65 | +------------+-------------+----------------+---------------+   ※ 需求：求所有数学课程成绩大于语文课程成绩的学生的信息，格式如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  +--------+ | a.sid | +--------+ | 1 | | 2 | +--------+ # 为了方便展示，把成绩也贴出来 +--------+-----------+----------+-----------+----------+ | a.sid | a.course | a.score | b.course | b.score | +--------+-----------+----------+-----------+----------+ | 1 | shuxue | 55 | yuwen | 43 | | 2 | shuxue | 88 | yuwen | 77 | +--------+-----------+----------+-----------+----------+   解决的思路：course表先自连接，根据过滤条件筛选出符合要求的记录。参考SQL如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13  select a.sid, a.course, a.score, b.course, b.score from course a join course b on a.sid = b.sid and a.course = \u0026#39;shuxue\u0026#39; and b.course = \u0026#39;yuwen\u0026#39; where a.score \u0026gt; b.score;   另一种解法，使用开窗函数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  select * from ( select sid, sum( case course when \u0026#34;shuxue\u0026#34; then score else 0 end ) as math, sum( case course when \u0026#34;yuwen\u0026#34; then score else 0 end ) as chinese from course group by sid ) as t1 where t1.math \u0026gt; t1.chinese;   三、附送：科普VirtualBox虚拟机网络 3.1 声明几个名词 一般来说诸如VirtualBox、VMwareWorkstation Pro等虚拟机才叫虚拟机。真正的Linux系统是装在虚拟机中的，但是此文为了方便，把虚拟机中的Linux系统称之为“虚拟机”安装虚拟机（VirtualBox、VMwareWorkstation Pro\u0026hellip;）的机器叫主机。特此声明！\n3.2 VirtualBox中常见的网络接入模式  NAT模式 Host-Only 桥接 Internal  3.3 各种网络接入模式详解 【01 NAT模式的特点】：\n 如果主机可以上网，虚拟机可以上网 虚拟机之间不能ping通 虚拟机可以ping通主机（此时ping虚拟机的网关，即是ping主机） 主机不能ping通虚拟机  NAT模式的应用场景：\n 虚拟机只要求可以上网，无其它特殊要求。  NAT模式下的IP样式：\n IP：10.0.2.15 网关：10.0.2.2  【02 Bridged Adapter桥接模式的特点】：\n 如果主机可以上网，虚拟机可以上网 虚拟机之间可以ping通 虚拟机可以ping通主机 主机可以ping通虚拟机  以上四点都基于一个前提：主机可以上网。由此可以引申出一个很重要的结论：\n 如果在同一个局域网下，多台主机里面的虚拟机是可以互相访问的（特点2），因此在一定条件下可以充分利用多台主机的资源，比如硬盘和内存。想到一个不错的利用方式是用来搭建Hadoop集群~\n桥接很形象的解释是，通过主机网卡，架设一条桥，直接连入到网络中。它使得虚拟机能被分配到一个网络中独立的IP，所有网络功能完全和在网络中的真实机器一样。\n 桥接模式的IP样式：\n IP与本机IP在同一网段内（很重要） 网关与本机网关相同  【03 Host-only Adapter模式的特点】：\n 虚拟机不可以上网 虚拟机之间可以ping通 虚拟机可以ping通主机（注意虚拟机与主机通信是通过主机的名为VirtualBox Host-Only Network的网卡，因此ip是该网卡ip 192.168.56.1，而不是你现在正在上网所用的ip） 主机可以ping通虚拟机  桥接模式的应用场景：\n 在主机无法上网的情况下，也可以搭建一个模拟局域网，因为所有的虚拟机之间都是可以互相访问的。  桥接模式的IP样式：\n IP 与本机VirtualBox Host-Only Network的网卡IP在同一网段内（默认192.168.56.*） 网关 本机VirtualBox Host-Only Network的网卡IP（默认192.168.56.1）  稍微引申一下：\n 在本地搭建大数据集群的时候，一般选择NAT模式+Host-Only模式的组合方式进行网络配置。NAT模式允许虚拟机能够访问外网，做一些软件下载、更新等操作；Host-Only模式下的虚拟机与虚拟机之间可以相互访问，因此可以模拟搭建一个模拟局域网。\n 【04 Internal模式的特点】：\n 虚拟机不可以上网 虚拟机之间可以ping通 虚拟机不能ping通主机 主机不能ping通虚拟机  Internal模式的应用场景：\n 与世隔绝。让各台虚拟机处于隔离的局域网内，只让它们相互通信，与外界（包括主机）隔绝；  Internal模式的IP样式:\n ip 169.254.147.9  不得不说，正经人谁选择内网模式啊！\n附送，在CentOS7环境下，几个网卡的配置文件在：/etc/sysconfig/network-scripts文件夹下。\n1 2 3 4 5 6 7 8 9 10 11  [root@hadoop200m network-scripts]# ll total 236 -rw-r--r--. 1 root root 240 Aug 16 13:48 ifcfg-enp0s3 -rw-r--r--. 1 root root 286 Aug 16 14:49 ifcfg-enp0s8 -rw-r--r--. 1 root root 254 Mar 29 2019 ifcfg-lo lrwxrwxrwx. 1 root root 24 Jan 16 2018 ifdown -\u0026gt; ../../../usr/sbin/ifdown -rwxr-xr-x. 1 root root 654 Mar 29 2019 ifdown-bnep -rwxr-xr-x. 1 root root 6532 Mar 29 2019 ifdown-eth -rwxr-xr-x. 1 root root 781 Mar 29 2019 ifdown-ippp -rwxr-xr-x. 1 root root 4540 Mar 29 2019 ifdown-ipv6 ......   其中ifcfg-enp0s3是NAT模式下的网络配置文件，ifcfg-enp0s8是Host-Only模式下的网络配置文件；\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  [root@hadoop200m network-scripts]# more ifcfg-enp0s3 TYPE=Ethernet PROXY_METHOD=none BROWSER_ONLY=no BOOTPROTO=dhcp DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=yes IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_FAILURE_FATAL=no IPV6_ADDR_GEN_MODE=stable-privacy NAME=enp0s3 DEVICE=enp0s3 ONBOOT=yes [root@hadoop200m network-scripts]# more ifcfg-enp0s8 TYPE=Ethernet PROXY_METHOD=none BROWSER_ONLY=no BOOTPROTO=static DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=yes IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_FAILURE_FATAL=no IPV6_ADDR_GEN_MODE=stable-privacy NAME=enp0s8 DEVICE=enp0s8 ONBOOT=yes IPADDR=192.168.56.200 NETMASK=255.255.255.0   ","description":"聚合函数是SQL的基本函数，其功能是对一组值执行计算，并返回单个值。","id":6,"section":"posts","tags":["Hive",""],"title":"请为Hive开扇窗","uri":"http://blog.langchao2020.tech/posts/hive-window-func/"},{"content":"浅谈SQL语句的执行顺序 一、SQL语句执行顺序解析 SQL语句和编程语言的语句有很大的不同，有一点原因在于SQL并不一定是按照你写的SQL语句顺序执行的。因此在写SQL语句的时候很容易出现问题，最主要的问题还是记不住SQL命令，死记硬背效果好像也不是很好。\n需要知道的是，在SQL语句执行的过程中，都会产生一个虚拟表，用来保存SQL语句的执行结果。这些虚拟表对用户来说是透明的，只有最后一步生成的虚拟表才会返回给用户。如果没有再查询中指定某一子句，则将跳过相应的步骤。下面先给出SQL语句的执行顺序，并加以简单的解释。\n1 2 3 4 5 6 7 8 9 10  7) select 8) distinct \u0026lt;select_list\u0026gt; 1) from \u0026lt;left_table\u0026gt; 3) \u0026lt;join_type\u0026gt; join \u0026lt;right_table\u0026gt; 2) on \u0026lt;join_condition\u0026gt; 4) where \u0026lt;where_condition\u0026gt; 5) group by \u0026lt;group_by_list\u0026gt; 6) having \u0026lt;having_condition\u0026gt; 9) order by \u0026lt;order_by_list\u0026gt; 10) limit \u0026lt;limit_number\u0026gt;   1）from：对FROM子句中的左表\u0026lt;left_table\u0026gt;和右表\u0026lt;right_table\u0026gt;执行笛卡儿积（Cartesian product），产生虚拟表VT1。\n2）on： 对虚拟表VT1应用ON筛选，只有那些符合\u0026lt;join_condition\u0026gt;的行才被插入虚拟表VT2中。\n3）join：如果指定了OUTER JOIN（如LEFT OUTER JOIN、RIGHT OUTERJOIN），那么保留表中未匹配的行作为外部行添加到虚拟表VT2中，产生虚拟表VT3。如果FROM子句包含两个以上表，则对上一个连接生成的结果表VT3和下一个表重复执行步骤1）～步骤3），直到处理完所有的表为止。\n 这里出现了两个陌生的名词：“保留表”、“外部行”。\nLEFT OUTER JOIN把左表记为保留表，RIGHT OUTER JOIN把右表记为保留表\u0026hellip;\n一时半会也解释不清这个东西，我自己懂了就好了，先挖个坑，日后再补上具体数据来做详细解释说明。\n 4）where：对虚拟表VT3应用WHERE过滤条件，只有符合\u0026lt;where_condition\u0026gt;的记录才被插入虚拟表VT4中。\n5）group by：根据GROUP BY子句中的列，对VT4中的记录进行分组操作，产生VT5。\n6）having：对虚拟表VT6应用HAVING过滤器，只有符合\u0026lt;having_condition\u0026gt;的记录才被插入虚拟表VT6中。\n7）select：选择指定的列，插入到虚拟表V7中。\n 看到没有，select到第7步才被执行，所以千万别人认为写在第一行的就是第一个被执行的。\n 8）distinct：去除重复数据，产生虚拟表V8。\n9）order by：将虚拟表V8中的记录按照\u0026lt;order_by_list\u0026gt;进行排序操作，产生虚拟表V9。\n ORDER BY 默认是升序排序，如果要指定为降序排序则需要加上 DESC 修饰。\n 10）limit：取出指定行的记录，产生虚拟表V10，并返回给查询用户。\n 值得注意的是：LIMIT n, m 表示从第n条记录开始选择m条记录。少量数据时，使用limit进行分页查询是没有任何问题的，但是对于大量数据而言，LIMIT n, m是很低效的。原因是LIMIT每次都是从头开始扫描，如果要取第100万行开始3条数据的话，就需要先扫描定位到第100万行，然后再取，可见其效率是很低很低的。\n 二、附送：Hive中四个BY的区别 所谓四个BY指的是：\n order by sort by distribute by cluster by  关于order by：\n order by会对输入做全局排序，因此只有一个reducer，然而当只有一个reducer会导致当输入数据规模很大时，消耗较长的计算时间。\n 关于sort by：\n sort by会在数据进入reducer前完成排序，实现的是局部排序。因此，如果用 sort by进行排序并且设置 mapped. reduce. tasks \u0026gt;1，则 sort by只会保证每个 reducer的输出有序，并不保证全局有序。\n所以在使用sort by之前还需要设置reduce的个数：\nset mapreduce.job.reducers=4;\n 关于distribute by：\n distribute by是控制在map端如何拆分数据给 reduce端的。hive会根据 distribute by后面的列，对应 reduce的个数进行分发，默认是采用hash算法。sort by为每个 reduce产生一个排序文件。在有些情况下，你需要控制某个特定行应该到哪个 reducer，这通常是为了进行后续的聚集操作。distribute by刚好可以做这件事。因此， distribute by经常和 sort by配合使用。并且hive规定distribute by 语句要写在sort by语句之前。\n 关于cluster by：\n 当distribute by 和 sort by 所指定的字段相同时，cluster by的效果等同于sort by + distribute by，但是cluster by 指定的列只能是升序，且补鞥呢指定asc和desc。\n 其实本人还有两个疑问，那就是group by和partition by。\ngroup by操作表示按照某些字段的值进行分组，有相同的值放到一起。\npartition by 按照字段对数据进行分组。\n","description":"SQL语句和编程语言的语句有很大的不同，有一点原因在于SQL并不一定是按照你写的SQL语句顺序执行的。","id":7,"section":"posts","tags":["SQL","Hive"],"title":"浅谈SQL语句的执行顺序","uri":"http://blog.langchao2020.tech/posts/sql-execution-sequence/"},{"content":"  一、Hive简介 1.1 什么是Hive Hive官网给出的定义是：“The Apache Hive ™ data warehouse software facilitates reading, writing, and managing large datasets residing in distributed storage using SQL. Structure can be projected onto data already in storage. A command line tool and JDBC driver are provided to connect users to Hive.”\n我粗糙的理解是，Hive是一个类似Hadoop（集群）的客户端，所谓客户端在手天下我有。就好比你拿到了电视的遥控器，想怎么操作电视就怎么操作电视，比如换台。实际上Hive使用的是类似SQL的语句去操作（离线数据分析、数据管理\u0026hellip;）HDFS上的数据，本质是将SQL语句转化成MapReduce作业。\n1.2 为什么要使用Hive Hive的本质是将SQL转化成MapReduce作业，那么直接使用MapReduce不就好了，何必转一个弯呢？因为Hive更方便啊，它是遥控器！MapReduce编程模型还是有一定门槛的，代码量多而且只有map和reduce过程，实现复杂的计算逻辑则难度相当之大。\n而，Hive能够使得不会编程的数据开发人员也具备操作分析HDFS上数据的能力，只要你SQL写的好、写的妙。\n1.3 Hive有什么特点 先说缺点，这样记得更牢固。\n首先，慢，而且不是一般的慢。当然这是对少量数据而言，比如查询十多行的数据需要100秒左右的时间，这哪能忍。\n其次，Hive不太支持记录级别的增删改操作。注意是不太支持，你要是真想用还是可以用的，只是要选择对应的Hive版本。\n最后，Hive不支持事务。它主要是用来做OLAP（联机分析处理）的，而传统数据库是用来做OLTP（联机事务处理）的，这也是它俩的本质区别之一。\n优点，我是记不住，正经人谁记某个东西的优点啊。\n首先，延展性好。传统SQL能做的它也能做，传统SQL不能做的它还是能做。比如Hive支持自定义函数UDF，开发人员可以根据自己的需求来实现自定义函数。\n其次，拥有HDFS的优点。HDFS的优点也算是它的优点，比如横向扩展。比如加机器的时候是不会对Hive造成影响的，连重启服务也不需要。\n最后，良好的容错性。这一点是硬凑的，我理解不到这一层。\n稍微总结一下：Hive只适合用来做海量数据离线统计分析，也是数据仓库实现常用的技术之一。\n二、Hive的架构  用户接口：包括CLI、JDBC等方式（也就是客户端） 元数据MetaStore：Hive通常将元数据信息保存在传统关系型数据库中，如MySQL，但默认是放在Derby数据库中（这种数据库不支持多用户同时访问）。元数据信息包括：库名、表名、表所属的库名、表的列名/分区字段，表的属性（是否为外部表）、表中数据所在的HDFS目录等信息。【由此可见，元数据的重要性不言而喻。】 Driver：包括：解释器、编译器、优化器、执行器。Hive SQL语句从词法分析、语法分析、编译、优化以及查询计划生成，查询计划存储在HDFS上，MapReduce负责调用执行；  解释器：将用户输入的Hive SQL转化成抽象语法树（AST） 编译器：将AST编译成逻辑执行计划 优化器：将逻辑执行计划进行优化 执行器：优化后的逻辑执行计划转换成可以运行的物理执行计划    三、Hive中数据组织方式 3.1 数据组织方式概览 Hive的存储结构包括数据库、表、视图、分区、表数据等。库、表、分区在HDFS上体现的是一个目录,表数据对应的是目录下的文件。\nHive实际并不存储数据，数据都是存放在HDFS上，因此也没有专门的数据存储格式。Hive是读模式，可支持TextFile、SequenceFile、RCFile或者自定义格式。\nHive支持的存储格式如下表所示，其中，ORC 和 Parquet 的综合性能突出，使用较为广泛，推荐使用这两种格式。在创建表的时候可指定其存储格式，使用STORED AS 参数指定。\n   格式 说明     TextFile 存储为纯文本文件。 这是 Hive 默认的文件存储格式。这种存储方式数据不做压缩，磁盘开销大，数据解析开销大。   SequenceFile SequenceFile 是 Hadoop API 提供的一种二进制文件，它将数据以\u0026lt;key,value\u0026gt;的形式序列化到文件中。这种二进制文件内部使用 Hadoop 的标准的 Writable 接口实现序列化和反序列化。它与 Hadoop API 中的 MapFile 是互相兼容的。Hive 中的 SequenceFile 继承自 Hadoop API 的 SequenceFile，不过它的 key 为空，使用 value 存放实际的值，这样是为了避免 MR 在运行 map 阶段进行额外的排序操作。   RCFile RCFile 文件格式是 FaceBook 开源的一种 Hive 的文件存储格式，首先将表分为几个行组，对每个行组内的数据按列存储，每一列的数据都是分开存储。   ORC Files ORC 是在一定程度上扩展了 RCFile，是对 RCFile 的优化。   Avro Files Avro 是一个数据序列化系统，设计用于支持大批量数据交换的应用。它的主要特点有：支持二进制序列化方式，可以便捷，快速地处理大量数据；动态语言友好，Avro 提供的机制使动态语言可以方便地处理 Avro 数据。   Parquet Parquet 是基于 Dremel 的数据模型和算法实现的，面向分析型业务的列式存储格式。它通过按列进行高效压缩和特殊的编码技术，从而在降低存储空间的同时提高了 IO 效率。    Hive的列分隔符默认是不常见字符Ctrl + A，\\x01；\nHive的行分隔符默认是换行符 \u0026lsquo;\\n\u0026rsquo; ；\nHive中包含以下数据类型：\n database table：在HDFS上体现的是一个目录 external table：与table类似，但是其数据存放位置可以指定任意HDFS目录路径 partition：体现为HDFS上table目录的子目录 bucket：在 HDFS 中表现为同一个表目录或者分区目录下根据某个字段的值进行 hash 散 列之后的多个文件 view：与传统数据库类似，只读，基于表创建  3.2 内外部表和分桶表 内部表和外部表的区别：\nHive默认创建的表都是内部表，除非加external关键字修饰变成外部表。\n当删除内部表时，表中数据和表元数据都会被删掉；\n当删除外部表时，只删除表元数据，不删除表中数据；\n内部表外部表使用选择：\n大多数情况下它们的区别不明显，如果数据的所有处理都在Hive中进行，则倾向于选择内部表。但如果是Hive和其它工具要对相同的数据集进行处理，则外部表更合适。\n 每天采集的网站日志和埋点日志数据，在存储的时候建议使用外部表，因为日志数据是采集程序实时采集进来的，一旦被误删，恢复起来非常麻烦。而且外部表方便数据的共享。 抽取过来的业务数据，其实用外部表或者内部表问题都不大，就算被误删，恢复起来也是很快的，如果需要对数据内容和元数据进行紧凑的管理, 那还是建议使用内部表。 在做统计分析时候用到的中间表，结果表建议使用内部表，因为这些数据不需要共享。并且很多时候结果分区表只需要保留最近3天的数据，用外部表的时候删除分区时无法删除数据。  四、如何使用Hive 4.1 科普SQL中的几个概念 SQL：Structure Query Language，即结构化查询语言；\nSQL共分为四大类：\n 数据定义语言 DDL（Data Definition Language） 数据操纵语言 DML（Data Manipulation Language） 数据查询语言 DQL（Data Query Language） 数据控制语言 DCL（Data Control Language）  其中还有一个事务控制语言 TCL （Transaction Control Language）。下面一张图很好的展示了各个层面的操作SQL命令；\n因此，可以简单的概括一下DDL、DML、DQL、DCL。\n  DDL：用来创建数据库中的各种对象——表、视图、索引、同义词、聚簇等\nCREATE TABLE/VIEW/INDEX/SYN/CLUSTER # 值得注意的是，DDL操作是隐性提交的，不能Rollback；   DML：最常见的增删改\nINSERT/UPDATE/DELETE   DQL：基本结构是由SELECT子句，FROM子句，WHERE子句组成的查询块\nSELECT \u0026lt;字段名表\u0026gt; FROM \u0026lt;表或视图名\u0026gt; WHERE \u0026lt;查询条件\u0026gt;   DCL：用来授予或者回收访问数据库的权限，并控制数据库操纵事务发生的时间及效果，对数据库实时监视等。\nGRANT：授权 ROLLBACK [WORK] TO [SAVEPOINT]：回退到某一点 ROLLBACK：回滚，回滚命令使数据库状态回到上次最后提交的状态   4.2 继续科普一下Hive中的数据类型 传统关系型数据库支持的基本数据类型Hive基本都支持，比如TINYINT、SMALLINT、INT、BIGINT、FLOAT、DOUBLE、BOOLEAN、STRING、DATE。另外，Hive还支持另外三种复杂的类型：ARRAY、MAP、STRUCT。\n4.3 Hive中库表的相关操作 库相关的操作如下面所示：\n   描述 命令 备注     创建一个新的数据库myhive create database myhive;    使用新的数据库myhive use myhive;    查看当前正在使用的数据库 select current_database();     表相关操作表格所示：\n  新建一张student表\n1 2 3 4 5 6 7  create table student( id int, name string, sex string, age int, department string ) row format delimited fields terminated by \u0026#34;,\u0026#34;;     从本地往表中加载数据\n1  load data local inpath \u0026#34;/data/soft/mydata/student.txt\u0026#34; into table student;     查看表结构信息\n  1 2 3 4  # 三种方式，其中formatted展示的信息最全 desc student; desc extended student; desc formatted student;   4.4 使用Beeline Hive 内置了 HiveServer 和 HiveServer2 服务，两者都允许客户端使用多种编程语言进行连接，但是 HiveServer 不能处理多个客户端的并发请求，因此产生了 HiveServer2。HiveServer2（HS2）允许远程客户端可以使用各种编程语言向 Hive 提交请求并检索结果，支持多客户端并发访问和身份验证。HS2 是由多个服务组成的单个进程，其包括基于 Thrift 的 Hive 服务（TCP 或 HTTP）和用于 Web UI 的 Jetty Web 服务。\nHiveServer2 拥有自己的 CLI 工具——Beeline。Beeline 是一个基于 SQLLine 的 JDBC 客户端。由于目前 HiveServer2 是 Hive 开发维护的重点，所以官方更加推荐使用 Beeline 而不是 Hive CLI。以下主要讲解 Beeline 的配置方式。\n  首先启动hiverser2：nohup hiveserver2 \u0026amp;\n  然后使用beeline：beeline -u jdbc:hive2://hadoop200m:10000 -n root\n    ","description":"Hive是一个类似Hadoop（集群）的`客户端`，所谓客户端在手天下我有。","id":8,"section":"posts","tags":["Hive"],"title":"Hive认识我的第一天","uri":"http://blog.langchao2020.tech/posts/hive-meeting/"},{"content":"小羊和狼  一只小羊站在屋顶上,自以为没有危险,看见一只狼走过,便开口向他骂起来。狼向上一瞧说:“哼！我已经听见了,但这并不是你在骂我,只是你站着的屋顶在骂我啊！”。\n ","description":".tech域名有助于创建被认为是前瞻性思维的尖端品牌","id":9,"section":"","tags":null,"title":"About","uri":"http://blog.langchao2020.tech/about/"},{"content":"一眨眼就是五个月，整整五个月，你知道我这五个月都是怎么过来的吗？\n迷茫、踌躇、失意、自闭、堕落、颓废、自暴自弃\u0026hellip;\n这注定是一段挥之不去的记忆。\n1 2 3 4 5 6 7  #include\u0026lt;stdio.h\u0026gt;int main() { for (int i = 0; i \u0026lt; 10; i++) { printf(\u0026#34;Hello, World!\u0026#34;); } return 0; }   为什么要使用图床 在hugo中，图片是以/static为基准目录的，例如，设baseUrl为https://focksor.gitee.io/，图片文件存放位置是static/img/gitee/123.jpg，那么，编译完成后页面图片引用的地址就是https://focksor.gitee.io/img/gitee/123.jpg，则在Markdown要引用此图片应该用![图片说明](/img/gitee/123.jpg)，但是这样带来的问题是，在写作的时候无法看到图片，要经过hugo编译之后才能看到文档图片，这样的写作显然是不友好的。\n图床指存储图片的服务器，使用图床存储文档中的图片，那么在使用图片的时候只要写上图片所在的网络地址就好了，这样比较使用静态图片体验显然要好很多。下面介绍Gitee+PicGo的方法来使用gitee作为图床。\n 图床指存储图片的服务器，使用图床存储文档中的图片，那么在使用图片的时候只要写上图片所在的网络地址就好了，这样比较使用静态图片体验显然要好很多。下面介绍Gitee+PicGo的方法来使用gitee作为图床。\n一眨眼就是五个月，整整五个月，你知道我这五个月都是怎么过来的吗？\n ","description":"","id":10,"section":"posts","tags":["",""],"title":"时隔五个月的少年又回来了","uri":"http://blog.langchao2020.tech/posts/%E6%97%B6%E9%9A%94%E4%BA%94%E4%B8%AA%E6%9C%88%E7%9A%84%E5%B0%91%E5%B9%B4%E5%8F%88%E5%9B%9E%E6%9D%A5%E4%BA%86/"},{"content":"★配置项目相关的数据 1.数据库数据 2. SSM框架整合 3. 单元测试   dao层单元测试\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45  package tech.langchao2020.test; import org.junit.Test; import org.junit.runner.RunWith; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.test.context.ContextConfiguration; import org.springframework.test.context.junit4.SpringJUnit4ClassRunner; import tech.langchao2020.xiaomi.dao.ConsumerMapper; import tech.langchao2020.xiaomi.entity.Consumer; import tech.langchao2020.xiaomi.entity.ConsumerExample; import java.util.List; @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration(locations = {\u0026#34;classpath:applicationContext.xml\u0026#34;}) public class DaoTest { @Autowired private ConsumerMapper consumerMapper; @Test public void testConsumerInsert() { // 创建consumer对象  Consumer consumer = new Consumer(\u0026#34;浪花之颠\u0026#34;, \u0026#34;123123\u0026#34;); // 将consumer对象插入到数据库中  consumerMapper.insertSelective(consumer); System.out.println(\u0026#34;Insert操作成功！用户\u0026#34; + consumer.getUsername() + \u0026#34;已添加成功！\u0026#34;); } @Test public void testConsumerSelectById() { Consumer consumer = consumerMapper.selectByPrimaryKey(1); System.out.println(consumer.toString()); } @Test public void testConsumerSelectByExample() { // 创建条件查询【用户+密码】  ConsumerExample ce = new ConsumerExample(); ce.createCriteria().andUsernameEqualTo(\u0026#34;langchao\u0026#34;) .andPasswordEqualTo(\u0026#34;root123\u0026#34;); // 查询结果集  List\u0026lt;Consumer\u0026gt; consumerList = consumerMapper.selectByExample(ce); consumerList.forEach(consumer -\u0026gt; System.out.println(consumer.toString())); } }     4. 业务模型开发 \u0026amp; 响应封装 从简单业务 \u0026mdash;》复杂业务，如从登录、注册\u0026mdash;-》首页数据加载\u0026mdash;-》搜索\u0026mdash;》购物车\u0026mdash;》订单相关\n（1）登录业务\n首先创建用户相关业务处理类：tech.langchao2020.xiaomi.service.ConsumerService.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  package tech.langchao2020.xiaomi.service; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Service; import tech.langchao2020.xiaomi.dao.ConsumerMapper; import tech.langchao2020.xiaomi.entity.Consumer; import tech.langchao2020.xiaomi.entity.ConsumerExample; import java.util.List; @Service public class ConsumerService { @Autowired private ConsumerMapper consumerMapper; public boolean findConsumerWithUsernameAndPassword(Consumer consumer) { // 1. 创建条件查询对象  ConsumerExample ce = new ConsumerExample(); ce.createCriteria().andUsernameEqualTo(consumer.getUsername()) .andPasswordEqualTo(consumer.getPassword()); // 2. 查询数据  List\u0026lt;Consumer\u0026gt; consumerList = consumerMapper.selectByExample(ce); // 3. 返回结果  return consumerList != null \u0026amp;\u0026amp; consumerList.size() == 1; } }   其次，创建用户相关业务访问接口/控制器：tech.langchao2020.xiaomi.controller.ConsumerController.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  package tech.langchao2020.xiaomi.controller; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Controller; import org.springframework.web.bind.annotation.PostMapping; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RequestParam; import tech.langchao2020.xiaomi.entity.Consumer; import tech.langchao2020.xiaomi.service.ConsumerService; @Controller @RequestMapping(\u0026#34;/consumer\u0026#34;) public class ConsumerController { @Autowired private ConsumerService consumerService; @PostMapping(\u0026#34;/login/auth\u0026#34;) public String login(@RequestParam String username, @RequestParam String password) { Consumer consumer = new Consumer(username,password); boolean result = consumerService.findConsumerWithUsernameAndPassword(consumer); return result ? \u0026#34;success\u0026#34; : \u0026#34;error\u0026#34;; } }   针对登录业务进行数据响应封装；\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56  package tech.langchao2020.xiaomi.utils; import java.util.HashMap; import java.util.Map; /** * 响应数据封装 */ public class ResponseMessage { private String errorCode; private String errorMsg; private Map\u0026lt;String, Object\u0026gt; objectmap = new HashMap\u0026lt;\u0026gt;(); public String getErrorCode() { return errorCode; } public void setErrorCode(String errorCode) { this.errorCode = errorCode; } public String getErrorMsg() { return errorMsg; } public void setErrorMsg(String errorMsg) { this.errorMsg = errorMsg; } public Map\u0026lt;String, Object\u0026gt; getObjectmap() { return objectmap; } public void setObjectmap(Map\u0026lt;String, Object\u0026gt; objectmap) { this.objectmap = objectmap; } public ResponseMessage addObject(String key, Object object) { this.objectmap.put(key,object); return this; } public static ResponseMessage success() { ResponseMessage responseMessage = new ResponseMessage(); responseMessage.setErrorCode(\u0026#34;100\u0026#34;); responseMessage.setErrorMsg(\u0026#34;处理成功！\u0026#34;); return responseMessage; } public static ResponseMessage error() { ResponseMessage responseMessage = new ResponseMessage(); responseMessage.setErrorCode(\u0026#34;200\u0026#34;); responseMessage.setErrorMsg(\u0026#34;处理失败！\u0026#34;); return responseMessage; } }   最后，基于Web业务单元测试；\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  package tech.langchao2020.test; import org.junit.Before; import org.junit.Test; import org.junit.runner.RunWith; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.test.context.ContextConfiguration; import org.springframework.test.context.junit4.SpringJUnit4ClassRunner; import org.springframework.test.context.web.WebAppConfiguration; import org.springframework.test.web.servlet.MockMvc; import org.springframework.test.web.servlet.MvcResult; import org.springframework.test.web.servlet.request.MockMvcRequestBuilders; import org.springframework.test.web.servlet.setup.MockMvcBuilders; import org.springframework.web.context.WebApplicationContext; @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration(locations = {\u0026#34;classpath:applicationContext.xml\u0026#34;, \u0026#34;classpath:springMVC.xml\u0026#34;}) @WebAppConfiguration public class WebTest { // 申明一个模拟请求的对象  private MockMvc mockMvc; // 需要一个web容器构建web环境  @Autowired private WebApplicationContext webApplicationContext; @Before public void setUp() throws Exception { mockMvc = MockMvcBuilders.webAppContextSetup(webApplicationContext).build(); } @Test public void testLogin() throws Exception { // 模拟发送请求  MvcResult mvcResult = mockMvc.perform(MockMvcRequestBuilders.post(\u0026#34;/consumer/login/auth\u0026#34;).param(\u0026#34;username\u0026#34;, \u0026#34;langchao\u0026#34;) .param(\u0026#34;password\u0026#34;, \u0026#34;root123\u0026#34;)).andReturn(); System.out.println(mvcResult.getResponse().getContentAsString()); } }   针对登录业务进行数据响应封装之后重构登录业务；\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  package tech.langchao2020.xiaomi.controller; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Controller; import org.springframework.web.bind.annotation.PostMapping; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RequestParam; import org.springframework.web.bind.annotation.ResponseBody; import tech.langchao2020.xiaomi.entity.Consumer; import tech.langchao2020.xiaomi.service.ConsumerService; import tech.langchao2020.xiaomi.utils.ResponseMessage; @Controller @RequestMapping(\u0026#34;/consumer\u0026#34;) public class ConsumerController { @Autowired private ConsumerService consumerService; /** * 序列化操作：将返回的数据封装成json格式（类型转换）jackson --\u0026gt; json * @param username * @param password * @return */ @PostMapping(values=\u0026#34;/login/auth\u0026#34;, produces=\u0026#34;{application/json;charset=UTF-8}\u0026#34;) @ResponseBody public ResponseMessage login(@RequestParam String username, @RequestParam String password) { System.out.println(\u0026#34;接收到请求：/consumer/login/auth\u0026#34;); System.out.println(\u0026#34;账号：\u0026#34; + username + \u0026#34;; 密码\u0026#34; + password); Consumer consumer = new Consumer(username,password); boolean result = consumerService.findConsumerWithUsernameAndPassword(consumer); System.out.println(\u0026#34;登录结果：\u0026#34; + result); return result ? ResponseMessage.success() : ResponseMessage.error(); } }   面对程序报错不要慌；\n★项目前后端整合 1.前端登录处理逻辑 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  \u0026lt;script\u0026gt; $(function () { // 点击登录按钮时,发送ajax请求  $(\u0026#34;#login-btn\u0026#34;).click(function () { // 发送ajax请求  // alert($(\u0026#34;#username\u0026#34;).val()+\u0026#34;:\u0026#34;+$(\u0026#34;#password\u0026#34;).val())  $.ajax({ url: \u0026#34;/consumer/login/auth\u0026#34;, method: \u0026#34;post\u0026#34;, data: { \u0026#34;username\u0026#34;: $(\u0026#34;#username\u0026#34;).val(), \u0026#34;password\u0026#34;: $(\u0026#34;#password\u0026#34;).val() }, success: function (response) { console.log(\u0026#34;请求发送成功\u0026#34;); console.log(response); if (response.errorCode === \u0026#34;100\u0026#34;) { // 登录成功  alert(\u0026#34;恭喜，用户登录成功！\u0026#34;); window.location = \u0026#34;/index.jsp\u0026#34;; } else { // 登录失败  $(\u0026#34;#error-username\u0026#34;).text(\u0026#34;账号或者密码有误，请重新登录\u0026#34;).css({ \u0026#34;color\u0026#34;: \u0026#34;red\u0026#34; }); } }, error: function () { console.log(\u0026#34;请求发送失败..\u0026#34;); } }) }); });   ","description":"在B站上找的一个SSM项目——小米商城，今天主要是把项目的框架搭建好了，并且前后端能够正常通信。SSM整合、配置、MyBatis逆向工程、Ajax、单元测试、响应数据封装...还是能够学到不少东西的。","id":11,"section":"posts","tags":["SSM项目",""],"title":"4.29_SSM项目-小米商城学习笔记","uri":"http://blog.langchao2020.tech/posts/xiaomi/"},{"content":"★MyBatis基础 1.什么是MyBatis？ MyBatis是一个实现了数据持久化的开源框架，这句话的终点是数据持久化。问题来了，什么是数据持久化呢？百度百科给出的解释是：\n “数据持久化就是将内存中的数据模型转换为存储模型，以及将存储模型转换为内存中的数据模型的统称。 数据模型可以是任何数据结构或对象模型,存储模型可以是关系模型、XML、二进制流等。”\n 但是对于现阶段的我这个菜鸟俩说，只需要记得数据持久化就是把数据存到数据库中即可（Java对象模型和关系模型之间的对应）。\n2.如何使用MyBatis？(准备阶段)   创建Maven工程，配置pom.xml相关的依赖\n1 2 3 4 5 6 7 8 9 10 11  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.mybatis\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.5.4\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;8.0.18\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;     在mybatis数据库中新建数据表\n1 2 3 4 5 6  create table t_user( id int primary key auto_increment, username varchar(11), password varchar(11), age int )     在Java代码中创建数据表t_user对应的实体类tech.langchao2020.entity.User\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  public class User { private int id; private String username; private String password; private int age; public int getId() { return id; } public void setId(int id) { this.id = id; } public String getUsername() { return username; } public void setUsername(String username) { this.username = username; } public String getPassword() { return password; } public void setPassword(String password) { this.password = password; } public int getAge() { return age; } public void setAge(int age) { this.age = age; } @Override public String toString() { return \u0026#34;User{\u0026#34; + \u0026#34;id=\u0026#34; + id + \u0026#34;, username=\u0026#39;\u0026#34; + username + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, password=\u0026#39;\u0026#34; + password + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, age=\u0026#34; + age + \u0026#39;}\u0026#39;; } }     添加MyBatis配置文件\\src\\main\\resources\\mybatis-config.xml文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE configuration PUBLIC \u0026#34;-//mybatis.org//DTD Config 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-config.dtd\u0026#34;\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;!-- 配置MyBatis运行环境 --\u0026gt; \u0026lt;environments default=\u0026#34;development\u0026#34;\u0026gt; \u0026lt;environment id=\u0026#34;development\u0026#34;\u0026gt; \u0026lt;!-- 配置JDBC事务管理 --\u0026gt; \u0026lt;transactionManager type=\u0026#34;JDBC\u0026#34;/\u0026gt; \u0026lt;!-- POOLED配置JDBC数据源连接池 --\u0026gt; \u0026lt;dataSource type=\u0026#34;POOLED\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;driver\u0026#34; value=\u0026#34;com.mysql.cj.jdbc.Driver\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;url\u0026#34; value=\u0026#34;jdbc:mysql://120.24.207.216:3306/mybatis?useUnicode=true\u0026amp;amp;characterEncoding=UTF-8\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;username\u0026#34; value=\u0026#34;root\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34; value=\u0026#34;xxxxx\u0026#34;/\u0026gt; \u0026lt;/dataSource\u0026gt; \u0026lt;/environment\u0026gt; \u0026lt;/environments\u0026gt; \u0026lt;/configuration\u0026gt;     3.MyBatis开发的两种方式  使用原生接口 使用Mapper代理实现自定义接口  1.使用原生接口开发 步骤1：在tech.langchao2020.mapper下创建UserMapper.xml文件；namespace通常设置为文件所在包名+文件名，parameterType为参数数据类型，resultType为返回值数据类型。\n1 2 3 4 5 6 7 8 9  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE mapper PUBLIC \u0026#34;-//mybatis.org//DTD Mapper 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-mapper.dtd\u0026#34;\u0026gt; \u0026lt;mapper namespace=\u0026#34;com.southwind.mapper.UserMapper\u0026#34;\u0026gt; \u0026lt;select id=\u0026#34;get\u0026#34; parameterType=\u0026#34;int\u0026#34; resultType=\u0026#34;tech.langchao2020.entity.User\u0026#34;\u0026gt; select * from user where id=#{id} \u0026lt;/select\u0026gt; \u0026lt;/mapper\u0026gt;    namespace 通常设置为⽂文件所在包+⽂文件名的形式。 insert 标签表示执⾏行行添加操作。 select 标签表示执⾏行行查询操作。 update 标签表示执⾏行行更更新操作。 delete 标签表示执⾏行行删除操作。 id 是实际调⽤用 MyBatis ⽅方法时需要⽤用到的参数。 parameterType 是调⽤用对应⽅方法时参数的数据类型。  步骤2：在\\src\\main\\resources\\mybatis-config.xml配置文件中注册UseMapper.xml`文件。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE configuration PUBLIC \u0026#34;-//mybatis.org//DTD Config 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-config.dtd\u0026#34;\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;!-- 配置MyBatis运行环境 --\u0026gt; \u0026lt;environments default=\u0026#34;development\u0026#34;\u0026gt; \u0026lt;environment id=\u0026#34;development\u0026#34;\u0026gt; \u0026lt;!-- 配置JDBC事务管理 --\u0026gt; \u0026lt;transactionManager type=\u0026#34;JDBC\u0026#34;/\u0026gt; \u0026lt;!-- POOLED配置JDBC数据源连接池 --\u0026gt; \u0026lt;dataSource type=\u0026#34;POOLED\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;driver\u0026#34; value=\u0026#34;com.mysql.cj.jdbc.Driver\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;url\u0026#34; value=\u0026#34;jdbc:mysql://120.24.207.216:3306/mybatis?useUnicode=true\u0026amp;amp;characterEncoding=UTF-8\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;username\u0026#34; value=\u0026#34;root\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34; value=\u0026#34;xxxxx\u0026#34;/\u0026gt; \u0026lt;/dataSource\u0026gt; \u0026lt;/environment\u0026gt; \u0026lt;/environments\u0026gt; \u0026lt;mappers\u0026gt; \u0026lt;mapper resource=\u0026#34;tech/langchao2020/mapper/UserMapper.xml\u0026#34;/\u0026gt; \u0026lt;/mappers\u0026gt; \u0026lt;/configuration\u0026gt;   步骤3，在tech.langchao2020.test创建Test类测试。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  package tech.langchao2020.test; import org.apache.ibatis.session.SqlSession; import org.apache.ibatis.session.SqlSessionFactory; import org.apache.ibatis.session.SqlSessionFactoryBuilder; import tech.langchao2020.entity.User; import java.io.InputStream; public class Test { public static void main(String[] args) { //加载MyBatis配置文件  InputStream is = Test.class.getClassLoader().getResourceAsStream(\u0026#34;mybatis-config.xml\u0026#34;); SqlSessionFactoryBuilder sqlSessionFactoryBuilder = new SqlSessionFactoryBuilder(); SqlSessionFactory sqlSessionFactory = sqlSessionFactoryBuilder.build(is); //获取SqlSession  SqlSession sqlSession = sqlSessionFactory.openSession(); //调用MyBatis原生接口执行SQL  //statement为UserMapper.xml的namespace值+\u0026#34;.\u0026#34;+select标签的id值  String statement = \u0026#34;tech.langchao2020.mapper.UserMapper.findById\u0026#34;; User user = sqlSession.selectOne(statement,1); System.out.println(user.toString()); } }   查询的结果为：\n1  User{id=1, username=\u0026#39;浪花之颠\u0026#39;, password=\u0026#39;996.icu\u0026#39;, age=26}   注意！**，Idea集成开发环境不会编译src下的java目录下的xml文件的，所以找不到xml文件，因此需要在pom.xml配置相关build；\n1 2 3 4 5 6 7 8 9 10 11  \u0026lt;build\u0026gt; \u0026lt;resources\u0026gt; \u0026lt;resource\u0026gt; \u0026lt;directory\u0026gt;src/main/java\u0026lt;/directory\u0026gt; \u0026lt;includes\u0026gt; \u0026lt;include\u0026gt;**/*.xml\u0026lt;/include\u0026gt; \u0026lt;/includes\u0026gt; \u0026lt;/resource\u0026gt; \u0026lt;/resources\u0026gt; \u0026lt;/build\u0026gt;   2.使用Mapper代理实现自定义接口 步骤一：自定义接口，定义相关的业务方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  package tech.langchao2020.repository; import tech.langchao2020.entity.User; import java.util.List; public interface UserRepository { // 定义CRUD相关操作  public int save(User user); public int update(User user); public int deleteById(int id); public List\u0026lt;User\u0026gt; findAll(); public User findById(int id); }   步骤二：编写与方法相对应的Mapper.xml文件（其接口方法对应的SQL语句）\nstatement 标签可根据 SQL 执⾏行行的业务选择 insert、delete、update、select；\nMyBatis框架会自动根据规则自动创建接口实现类的代理对象，对应规则如下：\n Mapper.xml 中 namespace 为接口的全类名。 Mapper.xml 中 statement 的 id 为接口中对应的⽅方法名。 Mapper.xml 中 statement 的 parameterType 和接口中对应⽅方法的参数类型⼀一致。 Mapper.xml 中 statement 的 resultType 和接口中对应⽅方法的返回值类型一致。  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE mapper PUBLIC \u0026#34;-//mybatis.org//DTD Mapper 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-mapper.dtd\u0026#34;\u0026gt; \u0026lt;mapper namespace=\u0026#34;tech.langchao2020.repository.UserRepository\u0026#34;\u0026gt; \u0026lt;select id=\u0026#34;save\u0026#34; parameterType=\u0026#34;tech.langchao2020.entity.User\u0026#34; resultType=\u0026#34;int\u0026#34;\u0026gt; insert into t_user (id, username, password, age) values (#{id}, #{username},#{password}, #{age}) \u0026lt;/select\u0026gt; \u0026lt;update id=\u0026#34;update\u0026#34; parameterType=\u0026#34;tech.langchao2020.entity.User\u0026#34;\u0026gt; update t_user set username = #{username},password = #{password},age= #{age} where id = #{id} \u0026lt;/update\u0026gt; \u0026lt;delete id=\u0026#34;deleteById\u0026#34; parameterType=\u0026#34;int\u0026#34;\u0026gt; delete from t_user where id = #{id} \u0026lt;/delete\u0026gt; \u0026lt;select id=\u0026#34;findAll\u0026#34; resultType=\u0026#34;tech.langchao2020.entity.User\u0026#34;\u0026gt; select * from t_user \u0026lt;/select\u0026gt; \u0026lt;select id=\u0026#34;findById\u0026#34; parameterType=\u0026#34;int\u0026#34; resultType=\u0026#34;tech.langchao2020.entity.User\u0026#34;\u0026gt; select * from t_user where id=#{id} \u0026lt;/select\u0026gt; \u0026lt;/mapper\u0026gt;   步骤三：在\\src\\main\\resources\\mybatis-config.xml配置文件中注册UserRepository.xml文件。\n1 2 3 4  \u0026lt;mappers\u0026gt; \u0026lt;mapper resource=\u0026#34;tech/langchao2020/repository/UserRepository.xml\u0026#34;/\u0026gt; \u0026lt;/mappers\u0026gt;   步骤四：在Test类中编写测试程序\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49  package tech.langchao2020.test; import org.apache.ibatis.session.SqlSession; import org.apache.ibatis.session.SqlSessionFactory; import org.apache.ibatis.session.SqlSessionFactoryBuilder; import tech.langchao2020.entity.User; import tech.langchao2020.repository.UserRepository; import java.io.InputStream; import java.util.List; public class Test { public static void main(String[] args) { // 1.使用原生接口  /*//加载MyBatis配置文件 InputStream is = Test.class.getClassLoader().getResourceAsStream(\u0026#34;mybatis-config.xml\u0026#34;); SqlSessionFactoryBuilder sqlSessionFactoryBuilder = new SqlSessionFactoryBuilder(); SqlSessionFactory sqlSessionFactory = sqlSessionFactoryBuilder.build(is); //获取SqlSession SqlSession sqlSession = sqlSessionFactory.openSession(); //调用MyBatis原生接口执行SQL //statement为UserMapper.xml的namespace值+\u0026#34;.\u0026#34;+select标签的id值 String insertSql = \u0026#34;tech.langchao2020.mapper.UserMapper.save\u0026#34;; User user1 = new User(4, \u0026#34;狂野之裤\u0026#34;, \u0026#34;root666\u0026#34;, 21); sqlSession.insert(insertSql,user1); sqlSession.commit(); String statement = \u0026#34;tech.langchao2020.mapper.UserMapper.findById\u0026#34;; User user = sqlSession.selectOne(statement, 3); System.out.println(user.toString());*/ // 2. 使用自定义接口  InputStream is = Test.class.getClassLoader().getResourceAsStream(\u0026#34;mybatis-config.xml\u0026#34;); SqlSessionFactoryBuilder sqlSessionFactoryBuilder = new SqlSessionFactoryBuilder(); SqlSessionFactory sqlSessionFactory = sqlSessionFactoryBuilder.build(is); //获取SqlSession  SqlSession sqlSession = sqlSessionFactory.openSession(); // 获取实现接口的代理对象  UserRepository userRepository = sqlSession.getMapper(UserRepository.class); userRepository.deleteById(3); // System.out.println(userRepository.findById(1).toString());  List\u0026lt;User\u0026gt; list = userRepository.findAll(); for (User user:list) { System.out.println(user.toString()); } sqlSession.commit(); sqlSession.close(); } }   程序输出结果为：\n1 2 3 4  User{id=1, username=\u0026#39;浪花之颠\u0026#39;, password=\u0026#39;996.icu\u0026#39;, age=26} User{id=2, username=\u0026#39;飘过的野牛\u0026#39;, password=\u0026#39;root123\u0026#39;, age=17} User{id=4, username=\u0026#39;狂野之裤\u0026#39;, password=\u0026#39;root666\u0026#39;, age=21}   4.Mapper.xml详解  statement标签：select、update、delete、insert 分别对应查询、修改、删除、添加操作。 parameterType：参数的数据类型（Java程序调用方法所提供的参数）    基本数据类型，通过 id 查询 User\n1 2 3 4  \u0026lt;select id=\u0026#34;findById\u0026#34; parameterType=\u0026#34;int\u0026#34; resultType=\u0026#34;tech.langchao2020.entity.User\u0026#34;\u0026gt; select * from t_user where id=#{id} \u0026lt;/select\u0026gt;     String 类型，通过 username 查询 User\n1 2 3 4  \u0026lt;select id=\u0026#34;findByName\u0026#34; parameterType=\u0026#34;java.lang.String\u0026#34; resultType=\u0026#34;tech.langchao2020.entity.User\u0026#34;\u0026gt; select * from t_user where username=#{username} \u0026lt;/select\u0026gt;     包装类，通过 id 查询 User\n1 2 3 4  \u0026lt;select id=\u0026#34;findById\u0026#34; parameterType=\u0026#34;java.lang.Integer\u0026#34; resultType=\u0026#34;tech.langchao2020.entity.User\u0026#34;\u0026gt; select * from t_user where id=#{id} \u0026lt;/select\u0026gt;     多个参数，通过uesrname 和 age 查询 User\n1 2 3 4  \u0026lt;select id=\u0026#34;findByUsernameAndAge\u0026#34; resultType=\u0026#34;tech.langchao2020.entity.User\u0026#34;\u0026gt; select * from t_user where username=#{arg0} and age=#{arg1} \u0026lt;/select\u0026gt;     Java Bean\n1 2 3 4 5  \u0026lt;update id=\u0026#34;update\u0026#34; parameterType=\u0026#34;tech.langchao2020.entity.User\u0026#34;\u0026gt; update t_user set username = #{username},password = #{password},age = #{age} where id = #{id} \u0026lt;/update\u0026gt;      resultType：结果类型    基本数据类型，统计 User 总数\n1 2 3 4  \u0026lt;select id=\u0026#34;count\u0026#34; resultType=\u0026#34;int\u0026#34;\u0026gt; select count(id) from t_user \u0026lt;/select\u0026gt;     包装类，统计 User 总数\n1 2 3 4  \u0026lt;select id=\u0026#34;count\u0026#34; resultType=\u0026#34;java.lang.Integer\u0026#34;\u0026gt; select count(id) from t_user \u0026lt;/select\u0026gt;     String 类型，通过 id 查询 User 的 username\n1 2 3 4  \u0026lt;select id=\u0026#34;findNameById\u0026#34; resultType=\u0026#34;java.lang.String\u0026#34;\u0026gt; select username from t_user where id=#{id} \u0026lt;/select\u0026gt;     Java Bean\n1 2 3 4  \u0026lt;select id=\u0026#34;findById\u0026#34; parameterType=\u0026#34;int\u0026#34; resultType=\u0026#34;tech.langchao2020.entity.User\u0026#34;\u0026gt; select * from t_user where id=#{id} \u0026lt;/select\u0026gt;     5.级联查询  一对多 多对多  6.逆向工程 MyBatis Generator，简称MBG，是⼀一个专⻔门为 MyBatis 框架开发者定制的代码⽣生成器器，可自动⽣生成\nMyBatis 框架所需的实体类、Mapper 接口、Mapper.xml，⽀支持基本的 CRUD 操作，但是⼀些相对复杂的 SQL 需要开发者自己来完成。\n如何使用逆向工程？ 步骤1：新建Maven工程，添加相关的依赖\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.mybatis\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.4.5\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;8.0.11\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.mybatis.generator\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-generator-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.3.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt;   步骤2：创建MBG配置文件，src/resource/generatorConfig.xml\n jdbcConnection 配置数据库连接信息。 javaModelGenerator 配置 JavaBean 的生成策略。 sqlMapGenerator 配置 SQL 映射⽂文件生成策略。 javaClientGenerator 配置 Mapper 接口的生成策略. table 配置目标数据表（tableName：表名，domainObjectName：JavaBean 类(实体类)名）。  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE generatorConfiguration PUBLIC \u0026#34;-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd\u0026#34;\u0026gt; \u0026lt;generatorConfiguration\u0026gt; \u0026lt;context id=\u0026#34;testTables\u0026#34; targetRuntime=\u0026#34;MyBatis3\u0026#34;\u0026gt; \u0026lt;jdbcConnection driverClass=\u0026#34;com.mysql.cj.jdbc.Driver\u0026#34; connectionURL=\u0026#34;jdbc:mysql://120.24.207.216:3306/mybatis?useUnicode=true\u0026amp;amp;characterEncoding=UTF-8\u0026#34; userId=\u0026#34;root\u0026#34; password=\u0026#34;xxxxx\u0026#34;/\u0026gt; \u0026lt;javaModelGenerator targetPackage=\u0026#34;tech.langchao2020.entity\u0026#34; targetProject=\u0026#34;./src/main/java\u0026#34;/\u0026gt; \u0026lt;sqlMapGenerator targetPackage=\u0026#34;tech.langchao2020.repository\u0026#34; targetProject=\u0026#34;./src/main/java\u0026#34;/\u0026gt; \u0026lt;javaClientGenerator type=\u0026#34;XMLMAPPER\u0026#34; targetPackage=\u0026#34;tech.langchao2020.repository\u0026#34; targetProject=\u0026#34;./src/main/java\u0026#34;\u0026gt;\u0026lt;/javaClientGenerator\u0026gt; \u0026lt;table tableName=\u0026#34;t_user\u0026#34; domainObjectName=\u0026#34;User\u0026#34;/\u0026gt; \u0026lt;/context\u0026gt; \u0026lt;/generatorConfiguration\u0026gt;   步骤3：创建Test程序测试\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51  package tech.langchao2020.test; import org.mybatis.generator.api.MyBatisGenerator; import org.mybatis.generator.config.Configuration; import org.mybatis.generator.config.xml.ConfigurationParser; import org.mybatis.generator.exception.InvalidConfigurationException; import org.mybatis.generator.exception.XMLParserException; import org.mybatis.generator.internal.DefaultShellCallback; import java.io.File; import java.io.IOException; import java.sql.SQLException; import java.util.ArrayList; import java.util.List; public class Test { public static void main(String[] args) { List\u0026lt;String\u0026gt; warings = new ArrayList\u0026lt;String\u0026gt;(); boolean overwrite = true; String genCig = \u0026#34;/generatorConfig.xml\u0026#34;; File configFile = new File(Test.class.getResource(genCig).getFile()); ConfigurationParser configurationParser = new ConfigurationParser(warings); Configuration configuration = null; try { configuration = configurationParser.parseConfiguration(configFile); } catch (IOException e) { e.printStackTrace(); } catch (XMLParserException e) { e.printStackTrace(); } DefaultShellCallback callback = new DefaultShellCallback(overwrite); MyBatisGenerator myBatisGenerator = null; try { myBatisGenerator = new MyBatisGenerator(configuration, callback, warings); } catch (InvalidConfigurationException e) { e.printStackTrace(); } try { myBatisGenerator.generate(null); } catch (SQLException e) { e.printStackTrace(); } catch (IOException e) { e.printStackTrace(); } catch (InterruptedException e) { e.printStackTrace(); } } }   7.延迟加载 8.缓存 9.动态SQL (7、8、9条日后有空填坑。)\n","description":"今天还是学的MyBatis框架，主要是学习了如何使用Mapper代理实现自定义接口以及逆向工程。","id":12,"section":"posts","tags":["JavaWeb",""],"title":"4.28_MyBatis（补充版）","uri":"http://blog.langchao2020.tech/posts/mybatis-02/"},{"content":"★MyBatis基础 1.什么是MyBatis？ MyBatis是一个实现了数据持久化的开源框架，这句话的终点是数据持久化。问题来了，什么是数据持久化呢？百度百科给出的解释是：\n “数据持久化就是将内存中的数据模型转换为存储模型，以及将存储模型转换为内存中的数据模型的统称。 数据模型可以是任何数据结构或对象模型,存储模型可以是关系模型、XML、二进制流等。”\n 但是对于现阶段的我这个菜鸟俩说，只需要记得数据持久化就是把数据存到数据库中即可（Java对象模型和关系模型之间的对应）。\n2.如何使用MyBatis？(准备阶段)   创建Maven工程，配置pom.xml相关的依赖\n1 2 3 4 5 6 7 8 9 10 11  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.mybatis\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.5.4\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;8.0.18\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;     在mybatis数据库中新建数据表\n1 2 3 4 5 6  create table t_user( id int primary key auto_increment, username varchar(11), password varchar(11), age int )     在Java代码中创建数据表t_user对应的实体类tech.langchao2020.entity.User\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  public class User { private int id; private String username; private String password; private int age; public int getId() { return id; } public void setId(int id) { this.id = id; } public String getUsername() { return username; } public void setUsername(String username) { this.username = username; } public String getPassword() { return password; } public void setPassword(String password) { this.password = password; } public int getAge() { return age; } public void setAge(int age) { this.age = age; } @Override public String toString() { return \u0026#34;User{\u0026#34; + \u0026#34;id=\u0026#34; + id + \u0026#34;, username=\u0026#39;\u0026#34; + username + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, password=\u0026#39;\u0026#34; + password + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, age=\u0026#34; + age + \u0026#39;}\u0026#39;; } }     添加MyBatis配置文件\\src\\main\\resources\\mybatis-config.xml文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE configuration PUBLIC \u0026#34;-//mybatis.org//DTD Config 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-config.dtd\u0026#34;\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;!-- 配置MyBatis运行环境 --\u0026gt; \u0026lt;environments default=\u0026#34;development\u0026#34;\u0026gt; \u0026lt;environment id=\u0026#34;development\u0026#34;\u0026gt; \u0026lt;!-- 配置JDBC事务管理 --\u0026gt; \u0026lt;transactionManager type=\u0026#34;JDBC\u0026#34;/\u0026gt; \u0026lt;!-- POOLED配置JDBC数据源连接池 --\u0026gt; \u0026lt;dataSource type=\u0026#34;POOLED\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;driver\u0026#34; value=\u0026#34;com.mysql.cj.jdbc.Driver\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;url\u0026#34; value=\u0026#34;jdbc:mysql://120.24.207.216:3306/mybatis?useUnicode=true\u0026amp;amp;characterEncoding=UTF-8\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;username\u0026#34; value=\u0026#34;root\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34; value=\u0026#34;xxxxx\u0026#34;/\u0026gt; \u0026lt;/dataSource\u0026gt; \u0026lt;/environment\u0026gt; \u0026lt;/environments\u0026gt; \u0026lt;/configuration\u0026gt;     3.MyBatis开发的两种方式  使用原生接口 使用Mapper代理实现自定义接口  1.使用原生接口开发 步骤1：在tech.langchao2020.mapper下创建UserMapper.xml文件；namespace通常设置为文件所在包名+文件名，parameterType为参数数据类型，resultType为返回值数据类型。\n1 2 3 4 5 6 7 8 9  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE mapper PUBLIC \u0026#34;-//mybatis.org//DTD Mapper 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-mapper.dtd\u0026#34;\u0026gt; \u0026lt;mapper namespace=\u0026#34;com.southwind.mapper.UserMapper\u0026#34;\u0026gt; \u0026lt;select id=\u0026#34;get\u0026#34; parameterType=\u0026#34;int\u0026#34; resultType=\u0026#34;tech.langchao2020.entity.User\u0026#34;\u0026gt; select * from user where id=#{id} \u0026lt;/select\u0026gt; \u0026lt;/mapper\u0026gt;   步骤2：在\\src\\main\\resources\\mybatis-config.xml配置文件中注册UseMapper.xml`文件。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE configuration PUBLIC \u0026#34;-//mybatis.org//DTD Config 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-config.dtd\u0026#34;\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;!-- 配置MyBatis运行环境 --\u0026gt; \u0026lt;environments default=\u0026#34;development\u0026#34;\u0026gt; \u0026lt;environment id=\u0026#34;development\u0026#34;\u0026gt; \u0026lt;!-- 配置JDBC事务管理 --\u0026gt; \u0026lt;transactionManager type=\u0026#34;JDBC\u0026#34;/\u0026gt; \u0026lt;!-- POOLED配置JDBC数据源连接池 --\u0026gt; \u0026lt;dataSource type=\u0026#34;POOLED\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;driver\u0026#34; value=\u0026#34;com.mysql.cj.jdbc.Driver\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;url\u0026#34; value=\u0026#34;jdbc:mysql://120.24.207.216:3306/mybatis?useUnicode=true\u0026amp;amp;characterEncoding=UTF-8\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;username\u0026#34; value=\u0026#34;root\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34; value=\u0026#34;xxxxx\u0026#34;/\u0026gt; \u0026lt;/dataSource\u0026gt; \u0026lt;/environment\u0026gt; \u0026lt;/environments\u0026gt; \u0026lt;mappers\u0026gt; \u0026lt;mapper resource=\u0026#34;tech/langchao2020/mapper/UserMapper.xml\u0026#34;/\u0026gt; \u0026lt;/mappers\u0026gt; \u0026lt;/configuration\u0026gt;   步骤3，在tech.langchao2020.test创建Test类测试。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  package tech.langchao2020.test; import org.apache.ibatis.session.SqlSession; import org.apache.ibatis.session.SqlSessionFactory; import org.apache.ibatis.session.SqlSessionFactoryBuilder; import tech.langchao2020.entity.User; import java.io.InputStream; public class Test { public static void main(String[] args) { //加载MyBatis配置文件  InputStream is = Test.class.getClassLoader().getResourceAsStream(\u0026#34;mybatis-config.xml\u0026#34;); SqlSessionFactoryBuilder sqlSessionFactoryBuilder = new SqlSessionFactoryBuilder(); SqlSessionFactory sqlSessionFactory = sqlSessionFactoryBuilder.build(is); //获取SqlSession  SqlSession sqlSession = sqlSessionFactory.openSession(); //调用MyBatis原生接口执行SQL  //statement为UserMapper.xml的namespace值+\u0026#34;.\u0026#34;+select标签的id值  String statement = \u0026#34;tech.langchao2020.mapper.UserMapper.findById\u0026#34;; User user = sqlSession.selectOne(statement,1); System.out.println(user.toString()); } }   查询的结果为：\n1  User{id=1, username=\u0026#39;浪花之颠\u0026#39;, password=\u0026#39;996.icu\u0026#39;, age=26}   注意！**，Idea集成开发环境不会编译src下的java目录下的xml文件的，所以找不到xml文件，因此需要在pom.xml配置相关build；\n1 2 3 4 5 6 7 8 9 10  \u0026lt;build\u0026gt; \u0026lt;resources\u0026gt; \u0026lt;resource\u0026gt; \u0026lt;directory\u0026gt;src/main/java\u0026lt;/directory\u0026gt; \u0026lt;includes\u0026gt; \u0026lt;include\u0026gt;**/*.xml\u0026lt;/include\u0026gt; \u0026lt;/includes\u0026gt; \u0026lt;/resource\u0026gt; \u0026lt;/resources\u0026gt; \u0026lt;/build\u0026gt;   4.使用Mapper代理实现自定义接口 ","description":"今日学习了一点点MyBatis的相关知识，仅限于如何使用等最基本的操作。关于前几天的图书管理Java Web项目想停下来思考会儿，于是转来学习MyBatis了，算是给自己调剂调剂口味...","id":13,"section":"posts","tags":["JavaWeb",""],"title":"4.27_Mybatis基础学习","uri":"http://blog.langchao2020.tech/posts/mybatis-study/"},{"content":"★MVC开发模式 MVC是将程序分层的一种开发思想。\n  M：Model\t业务数据（service、repository、entity）\n  V：View\t试图（JSP、HTML、客户端等）\n  C：Controller\t控制（Servlet、Handler、Action）\n  请求进入Java Web应用后，Controller接收到该请求，进行业务逻辑的处理，最终将处理的结果（View+Model）再返回给用户；\n请求进入Controller，调用Service进行业务处理，从Controller中将Model数据带到View中并响应给用户；\nController\t\u0026ndash;\u0026gt;\tService\t\u0026ndash;\u0026gt;\trepository。\n★登录功能 ◇1.读者登录  在reader表中查询该读者账号密码是否正确，如果正确则跳转读者首页，失败则重定向到登录页面；  ◇2.管理员登录  在bookadmin表中查询该读者账号密码是否正确，如果正确则跳转读者首页，失败则重定向到登录页面；  ★分页功能 ","description":"打算找两个Java项目做，第一个是JSP版本的，用来巩固最近学的Java Web基础。另一个是SSM版的，用来巩固上周学习的Spring、Spring MVC以及MyBatis。总感觉自己还没有全力以赴，时间管理上还是很有欠缺，每天可供利用的有效时间很少很少...","id":14,"section":"posts","tags":["",""],"title":"4.26_基础版图书管理系统(使用最纯粹的Java Web开发方式)","uri":"http://blog.langchao2020.tech/posts/book-manage-system/"},{"content":"★JSTL详解 JSP标准标签库，JSP为开发者提供的一些列的标签；使用这些标签可以完成一些逻辑处理，比如循环遍历集合，让代码更加简洁，不会再出现JSP脚本穿插的情况；算是在EL表达式上又再一次简化了JSP的开发。\n实际开发中EL表达式和JSTL结合使用，EL通常用来展示数据，逻辑处理用JSTL；\nJSTL的使用   导入jstl.jar和standard.jar包，放在WEB-INF/lib下\n  在JSP页面开始的地方导入JSPL标签库\n1  \u0026lt;%@ taglib prefix=\u0026#34;c\u0026#34; uri=\u0026#34;http://java.sun.com/jsp/jstl/core\u0026#34; %\u0026gt;     使用\n\u0026lt;c:forEach items=\u0026quot;${list}\u0026quot; var=\u0026quot;user\u0026quot;\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;${user.id}\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;${user.name}\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;${user.score}\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;${user.address.value}\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/c:forEach\u0026gt;   JSTL优点  提供了统一的标签 可以编写各种动态功能  JSTL常用标签 set、out、remove、catch\n  set 向域对象中添加数据\n\u0026lt;c:set var=\u0026quot;name\u0026quot; scope=\u0026quot;request\u0026quot; value=\u0026quot;langchao\u0026quot;\u0026gt;\u0026lt;/c:set\u0026gt; ${requestScope.name}   out 输出域对象中的数据（如果属性不存在时可以默认输出）\n\u0026lt;c:set var=\u0026quot;name\u0026quot; scope=\u0026quot;request\u0026quot; value=\u0026quot;langchao\u0026quot;\u0026gt;\u0026lt;/c:set\u0026gt; \u0026lt;c:out value=\u0026quot;${name}\u0026quot; default=\u0026quot;未定义\u0026quot;\u0026gt;\u0026lt;/c:out\u0026gt;   remove 移除域对象中的数据\n\u0026lt;c:remove var=\u0026quot;name\u0026quot; scope=\u0026quot;page\u0026quot;\u0026gt;\u0026lt;/c:set\u0026gt; \u0026lt;c:out value=\u0026quot;${name}\u0026quot; default=\u0026quot;未定义\u0026quot;\u0026gt;\u0026lt;/c:out\u0026gt;   catch 处理异常信息\n\u0026lt;c:catch var=\u0026quot;error\u0026quot;\u0026gt; \u0026lt;% int a = 10 / 0; %\u0026gt; \u0026lt;/c:catch\u0026gt; ${error}   ★JDBC JDBC是什么？ Java DataBase Connectivity是一个独立于特定数据库的管理系统，是通用的SQL数据库存取和操作的公共接口；定义了一组标准，为访问不同的数据库提供了统一的途径；\nJDBC体系结构  面向应用的API（供开发者调用） 面向数据库API（供数据库厂商开发驱动程序）   JDBC API 提供者: Java 官方\n内容:供开发者调用的接口\njava.sq| 和javax.sql\n DriverManager 类 Connection 接口 Statement 接口 ResultSet 接口  DriverManager 提供者: Java官方\n作用：管理不同的JDBC驱动（比如MySQL、Oracle、Redis等）\nJDBC驱动\n提供者：数据库厂商\n作用：负责连接不同的数据库\nJDBC的使用  加载数据库驱动，该驱动是Java程序和数据库之间的桥梁； 获取Connection，表示Java程序与数据库的一次连接； 创建Statement对象，由Connection产生，用来执行SQL语句； 如果需要接受返回值，则创建ResulSet对象，保存Statement执行之后所查询到的结果；  增删改用的是statement对象的executeUpdate方法，查询使用的是executeQuery方法；\n案例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  try { // 1、加载数据库驱动(通过反射加载)  Class.forName(\u0026#34;com.mysql.cj.jdbc.Driver\u0026#34;); // 2、获取连接  String url = \u0026#34;jdbc:mysql://localhost:3306/library?useUnicode=true\u0026amp;characterEncoding=UTF-8\u0026#34;; String user = \u0026#34;root\u0026#34;; String password = \u0026#34;123123\u0026#34;; Connection connection = DriverManager.getConnection(url, user, password); // System.out.println(connection);  // 3、创建相关的SQL语句,并使用statement对象的相关方法执行  String sql = \u0026#34;INSERT INTO book(name, author, publish) values(\u0026#39;算法导论\u0026#39;,\u0026#39;大牛\u0026#39;,\u0026#39;机械工业出版社\u0026#39;)\u0026#34;; // String sql = \u0026#34;UPDATE book SET author=\u0026#39;路过的萌牛\u0026#39;\u0026#34;;  Statement statement = connection.createStatement(); statement.executeUpdate(sql); // 使用PreparedStatement(Statement的子类),其提供了占位符功能  String find = \u0026#34;SELECT * FROM book WHERE publish = ?\u0026#34;; String publishTest = \u0026#34;三联出版社\u0026#34;; PreparedStatement preparedStatement = connection.prepareStatement(find); preparedStatement.setString(1, publishTest); ResultSet resultSet = preparedStatement.executeQuery(); // 拿出Result中的数据  while (resultSet.next()) { int id = resultSet.getInt(\u0026#34;id\u0026#34;); String name = resultSet.getString(2); String author = resultSet.getString(\u0026#34;author\u0026#34;); String publish = resultSet.getString(4); System.out.println(id + \u0026#34;\\t\u0026#34; + name + \u0026#34;\\t\u0026#34; + author + \u0026#34;\\t\u0026#34; + publish); } } catch (ClassNotFoundException e) { e.printStackTrace(); } catch (SQLException e) { e.printStackTrace(); }   从数据库中取出的数据如下：\n1 2 3 4  11\t水浒传\t路过的萌牛\t三联出版社 12\t三国演义\t路过的萌牛\t三联出版社 13\t红楼梦\t路过的萌牛\t三联出版社 14\t西游记\t路过的萌牛\t三联出版社     开发中使用PreparedStatement（是Statement的子类）\n 提供了SQL占位符的功能\n   使用Statement进行开发的两大问题\n 需要频繁拼接String字符串，出错率较高 存在SQL注入风险    ★Web综合案例 ◇1.测试数据库是否连接成功 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  /** * 测试是否能够成功连接数据库 * 1.加载驱动 * 2.创建连接 * 3.PreparedStatement执行相关语句 */ public class Test { public static void main(String[] args) { try { Class.forName(\u0026#34;com.mysql.cj.jdbc.Driver\u0026#34;); String url = \u0026#34;jdbc:mysql://127.0.0.1:3306/library?useUnicode=true\u0026amp;characterEncoding=UTF-8\u0026#34;; String user = \u0026#34;root\u0026#34;; String password = \u0026#34;root123456\u0026#34;; Connection connection = DriverManager.getConnection(url, user, password); String sql = \u0026#34;SELECT * FROM book WHERE publish = ?\u0026#34;; PreparedStatement preparedStatement = connection.prepareStatement(sql); preparedStatement.setString(1, \u0026#34;三联出版社\u0026#34;); // 获取查询结果  ResultSet resultSet = preparedStatement.executeQuery(); while (resultSet.next()) { Integer id = resultSet.getInt(1); String name = resultSet.getString(\u0026#34;name\u0026#34;); String publish = resultSet.getString(\u0026#34;publish\u0026#34;); System.out.println(id + \u0026#34;-\u0026#34; + name + \u0026#34;-\u0026#34; + publish); } } catch (ClassNotFoundException e) { e.printStackTrace(); } catch (SQLException e) { e.printStackTrace(); } } }   ◇2.实现增删改查操作   Servlet+JSP+JDBC\n  使用过滤器Filter处理中文乱码问题\n  数据库的连接封装成JDBCTools类\n  ★数据库连接池C3P0 ◇1.C3P0概述 C3P0是为优化Java程序连接（Connection）数据库而产生，传统JDBC操作数据库（如执行一次查询操作就需要拿到一个connection对象（由DriverManger产生），但是查询完了之后就释放掉了，资源没有得到很好的利用）。如果放大操作次数，比如查询5000次，就得产生5000个连接并且每次用完就得释放掉。于是C3P0应运而生，它是一个数据库连接池，提前将若干个连接放到数据库连接池，Java程序需要用到的时候直接从数据库连接池中取，用完之后也不释放，继续还到连接池中，连接资源得到了很好的复用。\n◇2.使用C3P0的两种方式   在Java程序中使用(需要引入c3p0第三方包)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  // 创建C3P0 ComboPooledDataSource dataSource = new ComboPooledDataSource(); try { dataSource.setDriverClass(\u0026#34;com.mysql.cj.jdbc.Driver\u0026#34;); dataSource.setJdbcUrl(\u0026#34;jdbc:mysql://localhost:3306/library?useUnicode=true\u0026amp;character=UTF-8\u0026#34;); dataSource.setUser(\u0026#34;root\u0026#34;); dataSource.setPassword(\u0026#34;root123456\u0026#34;); // 获取连接  Connection connection = dataSource.getConnection(); // 设置若干连接池配置信息....  // 若干操作....  String sql = \u0026#34;SELECT * FROM book WHERE publish = ?\u0026#34;; PreparedStatement preparedStatement = connection.prepareStatement(sql); preparedStatement.setString(1, \u0026#34;三联出版社\u0026#34;); // 获取查询结果  ResultSet resultSet = preparedStatement.executeQuery(); while (resultSet.next()) { Integer id = resultSet.getInt(1); String name = resultSet.getString(\u0026#34;name\u0026#34;); String publish = resultSet.getString(\u0026#34;publish\u0026#34;); System.out.println(id + \u0026#34;-\u0026#34; + name + \u0026#34;-\u0026#34; + publish); } // 还回到数据库连接池中  connection.close(); } catch (PropertyVetoException e) { e.printStackTrace(); } catch (SQLException e) { e.printStackTrace(); }     在c3p0-config.xml文件中配置数据库连接池的相关信息(配置文件名必须是c3p0-config.xml且必须是在src根目录下)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  \u0026lt;c3p0-config\u0026gt; \u0026lt;named-config name=\u0026#34;otherc3p0\u0026#34;\u0026gt; \u0026lt;!-- 连接参数 --\u0026gt; \u0026lt;property name=\u0026#34;driverClass\u0026#34;\u0026gt;com.mysql.cj.jdbc.Driver\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;jdbcUrl\u0026#34;\u0026gt;jdbc:mysql://localhost:3306/library?useUnicode=true\u0026amp;amp;character=UTF-8\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;user\u0026#34;\u0026gt;root\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34;\u0026gt;root123456\u0026lt;/property\u0026gt; \u0026lt;!-- 连接池参数 --\u0026gt; \u0026lt;property name=\u0026#34;initialPoolSize\u0026#34;\u0026gt;5\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;maxPoolSize\u0026#34;\u0026gt;8\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;checkoutTimeout\u0026#34;\u0026gt;1000\u0026lt;/property\u0026gt; \u0026lt;/named-config\u0026gt; \u0026lt;/c3p0-config\u0026gt;   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  // 创建C3P0 (otherc3p0对应c3p0-config.xml文件中的name属性值) ComboPooledDataSource dataSource = new ComboPooledDataSource(\u0026#34;otherc3p0\u0026#34;); try { // 获取连接  Connection connection = dataSource.getConnection(); // 若干操作....  String sql = \u0026#34;SELECT * FROM book WHERE publish = ?\u0026#34;; PreparedStatement preparedStatement = connection.prepareStatement(sql); preparedStatement.setString(1, \u0026#34;三联出版社\u0026#34;); // 获取查询结果  ResultSet resultSet = preparedStatement.executeQuery(); while (resultSet.next()) { Integer id = resultSet.getInt(1); String name = resultSet.getString(\u0026#34;name\u0026#34;); String publish = resultSet.getString(\u0026#34;publish\u0026#34;); System.out.println(id + \u0026#34;-\u0026#34; + name + \u0026#34;-\u0026#34; + publish); } // 还回到数据库连接池中  connection.close(); } catch (SQLException e) { e.printStackTrace(); }     ★Windows10安装Ubuntu18.04 LTS子系统 1.如何安装Linux子系统 2.安装成功后相应的设置  设置root密码 更换国内阿里软件源 更新系统 安装并启用ssh服务 安装MySQL等常用软件 配置IP地址  ","description":"今天主要学习的是JSTL标签库和JDBC相关知识。正如昨天所说，肯定会有更好的东西取代EL表达式的，JSTL就是如此。JDBC提供了一组标准接口去访问数据库，C3P0对数据库连接做了优化，由此而来数据库连接池...","id":15,"section":"posts","tags":["JavaWeb",""],"title":"4.25_JSTL和JDBC的学习","uri":"http://blog.langchao2020.tech/posts/jstl-jdbc-study/"},{"content":"★HTTP请求状态码  200 正常 404 资源找不到 400 请求类型不匹配 500 Java程序抛出异常  response常用方法 转发 getRequestDispatcher 和重定向 sendRedirect 的区别\n转发是指将同一个请求传给下一个页面，重定向是创建新的请求（客户端重新请求）传给下一个页面，之前的请求结束生命周期；\n转发：同一个请求在服务器内部传递，浏览器地址栏不变，也叫做服务器跳转；\n重定向：由客户端发送新的请求，访问跳转后的新的资源，浏览器地址栏改变，也叫客户端跳转；\n如果服务器两个页面之间需要通过request传值，则必须使用转发，不能使用重定向；\n sendRedirect(String path) 重定向，完成页面之间的跳转 使用转发和重定向完成一个登录的demo，如果用户名和密码有一个不对，就重定向到登录页面，如果都正确就返回欢迎页面，并带上用户名；  ★Session和Cookie 服务器无法识别http请求来自哪个终端，只会接收到请求信号，http是无状态协议。因此就产生了会话技术，session就是其中的一种技术；\n会话：客户端和服务器之间发生的一系列连续的请求和响应的过程；\n会话状态：服务器和浏览器在会话过程中产生的状态信息\n实现会话的两种方式：\n session cookie（作用在客户端，如浏览器）  属于同一个会话的请求都有同一个请求标识符——sessionID；\n1  String sessionId = seesion.getId(); // 获取会话的id   session常用方法  String getId()\t获取sessionID void setMaxInactiveInterval() 设置session的失效时间，单位为秒 int getMaxInactiveInterval() 获取当前session的失效时间 void invalidate() 设置session立即失效 void setAttribute() 通过键值对存储数据 通过key获取对应的value值 void removeAttribute(String name) 通过key删除对应的value值  使用session完成一个登录跳转页面；\nCookie 创建cookie\n1 2 3  // 创建cookie并响应到客户端 Cookie cookie = new Cookie(\u0026#34;name\u0026#34;, \u0026#34;langchao\u0026#34;); response.addCookie(cookie);   读取cookie\n1 2 3 4 5  Cookie[] cookies = request.getCookies(); for (Cookie cookie:cookies) { // out.write(cookie.toString());  out.write(cookie.getName()+\u0026#34;:\u0026#34;+cookie.getValue() + \u0026#34;\u0026lt;br /\u0026gt;\u0026#34;); }   Cookie常用方法    方法名 描述     setMaxAge(int age) 设置Cookie的有效时间，单位为秒   getMaxAge(int age) 获取Cookie的有效时间，单位为秒   getName() 获取Cookie的name   getValue() 获取Cookie的value    Session 和 Cookie的区别 session：保存在服务器（jvm中），保存的类型是Object类型，会随着会话的结束而销毁，保存重要信息（如账户和密码）；\ncookie：保存在浏览器中，保存的数据是String类型，可以长期保存在浏览器汇总，与会话无关；保存并不是很重要的信息（如你在网站观看视频的进度信息）；\n使用cookie完成一个登录跳转页面；\n存储用户信息：\nsession：setAttribute(name, \u0026ldquo;admin\u0026rdquo;) 存\ngetAttribute(name) 取\n退出登录：session.invalidate()\n生命周期：Web服务器一关闭/重启就被销毁，客户端一关闭也会被销毁；\ncookie：response.addCookie(name, \u0026ldquo;admin\u0026rdquo;) 存\n1 2 3 4 5 6 7  // 取到cookie Cookie[] cookies = request.getCookies(); for (Cookie cookie:cookies) { if (cookie.getName().equals(\u0026#34;name\u0026#34;)) { out.write(\u0026#34;Welcome\u0026#34; + cookie.getValue()); } }   生命周期：不随服务端的重启而销毁，客户端默认是关闭就被销毁，但是可以通过setMaxAge()方法设置有效期，销毁由设置的时间来决定；\n退出登录：setMaxAge(0)\n★JSP内置对象的作用域 下面四个内置对象都具备setAttribute和getAttribute方法，所以才讨论其作用域。（传输数据，考虑能不能拿到数据）\n  page，page只在当前页面有效\n page作用域：对应的内置对象是 pageContext\n   request，在一次请求内有效\n request作用域：对应的内置对象是 request\n   session，在一次会话内有效\n session作用域：对应的内置对象是 session\n   application，作用整个WEB应用\n application作用域：对应的内置对象是 application\n   作用域的大小：page \u0026lt; request \u0026lt; session \u0026lt; application\ndemo：写一个网站访问量统计程序；\n1 2 3 4 5 6 7 8 9 10 11  \u0026lt;% Integer count = (Integer) application.getAttribute(\u0026#34;count\u0026#34;); if (count == null) { count = 1; application.setAttribute(\u0026#34;count\u0026#34;, count); } else { count++; application.setAttribute(\u0026#34;count\u0026#34;, count); } %\u0026gt; 您当前是第\u0026lt;%=count%\u0026gt;位访客！   ★EL表达式 Expression Language（EL）表达式语言，可以替代JSP页面中数据访问时的复杂编码，为简化JSP页面而生；语法是：${变量名}；可以方便的从域对象（page、request、session、application）中保存的数据，前提是需要先setAttribute；(EL表达式只能在JSP中使用，HTML和Servlet中都无法使用；)\n为什么说是简化了JSP页面呢？看一个例子就知道；\n比如el.jsp页面中需要向el2.jsp页面中传递一个name的变量，所以应该是这样写：\nel.jsp\n1 2 3 4 5  \u0026lt;% String name = \u0026#34;langchao\u0026#34;; request.setAttribute(\u0026#34;name\u0026#34;, name); request.getRequestDispatcher(\u0026#34;el2.jsp\u0026#34;).forward(request,response); %\u0026gt;   el2.jsp取到name\n1 2 3 4  \u0026lt;% String name = (String) request.getAttribute(\u0026#34;name\u0026#34;); %\u0026gt; el.jsp中传递过来的name为：\u0026lt;%=name%\u0026gt;   用EL表达式简化后的写法：\n1  el.jsp中传递过来的name为：${name}   那问题来了，如果四个域对象都设置了同一个属性值（比如name），EL表达式该如何取呢？\n答：EL表达式查找顺序是：page-》request-》session》application\n问题又来了，如果就要取来自session中的属性值呢？\n答：${sessionScope.name}\n1 2 3 4 5 6 7  \u0026lt;% pageContext.setAttribute(\u0026#34;name\u0026#34;, \u0026#34;page\u0026#34;); request.setAttribute(\u0026#34;name\u0026#34;, \u0026#34;request\u0026#34;); session.setAttribute(\u0026#34;name\u0026#34;, \u0026#34;session\u0026#34;); application.setAttribute(\u0026#34;name\u0026#34;, \u0026#34;application\u0026#34;); %\u0026gt; ${sessionScope.name}   还可以很方便的取出对象的属性值；\n${user} ${user.id}或者${user[\u0026quot;id\u0026quot;]} ${user.name} ${user.address}  ${user.id}实际上是通过调用User类的getId()方法得到id的值；\n EL可以执行表达式，比如与、或、非运算。\n1 2  \u0026amp;\u0026amp; || ! \u0026lt; \u0026gt; \u0026lt;= \u0026gt;= == ${not empty num}   ","description":"今天主要学习的是Session和Cookie以及JSP内置对象和作用域的学习，还顺便学习了EL表达式。一步步的演进，让我懂得了技术的发展并不是一蹴而就的，有不方便的地方就要去解决，比如EL表达式就极大的简化了JSP页面的代码。相信还会有更加简便的工具来代替EL表达式；","id":16,"section":"posts","tags":["JavaWeb",""],"title":"4.24_Session、Cookie和EL学习","uri":"http://blog.langchao2020.tech/posts/session-cookie-el-study/"},{"content":"★第一部分 Tomcat介绍 tomcat是什么？ Tomcat是一个Web应用服务器，它可以使得你写的Java程序被别人访问（通过网络），类似的Web应用服务器还有xxx、xxx、xxx。\n如何安装tomcat？  下载tomcat9.0.34，下载地址是：https://mirrors.tuna.tsinghua.edu.cn/apache/tomcat/tomcat-9/v9.0.34/bin/apache-tomcat-9.0.34-windows-x64.zip 解压到指定目录，比如：D:\\Apps\\JavaEE  tomcat压缩包内各个文件夹的作用  bin：存放各个平台下启动和停止tomcat服务的脚本文件，比如Mac下使用startup.sh就可以启动tomcat，windows下是用startup.bat启动； conf：存放各种tomcat服务器的配置文件，比如配置端口； lib：一些jar包，供tomcat使用，也可以拷出来给其它Java程序使用； logs：记录tomcat服务器运行的日志信息； temp：存放tomcat运行时的临时文件，比如文件的上传和下载（临时）； webapps：存放允许被客户端访问的资源（如Java程序、图片等）； work：存放tomcat将JSP转换之后的Servlet文件；  如何在IDEA中创建第一个tomcat应用程序？  创建JavaEE程序 配置本地Tomcat服务器 配置访问路径  ★第二部分 Servlet详解 什么是Servlet？ Servlet是Java Web开发的基石，与平台无关的服务器组件，它是运行在Servlet容器（其实也就是Web应用服务器），负责与客户端通信；\n主要功能  创建并返回基于客户请求的动态HTML页面（比如登录成功页面、登录失败页面）； 与数据库进行通信；  如何使用Servlet？ Servlet本身是一组接口（接口是描述功能的），其接口在javax.servlet包内。因此需要自定义一个类，并且实现servlet接口，于是这个类就具备了接受客户端请求以及做出响应的功能；\nservlet程序所处的物理路径（WEB-INF目录中）不允许被直接访问，所以需要做一个映射（注解应该是基于这个）。\n如何映射servlet程序？   方法一：在web.xml中配置（基于XML文件）\n例如通过浏览器/myservlet路径访问MyServlet程序，通过相同的MyServlet间接映射。在web.xml做如下设置即可：\n1 2 3 4 5 6 7 8  \u0026lt;servlet\u0026gt; \u0026lt;servlet-name\u0026gt;MyServlet\u0026lt;/servlet-name\u0026gt; \u0026lt;servlet-class\u0026gt;tech.langchao2020.servlet.MyServlet\u0026lt;/servlet-class\u0026gt; \u0026lt;/servlet\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;MyServlet\u0026lt;/servlet-name\u0026gt; \u0026lt;url-pattern\u0026gt;/myservlet\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt;   自定义类中的service方法可以响应客户端的请求，比如返回一句话（值得注意的是会有中文乱码，因此需要转码）：\n1 2 3 4 5 6  @Override public void service(ServletRequest servletRequest, ServletResponse servletResponse) throws ServletException, IOException { System.out.println(\u0026#34;服务端已经接收到请求....\u0026#34;); servletResponse.setContentType(\u0026#34;text/html;charset=UTF-8\u0026#34;); servletResponse.getWriter().write(\u0026#34;你好啊，朋友！\u0026#34;); }   通过servletRequest对象的getParameter()方法可以接收来自客户端带来的参数：\n1 2  String id = servletRequest.getParameter(\u0026#34;id\u0026#34;); System.out.println(\u0026#34;服务端已经接收到请求,参数是：\u0026#34; + id);     方法二：通过注解的方式\n1 2 3 4 5 6 7 8 9 10 11  @WebServlet(\u0026#34;/demo1\u0026#34;) public class MyServlet implements Servlet { //此处省略需要重写的其它四个方法  @Override public void service(ServletRequest servletRequest, ServletResponse servletResponse) throws ServletException, IOException { String id = servletRequest.getParameter(\u0026#34;id\u0026#34;); System.out.println(\u0026#34;服务端已经接收到请求,参数是：\u0026#34; + id); servletResponse.setContentType(\u0026#34;text/html;charset=UTF-8\u0026#34;); servletResponse.getWriter().write(\u0026#34;你好啊，朋友！\u0026#34;); } }     扩展 java和javax的区别，java.x开头的是最基础的功能包，javax.x是后来扩展的功能包，都是jdk官方提供的；\nServlet生命周期 过程  客户端请求Servlet时，tomcat会查询当前的实例化对象是否存在，如果不存在则通过反射自动创建。如果存在，直接执行第三步； 调用init()方法完成初始化操作； 调用service()方法完成业务逻辑操作； 关闭tomcat服务器时，会调用destor()方法销毁当前对象（释放资源）；  生命周期方法   1 2 3 4  @Override public void init(ServletConfig servletConfig) throws ServletException { System.out.println(\u0026#34;对Servlet执行初始化操作...\u0026#34;); }     1 2 3 4  @Override public void service(ServletRequest servletRequest, ServletResponse servletResponse) throws ServletException, IOException { System.out.println(\u0026#34;对Servlet执行了业务方法....\u0026#34;); }     1 2 3 4  @Override public void destroy() { System.out.println(\u0026#34;销毁了Servlet对象....\u0026#34;); }     tomcat通过反射机制创建自定义类的对象 创建自定义类并实现Servlet接口时并没有自己手动new一个MyServlet对象，但这并不代表这个类并没有被实例化，而是tomcat容器帮你做了这个事情。它是通过反射机制创建的，反射创建对象一般是通过无参构造方法。\n通过反射调用无参构造：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  package tech.langchao2020.servlet; import java.lang.reflect.Constructor; public class TomcatTest { public static void main(String[] args) { // 拿到全类名  String str = \u0026#34;tech.langchao2020.servlet.LifeServlet\u0026#34;; // 获取运行时类  try { Class clazz = Class.forName(str); // 获取无参构造  Constructor constructor = clazz.getConstructor(); // System.out.println(constructor);  // 构造器创建对象  Object object = constructor.newInstance(); System.out.println(object); } catch (Exception e) { e.printStackTrace(); e.printStackTrace(); } } }   ServletConfig接口 改接口是用来描述Servlet的基本信息；\nservletConfig常用接口方法  1 2 3  getServletName(); // 获取Servlet的全类名（带包的类名） getInitParameter(username); // 获取init参数的值，这个值是来自web.xml里面的值（需要配置） getInitParameterNames();// 获取所有的init参数名     1 2 3 4 5 6 7 8  \u0026lt;servlet\u0026gt; \u0026lt;servlet-name\u0026gt;MyServlet\u0026lt;/servlet-name\u0026gt; \u0026lt;servlet-class\u0026gt;tech.langchao2020.servlet.MyServlet\u0026lt;/servlet-class\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;username\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;admin\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;/servlet\u0026gt;     getServletContext()方法返回ServletContext对象，是Servlet上下文（整个servlet的管理者），这是常用的方法，以上三个并不常用；能拿到很多关于Servlet的信息，比如上下文路径getContextPath()、tomcat服务器信息getServletInfo()；\n  ServletConfig 和 ServletContext的区别：\n ServletConfig 作用于某个特定的servlet实例，每个servlet都有对应的ServletConfig，实例化后是一个局部对象； ServletContext作用于整个Web应用，一个Web应用对应于一个ServletContext，多个servlet实例（如HelloServlet、LifeServlet、TestServlet）对应一个ServletContext，实例化后是一个全局对象；    Servlet层次上的改进 Servlet接口的层次 Servlet \u0026mdash;》GenericServlet \u0026mdash;》HttpServlet\n Servlet\n GenericServlet\n HttpServlet\n   GenericServlet实现了Servlet接口，同时屏蔽（继承的作用之一）了其子类并不常用的方法。实际使用中只需要将自定义的类继承自HttpServlet即可，然后重写doGet() 和 doPost() 方法即可；\n1 2 3 4 5 6 7 8 9 10 11 12  @WebServlet(\u0026#34;/hello\u0026#34;) public class HelloServlet extends HttpServlet { @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { resp.getWriter().write(\u0026#34;doGet! Hello langchao;\u0026#34;); } @Override protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { resp.getWriter().write(\u0026#34;doPost! Hello langchao;\u0026#34;); } }   Http请求有很多种类型（是不是要补习一点HTTP协议的相关知识？），常见的有下面四种：\n GET 读取 POST 保存 PUT 修改 DELETE 删除  CRUD指的分别是：\n Create Read Update Delete  ★第三部分 JSP详解 什么是JSP？ JSP本质上就是Servlet，JSP主要负责与客户端交互（界面上的交互），将最终的页面呈现给用户；一个JSP可能包含HTML、CSS、JavaScript、Java部分。(从开发角度来看就是在HTML中嵌入Java代码)\n当服务器接收到一个后缀是.jsp的请求时，则该将请求交给JSP引擎去处理；每一个JSP页面第一次被访问的时候，JSP引擎会将它翻译成一个Servlet文件，再由Web容器调用该Servlet文件完成响应；\nJSP中嵌入Java代码的方式   方式1——JSP脚本，执行Java逻辑代码\n1  \u0026lt;% Java代码 %     方式2——JSP声明，用来定义Java方法\n1 2 3  \u0026lt;%! 声明Java方法代码 %\u0026gt;   1 2 3 4 5 6 7 8 9 10  \u0026lt;%-- 声明Java方法--%\u0026gt; \u0026lt;%! public String test() { return \u0026#34;Hello String!\u0026#34;; } %\u0026gt; \u0026lt;%-- 调用--%\u0026gt; \u0026lt;% System.out.println(test()); %\u0026gt;     方式3——JSP表达式，把Java对象直接输出到HTML页面\n1  \u0026lt;%= Java变量 %\u0026gt;   1 2 3 4 5 6 7 8 9 10 11  \u0026lt;%-- 声明Java方法--%\u0026gt; \u0026lt;%! public String test() { return \u0026#34;Hello String!\u0026#34;; } %\u0026gt; \u0026lt;%-- 调用--%\u0026gt; \u0026lt;% String hi = test(); %\u0026gt; \u0026lt;%=hi%\u0026gt;     例子（往index.jsp页面中添加Java对象成员变量中的数据）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  package tech.langchao2020.servlet.entity; public class Student { private String name; private int age; public String getName() { return name; } public void setName(String name) { this.name = name; } public int getAge() { return age; } public void setAge(int age) { this.age = age; } public Student(String name, int age) { this.name = name; this.age = age; } }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  \u0026lt;% List\u0026lt;Student\u0026gt; students = new ArrayList\u0026lt;\u0026gt;(); students.add(new Student(\u0026#34;张三\u0026#34;, 34)); students.add(new Student(\u0026#34;李四\u0026#34;, 43)); %\u0026gt; \u0026lt;table\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th\u0026gt;姓名\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;年龄\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;% for (int i = 0; i \u0026lt; students.size(); i++) { %\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt; \u0026lt;%=students.get(i).getName()%\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;td\u0026gt; \u0026lt;%=students.get(i).getAge()%\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;% } %\u0026gt; \u0026lt;/table\u0026gt;     JSP内置对象（9个）  request  表示一次请求，由类HttpServletRequest产生   response  表示一次响应，由类HttpServletResponse产生   pageContext  页面上下文，可以获取页面信息，由类PageContext产生   session  表示一次会话，保存用户信息，由HttpSession产生   application  表示当前Web应用，是全局对象，保存所有用户共享信息，由类ServletContext产生   config  当前JSP对应的Servlet的ServletConfig对象，获取当前Servlet信息   out  由JspWriter类产生，用于向浏览器输出数据   page  当前JSP对应的Servlet对象，由Servlet产生   exception  表示JSP页面异常信息，来自Exception    常用的是：request、response、seesion、application、pageContext\nrequest常用方法  String getParameter(key) 获取客户端传来的参数 void setAttribute(String key, Object value) 通过键值对的形式来保存数据。 （Web容器/服务端内部页面传递数据需要使用到） Objcet getAttribute(String) 通过key取出value； RequestDispatcher getRequestDispatcher(String path)返回一个RequestDispatcher 对象，该对象的forwar()方法用于请求转发 String[] getParameterValues() 获取客户端传来的多个相同的key的值 void setCharaterEncoding(String charset) 指定每个请求的编码  ","description":"4.23日学习Tomcat、Servlet以及部分JSP的内容，主要是做了一些笔记。对请求转发这块得继续加强熟练度。","id":17,"section":"posts","tags":["JavaWeb",""],"title":"4.23_Servlet和JSP学习","uri":"http://blog.langchao2020.tech/posts/servlet-jsp-study/"},{"content":"★0、前言 　我们生活的这个时代充满着前所未有的机会：如果你有雄心，又不乏智慧，那么不管你从何处起步，你都可以沿着自己所选择的道路登上事业的顶峰。\n　不过，有了机会，也就有了责任。今天的公司并不怎么管员工的职业发展；实际上，知识工作者必须成为自己的首席执行官。你应该在公司中开辟自己的天地，知道何时改变发展道路，并在可能长达50年的职业生涯中不断努力、干出实绩。要做好这些事情，你首先要对自己有深刻的认识——不仅清楚自己的优点和缺点，也知道自己是怎样学习新知识和与别人共事的，并且还明白自己的价值观是什么、自己又能在哪些方面做出最大贡献。因为只有当所有工作都从自己的长处着眼，你才能真正做到卓尔不群。\n　历史上的伟人——拿破仑、达芬奇、莫扎特——都很善于自我管理。这在很大程度上也是他们成为伟人的原因。不过，他们属于不可多得的奇才，不但有着不同于常人的天资，而且天生就会管理自己，因而才取得了不同于常人的成就。而我们当中的大多数人，甚至包括那些还算有点天赋的人，都不得不通过学习来掌握自我管理的技巧。\n　我们必须学会自我发展，必须知道把自己放在什么样的位置上，才能做出最大的贡献，而且还必须在长达50年的职业生涯中保持着高度的警觉和投入——也就是说，我们得知道自己应该何时换工作，以及该怎么换。\n★1、我的长处是什么？ **多数人都以为他们知道自己擅长什么，其实不然！**更多的情况是，人们只知道自己不擅长什么——即便是在这一点上，人们也往往认识不清。然而，一个人要有所作为，只能靠发挥自己的长处，而如果从事自己不太擅长的工作是无法取得成就的，更不用说那些自己根本干不了的事情。\n　以前的人没有什么必要去了解自己的长处，因为一个人的出身就决定了他一生的地位和职业：农民的儿子也会当农民，工匠的女儿会嫁给另一个工匠等。但是，现在人们有了选择。我们需要知己所长，才能知己所属。\n　要发现自己的长处，唯一途径就是回馈分析法（feedback analysis）。每当做出重要决定或采取重要行动时，你都可以事先记录下自己对结果的预期。9到12个月后，再将实际结果与自己的预期比较。我本人采用这种方法已有15到20年了，而每次使用都有意外的收获。\n　比如，回馈分析法使我看到，我对专业技术人员，不管是工程师、会计师还是市场研究人员，都容易从直觉上去理解他们。这令我大感意外。它还使我看到，我其实与那些涉猎广泛的通才没有什么共鸣。\n　回馈分析法并不是什么新鲜的东西。早在14世纪，这种方法由一个原本会永远默默无闻的德国神学家发明，大约150年后被法国神学家约翰·加尔文和西班牙神学家圣依纳爵分别采用。他们都把这种方法用于其信徒的修行。事实上，回馈分析法使他们的信徒养成了一种始终注重实际表现和结果的习惯，这也是他们创立的教派——加尔文教会和耶稣会——能够主宰欧洲长达30年的原因。\n　**我们只要持之以恒地运用这个简单的方法，就能在较短的时间内（可能两三年），发现自己的长处——这是你需要知道的最重要的事情。**在采用这种方法之后，你就能知道，自己正在做（或没有做）的哪些事情会让你的长处无法发挥出来。同时，你也将看到自己在哪些方面能力不是特别强。最后，你还将了解到自己在哪些方面完全不擅长，做不出成绩来。\n　根据回馈分析的启示，你需要在几方面采取行动。\n　首先，最重要的是，专注于你的长处，把自己放到那些能发挥长处的地方。\n　其次，加强你的长处。回馈分析会迅速地显示，你在哪些方面需要改善自己的技能或学习新技能。它还将显示你在知识上的差距——这些差距通常都可以弥补。数学家是天生的，但是人人都能学习三角学。\n　第三，发现任何由于恃才傲物而造成的偏见和无知，并且加以克服。有太多的人，尤其是那些术业有专攻的人，往往对其他领域的知识不屑一顾，或者认为聪明的头脑就可取代知识。比如，很多一流的工程师遇上与人相关的事就束手无策，他们还以此为荣——因为他们觉得，对条理清晰的工程师头脑来说，人太混乱无序了。与此形成鲜明对照的是，人力资源方面的专业人员常常以他们连基本的会计知识或数量分析都一无所知而自傲。不过，人们要是对这样的无知还沾沾自喜的话，那无异于自取灭亡。其实，要让自己的长处得到充分发挥，你就应该努力学习新技能、汲取新知识。\n　**另外一点也同样重要——纠正你的不良习惯。所谓不良习惯，是指那些会影响你的工作成效和工作表现的事情。这样的习惯能很快地在回馈中反映出来。**例如，一位企划人员可能发现自己美妙的计划最终落空，原因是他没有把计划贯彻到底。同那些才华横溢的人一样，他也相信好的创意能够移动大山。但是，真正移山的是推土机，创意只不过是为推土机指引方向，让它知道该到何处掘土。这位企划人员必须意识到不是计划做好就大功告成，接下来还得找人执行计划，并向他们解释计划，在付诸行动前须做出及时的调整和修改，最后要决定何时中止计划。\n　与此同时，回馈还会反映出哪些问题是由缺乏礼貌造成的。礼貌是一个组织的润滑剂。两个移动物相互接触时发生摩擦是一个自然规律，不仅无生命的物体是这样，人类也是如此。礼貌，其实也很简单，无非是说声“请”和“谢谢”，记住别人的名字，或问候对方家人这样的小事，但就是这种不起眼的细节，使得两个人能够融洽相处，不管他们彼此之间是否有好感。许多聪明人，尤其是聪明的年轻人，没有意识到这一点。如果回馈分析表明某个人只要一遇到需要别人合作的事就屡屡失败，那么很可能就意味着这个人的举止不大得体——也就是缺乏礼貌。\n　把预期和实际结果进行比较，也会发现自己不擅长做什么。我们每个人都有许多一窍不通、毫无天分的领域，在这些领域我们甚至连平庸的水平都达不到。人们，尤其是知识工作者，就不应该试图去完成这些领域的工作和任务。他们应该尽量少把精力浪费在那些不能胜任的领域上，因为“从无能到平庸”要比“从一流到卓越”需要人们付出多得多的努力。然而，大多数人，尤其是教师，还有组织，都一门心思要把能力低下的人变成合格者。其实，他们还不如把精力、资源和时间花在将称职者培养成佼佼者上。\n★2、我的工作方式是怎样的？ 　令人惊讶的是，很少有人知道自己平时是怎样把事情给做成的。实际上，我们当中的大多数人甚至不知道不同人有着不同的工作方式和表现。许多人不是以他们习惯的方式工作，这当然就容易造成无所作为。对于知识工作者来说，“我的工作方式是怎样的？”可能比“我的长处是什么？”这个问题更加重要。\n　同一个人的长处一样，一个人的工作方式也是独一无二的——这是由人的个性所决定的。不管个性是先天决定的，还是后天培养的，它肯定是早在一个人进入职场前就形成了。正如一个人擅长什么、不擅长什么是既定的一样，一个人的工作方式也基本固定，它可以略微有所调整，但是不可能完全改变——当然也不会轻易改变。而且就像人们从事自己最拿手的工作容易做出成绩一样，他们要是采取了自己最擅长的工作方式也容易取得成就。通常，几个常见的个性特征就决定了一个人的工作方式。\n我属于读者型，还是听者型？\n　首先，你要搞清楚的是，你是读者型（习惯阅读信息）还是听者型（习惯听取信息）的人。绝大多数人甚至都不知道还有“读者型”和“听者型”之说，而且很少有人既是读者型又是听者型。知道自己属于哪种类型的人更少。但是，有一些例子说明了这样的无知可能造成多大的危害。\n　德怀特·艾森豪威尔担任欧洲盟军最高统帅时，一直是新闻媒体的宠儿。他的记者招待会以其独特的风格出名——不管记者提出什么问题，艾森豪威尔将军都从容地对答如流。无论是介绍情况，还是解释政策，他都能够用两三句言简意赅的话就说清楚。十年后，艾森豪威尔当上了总统，当年曾对他十分崇拜的同一批记者，这时却公开瞧不起他。他们抱怨说，他从不正面回答问题，而是喋喋不休地胡侃着其他事情。他们总是嘲笑他回答问题时语无伦次，不合乎语法，糟蹋标准英语。\n　艾森豪威尔显然不知道自己属于读者型，而不是听者型。当他担任欧洲盟军最高统帅时，他的助手设法确保媒体提出的每一个问题至少在记者招待会开始前半小时以书面形式提交。这样，艾森豪威尔就完全掌握了记者提出的问题。而当他就任总统时，他的两个前任都是听者型——富兰克林·罗斯福和哈里·杜鲁门。这两位总统知道自己是听者型的，并且都喜欢举行畅所欲言的记者招待会。艾森豪威尔可能认为他必须去做两位前任所做的事。可是，他甚至连记者们在问些什么都从来没听清楚过。而且，艾森豪威尔并不是个极端的例子。\n　几年后，林登·约翰逊把自己的总统职位给搞砸了，这在很大程度上是因为他不知道自己是听者型的人。他的前任约翰·肯尼迪是个读者型的人，他搜罗了一些出色的笔杆子当他的助手，要求他们每次进行当面讨论之前务必先给他写通报。约翰逊留下了这些人，他们则继续写通报。可是他显然根本看不懂他们写的东西。不过，约翰逊以前当参议员时曾经表现非凡，因为议员首先必须是听者型。\n　**没有几个听者型的人可以通过努力变成合格的读者型——不管是主动还是被动的努力；反之亦然。**因此，试图从听者型转为读者型的人会遭受林登·约翰逊的命运，而试图从读者型转为听者型的人会遭受德怀特·艾森豪威尔的命运。他们都不可能发挥才干或取得成就。\n★3、我如何学习？ 要了解一个人的工作方式，需要弄清的第二点是，他是如何学习的。\n　许多一流的笔杆子都不是好学生——温斯顿·邱吉尔就是一例。在他们的记忆中，上学往往是十足的折磨。然而，他们的同学有这种记忆的却很少。他们可能在学校里得不到什么乐趣，对他们来说上学的最大痛苦是无聊。有关这个问题的解释是，笔头好的人一般不靠听和读来学习，而靠写来学习，这已成了一种规律。学校不让他们以这种方式学习，所以他们的成绩总是很糟糕。\n　所有的学校都遵循这样的办学思路：只有一种正确的学习方式，而且人人都得遵从。但是，对学习方式跟别人不大一样的学生来说，被迫按学校教的方式来学习就是地狱。实际上，学习大概有六七种不同的方式。\n　像邱吉尔这样的人靠写来学习。还有些人以详尽的笔记来学习。例如，贝多芬留下了许多随笔小抄，然而他说，实际上他作曲时从来不看这些随笔小抄。当被问及他为什么还要用笔记下来时，据说他回答道：“如果我不马上写下来的话，我很快就会忘得一干二净。如果我把它们写到小本子上，我就永远不会忘记了，也用不着再看一眼。”有些人在实干中学习。另一些人通过听自己讲话学习。\n　我认识一位公司总经理，他把一个平庸的小家族企业发展成行业领军企业。他是一个通过讲话学习的人。他习惯于每周一次把全体高层管理人员召集到他的办公室，随后对他们讲上两三个小时。他总是提出政策性问题，在每一个问题上提出三种不同观点。但他很少请这帮同事发表意见或提出问题，他只需要听众听他讲话。这就是他的学习方式。虽然他是一个比较极端的例子，但是通过讲话学习绝不是一种少见的方法。成功的出庭律师也以同样的方式学习，许多诊断医师也是如此（我自己也是这样）。\n　在所有最重要的自我认识当中，最容易做到的就是知道自己是怎样学习的。当我问人们：“你怎么学习？”大多数人都知道答案。但是，当我问：“你根据这个认识来调整自己的行为吗？”没有几个人回答“是”。然而，知行合一是取得成就的关键；如果知行不合一，人们就会无所作为。\n　我属于读者型还是听者型？我如何学习？这是你首先要问自己的问题。但是，光这些问题显然不够。要想做好自我管理，你还需要问这样的问题：我能与别人合作得好吗？还是喜欢单枪匹马？如果你确实有与别人进行合作的能力，你还得问问这个问题：我在怎样的关系下与他人共事？\n　有些人适合当部属。二战时期美国的大英雄乔治·巴顿将军是一个很好的例子。巴顿是美军的一名高级将领。然而，当有人提议他担任独立指挥官时，美国陆军参谋长（可能也是美国历史上最成功的伯乐）乔治·马歇尔将军说：“巴顿是美国陆军造就的最优秀的部下，但是，他会成为最差劲的司令官。”\n　一些人作为团队成员工作最出色；另一些人单独工作最出色。一些人当教练和导师特别有天赋；另一些人却没能力做导师。\n　另一个关键的问题是，我如何才能取得成果——是作为决策者还是作为顾问？\n　许多人做顾问时的表现会很出色，但是不能够承担决策的负担和压力。与此相反，也有许多人需要顾问来迫使他们思考，随后他们才能做出决定，接着迅速、自信和大胆地执行决定。\n　顺便说一下，一个组织的二号人物在提升到一号职位时常常失败，也正是因为这个原因。最高职位需要一个决策者，而一个强势的决策者常常把其信赖的人放在二号位置，当他的顾问。顾问在二号位置上往往是很出色的，但是换到一号位置，他就不行了。他虽然知道应该做出什么样的决定，但是不能接受真正做决定的责任。\n　其他有助于认识自我的重要问题包括：\n 1、我是在压力下表现出色，还是适应一种按部就班、可预测的工作环境？\n2、我是在一个大公司还是在一个小公司中工作表现最佳？\n3、在各种环境下都工作出色的人寥寥无几。\n 　我不止一次地看到有些人在大公司中十分成功，换到小公司中则很不顺利。反过来也是如此。下面这个结论值得我们反复强调：**不要试图改变自我，因为这样你不大可能成功。但是，你应该努力改进你的工作方式。**另外，不要从事你干不了或干不好的工作。\n★4、我的价值观是什么？ 　要能够自我管理，你最后不得不问的问题是：我的价值观是什么？这不是一个有关伦理道德的问题。道德准则对每一个人都一样。要对一个人的道德进行测试，方法很简单。我把它称为“镜子测试”。\n　20世纪初，德国驻英国大使是当时在伦敦所有大国中最受尊重的一位外交官。显然，他命中注定会承担重任，即使不当本国的总理，至少也要当外交部长。然而，在1906年，他突然辞职，不愿主持外交使团为英国国王爱德华七世举行的晚宴。这位国王是一个臭名昭著的色鬼，并且明确表示他想出席什么样的晚宴。据有关报道，这位德国大使曾说：“我不想早晨刮脸时在镜子里看到一个皮条客。”——这就是镜子测试。\n　我们所遵从的伦理道德要求你问自己：我每天早晨在镜子里想看到一个什么样的人？在一个组织或一种情形下合乎道德的行为，在另一个组织或另一种情形下也是合乎道德的。但是，道德只是价值体系的一部分——尤其对于一个组织的价值体系来说。\n　如果一个组织的价值体系不为自己所接受或者与自己的价值观不相容，人们就会备感沮丧，工作效力低下。\n　让我们来看看一位十分成功的人力资源主管的经历。这位主管所在的公司被一家大企业收购。收购之后，她得到了提升，从事的是她以前做得最出色的工作，包括为重要职位挑选人才。这位主管深信，在选人时，公司只有在排除内部的所有可能人选后才能从外部招聘人才。但是她的新公司认为应该首先从外部招聘，以吸收新鲜血液。对于这两种方式，需要说明的一点是，根据我的经验，适当的方式是两者兼顾。然而，这两种方式在根本上是互不相容的——表面上是政策不同，实质是价值观的不同。这说明在该公司人们对以下三个问题有着不同看法：组织与员工之间是怎样的关系；组织应该为员工以及员工的发展承担何种责任；一个人对企业最重要的贡献是什么。经过几年挫折，这位主管最终辞职——尽管她的经济损失很大。她的价值观和这个组织的价值观就是无法融合。\n　同样，一家制药公司无论是通过不断的小幅改进，还是通过几次费用高昂、风险巨大的“突破”来取得出色业绩，都不是一个经济问题。这两种战略的结果可能都差不多。实质上，这是两种价值体系之间的冲突。一种价值体系认为公司的贡献是帮助医生把他们已经在做的工作锦上添花，另一种价值体系的取向是进行更多的科学发现。\n　至于一个企业的经营是着眼于短期结果，还是注重长远发展，这同样是价值观问题。财务分析师认为，企业可两者同时兼顾。成功的企业家知道得更清楚。诚然，每一家公司都必须取得短期成果。但是在短期成果与长期增长之间的冲突中，每一家公司都将决定自己所选择的重点。从根本上说，这是一种关于企业职能与管理层责任的价值观冲突。\n　价值观冲突并不限于商业组织。美国发展最快的一个牧师教会，其衡量工作成败的尺度是新教徒的人数。它的领导层认为，重要的是有多少新教徒入会。随后，上帝将满足他们的精神需求，或者至少会满足足够比例的新教徒的需求。另一个福音派牧师教会认为，重要的是人们的精神成长。这个教会慢慢地让那些形式上入会但精神上并没有融入教会生活的新教徒选择了离开。\n　这同样不是一个数量问题。乍一看，第二个教会好像发展较慢。但是，它留住新教徒的比例要远高于第一个。换言之，它的发展比较稳固。这也不是一个神学问题（至少首先并不是神学问题），而是有关价值观的问题。在一次公开辩论中，一位牧师这样说：“除非你先加入教会，否则你永远找不到天国之门。”而另一位牧师反驳说：“不，除非你先有心寻找天国之门，否则你就不属于教会。”\n　**组织和人一样，也有价值观。为了在组织中取得成效，个人的价值观必须与这个组织的价值观相容。两者的价值观不一定要相同，但是必须相近到足以共存。**不然，这个人在组织中不仅会感到沮丧，而且做不出成绩。\n　一个人的工作方式和他的长处很少发生冲突，相反，两者能产生互补。但是，一个人的价值观有时会与他的长处发生冲突。一个人做得好甚至可以说是相当好、相当成功的事情——可能与其价值体系不吻合。在这种情况下，这个人所做的工作似乎并不值得贡献毕生的精力（甚至没必要贡献太多的精力）。\n　如果可以，请允许我插入一段个人的故事。多年前，我也曾不得不在自己的价值观和做得很成功的工作之间做出选择。20世纪30年代中期，我还是一个年轻人，在伦敦做投资银行业务，工作非常出色。这项工作显然能发挥我的长处。然而，我并不认为自己担任资产管理人是在做贡献。我认识到，我所重视的是对人的研究。我认为，一生忙于赚钱、死了成为墓地中的最大富翁没有任何意义。当时我没有钱，也没有任何就业前景。尽管当时大萧条仍在持续，我还是辞去了工作。这是一个正确的选择。换言之，价值观是并且应该是最终的试金石。\n★5、我属于何处？ 　少数人很早就知道他们属于何处。比如，数学家、音乐家和厨师，通常在四五岁的时候就知道自己会成为数学家、音乐家和厨师了。物理学家通常在十几岁甚至更早的时候就决定了自己的工作生涯。但是，**大多数人，尤其是很有天赋的人，至少要过了二十五六岁才知道他们将身属何处。**然而，到这个时候，他们应该知道上面所谈的三个问题的答案：\n 1、我的长处是什么？\n2、我的工作方式是怎样的？\n3、我的价值观是什么？\n 随后，他们就能够决定自己该向何处投入精力。或者，他们应该能够决定自己不属于何处。\n　已经知道自己在大公司里干不好的人，应该学会拒绝在一个大公司中任职。已经知道自己不适合担任决策者的人，应该学会拒绝做决策工作。巴顿将军（他自己大概永远不知道这一点）本来应该学会拒绝担任独立总指挥的。\n　同样重要的是，知道上述三个问题的答案，也使得一个人能够坦然接受一个机会、一个邀请或一项任务。他们会说：“是的，我将做这件事。但是，我将按照我自己的特点，采取这样的方式来做这件事，进行这样的组织安排，这样来处理当中所牵涉的关系。这是我在这个时间范围内应该会取得的成果，因为这就是我。”\n　**成功的事业不是预先规划的，而是在人们知道了自己的长处、工作方式和价值观后，准备把握机遇时水到渠成的。**知道自己属于何处，可使一个勤奋、有能力但原本表现平平的普通人，变成出类拔萃的工作者。\n★6、我该做什么贡献？ 　综观人类的发展史，绝大多数人永远都不需要提出这样一个问题：我该做出什么贡献？因为他们该做出什么贡献是由别人告知的，他们的任务或是由工作本身决定的（例如农民或工匠的任务），或是由主人决定的（例如佣人的任务）。\n　以前的人大多都处于从属地位，别人吩咐他们做什么，就做什么，这被认为是理所当然的。甚至到了20世纪50年代和60年代，那时涌现出的知识工作者（即所谓的“组织人”，organization man）还指望公司的人事部为他们做职业规划。\n　随后，到20世纪60年代末，就再没有人想让别人来安排自己的职业生涯了。年轻的男男女女开始提出这个问题：我想做什么？而他们所听到的答案就是“你们自行其是吧”。但是，这种回答同“组织人”听命公司的做法一样错误。那些相信自行其是就能做出贡献、实现抱负、取得成功的人，一般连三点中的任何一点都做不到。\n　尽管如此，我们还是不能走回头路，让别人来吩咐、安排自己要干什么。对于知识工作者来说，他们还不得不提出一个以前从来没有提出过的问题：我的贡献应该是什么？要回答这个问题，他们必须考虑三个不同的因素：\n 1、当前形势的要求是什么？\n2、鉴于我的长处、我的工作方式以及我的价值观，我怎样才能对需要完成的任务做出最大贡献？\n3、必须取得什么结果才能产生重要影响？\n 　请看一位新任命的医院院长的经历。这是一所享有盛名的大医院，30年来一直就靠名气顺利经营着。新院长上任后决定了自己应做的贡献：两年内在医院的某个重要领域建立起卓越服务的标准。他决定以急诊室为重点，因为该院的急诊室地方比较大，受人注意，而又秩序混乱。他决定，到急诊室就诊的每一个患者必须在60秒钟之内由一名合格的护士接待。一年之内，该医院的急诊室变成了美国所有医院的样板，又过了两年，整个医院的面貌焕然一新。\n　正如这个事例所表明的，把眼光放得太远是不大可能的——甚至不是特别有效。一般来说，一项计划的时间跨度如果超过了18个月，就很难做到明确和具体。因此，在多数情况下我们应该提出的问题是：\n 1、我在哪些方面能取得将在今后一年半内见效的结果？\n2、如何取得这样的结果？\n 　回答这个问题时必须对几个方面进行权衡：\n　首先，这些结果应该是比较难实现的——用当前的一个时髦词说，就是要有“张力”（stretching）。但是，这些结果也应该是能力所及的。设定一个不能实现的目标或者只能在可能性微乎其微的情况下实现的目标，根本不能叫雄心勃勃，简直就是愚蠢。\n　其次，这些结果应该富有意义，要能够产生一定影响。\n　最后，结果应该明显可见，如果可能的话，还应当能够衡量。确定了要实现的结果之后，接着就可以制订行动方针：做什么，从何处着手，如何开始，目标是什么，在多长时间内完成。\n★7、我要如何处理人际关系？ 　除了少数伟大的艺术家、科学家和运动员，很少有人是靠自己单枪匹马而取得成果的。不管是组织成员还是个体职业者，大多数人都要与别人进行合作，并且是有效的合作。要实现自我管理，你需要对自己的人际关系负起责任。这包括两部分内容。\n　首先是要接受：别人是和你一样的个体这个事实。\n　每个人都会执意展现自己作为人的个性。这就是说，**每个人都有自己的长处，自己的做事方式和自己的价值观。因此，要想卓有成效，你就必须知道共事者的长处、工作方式和价值观。**这个道理听起来让人很容易明白，但是没有几个人真正会去注意。\n　一个习惯于写报告的人就是个典型的例子——他在第一份工作时就培养起写报告的习惯，因为他的老板是一个读者型的人，而即使下一个老板是个听者型，此人也会继续写着那肯定没有任何结果的报告。这位老板因此肯定会认为这个员工愚蠢、无能、懒惰，肯定干不好工作。但是，如果这个员工事先研究过新老板的情况，并分析过这位老板的工作方式，这种情况本来可以避免。\n　老板既不是组织结构图上的一个头衔，也不是一个“职能”。他们是有个性的人，他们有权以自己最得心应手的方式来工作。与他们共事的人有责任观察他们，了解他们的工作方式，并做出相应的自我调整，以适应老板最有效的工作方式。事实上，这就是“管理”上司的秘诀。\n　这种方法适用于所有与你共事的人。每个人都有他自己的做事方法，也有权按照自己的方式来工作，而不是按你的方法来工作。重要的是，他们能否有所作为以及他们持有什么样的价值观。至于工作方式，人各有别。提高效力的第一个秘诀是了解跟你合作和你要依赖的人，以利用他们的长处、工作方式和价值观。工作关系应当既以工作为基础，也以人为基础。\n　人际关系责任的第二部分内容是沟通责任。\n　在我或是其他人开始给一个组织做咨询时，我们听到的第一件事都与个性冲突有关。其中大部分冲突都是因为：人们不知道别人在做什么，他们又是采取怎样的工作方式，专注于做出什么样的贡献以及期望得到怎样的结果。而这些人不了解情况的原因是，他们没有去问，结果也就不得而知。这种不去问明情况的做法，与其说是反映了人类的愚蠢，倒不如说是历史使然。\n　在以前，人们没必要把这些情况告诉任何人。比如在中世纪的城市，一个区的每一个人从事的行业都一样。在乡村，土地刚一解冻，山谷里的每一个人就开始播种同一种农作物。即使有少数人做的事情和大家不一样，他们也是单独工作，因此不需要告诉任何人他们在做什么。\n　而现在，大多数人都与承担着不同任务和责任的人一道工作。市场营销副总裁可能是销售出身，知道有关销售的一切，但是，对于自己从未做过的事情，比如定价、广告、包装等等，就一无所知了。所以，那些正在做这些工作的人必须确保营销副总裁懂得他们设法做的是什么、他们为什么要做这件事、他们将如何去做以及期望取得什么结果。\n　如果营销副总裁不懂得这些高层次的、知识型的专业人士在做什么，错主要在后者身上，而不在自己。反过来说，营销副总裁的责任则是确保他的所有同事都知道自己是怎样看待营销这项工作的：他的目标是什么、他如何工作，以及他对他本人和他的每一个同事有什么期望。\n　即使一些人懂得负起人际关系责任的重要性，他们和同事的交流也往往不够。他们总是有所顾虑，怕别人把自己看成是一个冒昧、愚蠢、爱打听的人。他们错了。因为我们看到，每当有人找到他的同事说“这是我所擅长的工作。这是我的做事方式。这是我的价值观。这是我计划做出的贡献和应当取得的成果”，这个人总会得到如此回答：“这太有帮助了，可你为什么不早点告诉我？”\n　如果一个人继续问道：“那么，关于你的长处、你的工作方式、你的价值观以及你计划做出的贡献，我需要知道什么？”他也会得到类似的答复——据我的经验，无一例外。事实上，知识工作者应该向与他们共事的每一个人，不管是下属、上司、同事还是团队成员，都发出这样的疑问。而且，每次提出此类问题，都会得到这样的回答：“谢谢你来问我。但是，你为什么不早点问我？”\n　**组织已不再建立在强权的基础上，而是建立在信任的基础上。人与人之间相互信任，不一定意味着他们彼此喜欢对方，而是意味着彼此了解。**因此，人们绝对有必要对自己的人际关系负责。这是一种义务。不管一个人是公司的一名成员，还是公司的顾问、供应商或经销商，他都需要对他的所有共事者负起这种责任。所谓共事者，是指在工作上他所依赖的同事以及依赖他的同事。\n★8、我该如何管理后半生？ 　当多数人的工作是体力劳动时，你不必为自己的后半生担心。你只要继续从事你一直在做的工作就行了。如果你够幸运，能在工厂或铁路辛勤工作40年后撑下来，你就可以快乐地度过余生，什么也用不着干。然而，现在的多数工作都是知识工作，而知识工作者在干了40年后，仍能发挥余热，他们只是有些厌倦。\n　我们听到了许多有关经理人中年危机的谈论，“厌倦”这个词在其中频频出现。45岁时，多数经理人的职业生涯达到了顶峰，他们也知道这一点。在做了20年完全相同的工作之后，他们已经得心应手。但是他们学不到新东西，也没有什么新贡献，从工作中得不到挑战，因而也谈不上满足感。然而，在他们面前，还有20到25年的职业道路要走。这就是为什么经理人在进行自我管理后，越来越多地开始发展第二职业的原因。\n　发展第二职业有三种方式：\n　第一种是完全投身于新工作。\n　这常常只需要从一种组织转到另一种组织。例如，一家大公司某事业部的会计师成为一家中型医院的财务总监。但是也有越来越多的人转入完全不同的职业。例如，公司经理在45岁时进入政府内阁；或者中层管理人员在公司工作20年后离职，到法学院进修，成为一个小镇的律师。还有许多人在第一份职业中取得的成功有限，于是改行从事第二职业。这样的人有很多技能，他们也知道该如何工作。而且，他们需要一个社群——因为孩子已长大单飞，剩下一座空屋。他们也需要收入。但最重要的是，他们需要挑战。\n　为后半生做准备的第二种方式是，发展一个平行的职业。\n　许多人的第一职业十分成功，他们还会继续从事原有工作，或全职或兼职，甚至只是当顾问。但是，除此之外，他们会开创一项平行的工作，通常是在非营利机构，每周占用10个小时。例如，他们可能接手教会的管理，或者担任当地女童子军顾问委员会主席。他们也可能管理受虐妇女庇护所，担任当地公共图书馆的儿童图书管理员，或在学校董事会任职等。\n　最后一种方法是社会创业。\n　社会创业者通常是在第一职业中非常成功的人士。他们都热爱自己的工作，但是这种工作对他们已经不再有挑战性。在许多情况下，他们虽然继续做着原来的工作，但在这份工作上花的时间越来越少。他们同时开创了另一项事业，通常是非营利性活动。例如，我的朋友鲍勃·布福德创办了一个非常成功的电视公司，现在他仍然经营着。但与此同时，他还创建了一个与新教教会合作的非营利组织，也做得非常成功。现在他又创建了一个组织，专门指导社会创业者在经营原有业务的同时，如何管理自己另外创办的非营利机构。\n　**能管理好自己后半生的人总是少数。多数人可能“一干到底”，数着年头一年一年过去，直至退休。**但是，正是这些少数人，这些把漫长的工作寿命看做是自己和社会之机会的男男女女，才会成为领袖和模范。\n　**管理好后半生有一个先决条件：你必须早在你进入后半生之前就开始行动。**当30年前人们首次认识到工作寿命正在迅速延长时，许多观察家（包括我自己）认为，退休人员会越来越多地成为非营利机构的志愿者。可是，这种情况并没有发生。一个人如果不在40岁之前就开始做志愿者，那他60岁之后也不会去做志愿者。\n　同样，我认识的所有社会创业者，都是早在他们原有的事业达到顶峰之前就开始从事他们的第二事业。请看一名成功律师的例子。这位律师是一家大公司的法律顾问，他同时在自己所在的州开办了模特培训学校。早在他35岁左右的时候，他就开始志愿为学校提供法律咨询。40岁时被推选为一家学校的董事会成员。50岁时，他积累起了一笔财富，办起了自己的企业——建立并经营模特培训学校。然而此时，他依旧在那家他年轻时参与创建的公司里担任首席法律顾问，而且几乎是全职工作。\n　发展第二兴趣（而且是趁早发展）还有一个原因：任何人都不能指望在生活或工作中很长时间都不遭遇严重挫折。有一位很能干的工程师在45岁时错过了晋升的机会。另一位也很能干的普通学院的教授在42岁时认识到，即使她完全具备担任教授的资格，她永远也不会在一所有名的大学里获得教授职位。还有一位则是在家庭生活里出现了悲剧：婚姻破裂或者痛失子女。在这样的时刻，第二兴趣——不仅仅是业余爱好——还可能发挥重要作用。例如，这位工程师现在知道他在工作上并不十分成功。但是，在公司以外的活动中，例如负责教会资金的管理，他是成功的。一个人可能家庭破碎，但是他能在第二兴趣的活动中发现还有社区这个大“家庭”。\n　在一个崇尚成功的社会里，拥有各种选择变得越来越重要。从历史上来看，却没有“成功”一说。绝大多数人只期望坚守“适当的位置”。唯一的流动性是向下的流动性。然而，在知识社会里，我们期望每一个人都能取得成功。这显然是不可能的。对许多人来说，能避免失败就行。可是有成功的地方，就会有失败。因此，有一个能够让人们做出贡献、发挥影响力或成为“大人物”的领域，这不仅对个人十分重要，对个人的家庭也同样重要。这意味着人们需要找到一个能够有机会成为领袖、受到尊重、取得成功的第二领域——可能是第二份职业，也可能是平行的职业或社会创业。\n　自我管理中面临的挑战看上去比较明显，甚至非常基本，其答案可能不言自明，甚至近乎幼稚。但是，自我管理需要个人，尤其是知识工作者，做出以前从未做过的事情。实际上，自我管理需要每一个知识工作者在思想和行动上都要成为自己的首席执行官。更进一步来看，这样的转变——从一切听从别人吩咐的体力劳动者到不得不自我管理的知识工作者——也使得社会结构发生了深刻变化。\n　历史上每一个社会，甚至是个人主义倾向最强的社会，都认为（即使只是下意识地认为）两件事情是理所当然的：\n 1、组织比员工更长寿；\n2、大多数人从不挪地方。\n 　如今，情况恰恰相反。知识工作者的寿命超过了组织寿命，而且他们来去自如。于是，人们对自我管理的需要在人类事务中掀起了一场革命。\n","description":"据说，这篇长文对每个人都很有帮助。通过此文的借鉴，可以帮助你更好地规划自己的职业生涯和人生。","id":18,"section":"reproduced","tags":["转载",""],"title":"转载：自我管理","uri":"http://blog.langchao2020.tech/reproduced/managing-oneself/"},{"content":"★《爱因斯坦：我的世界观》 　我们这些总有一死的人，命运是多么的奇特！我们每个人在这个世界上都只作一个短暂的逗留；目的何在，却无从知道，尽管有时自以为对此若有所感。但是，不必深思，只要从日常生活中就可以明白：人是为别人而生存的──首先是为那样一些人，我们的幸福全部依赖于他们的喜悦和健康；其次是为许多我们所不认识的人，他们的命运通过同情的纽带同我们密切结合在一起。我每天上百次的提醒自己：我的精神生活和物质生活都是以别人（包括生者和死者）的劳动为基础的，我必须尽力以同样的分量来报偿我所领受了的和至今还在领受着的东西。我强烈地向往着俭朴的生活。并且时常发觉自己占用了同胞的过多劳动而难以忍受。我认为阶级的区分是不合理的，它最后所凭借的是以暴力为根据。我也相信，简单淳朴的生活，无论在身体上还是在精神上，对每个人都是有益的。\n　我完全不相信人类会有那种在哲学意义上的自由。每个人的行为不仅受着外界的强制，而且要适应内在的必然。叔本华说：“人虽然能够做他所想做的，但不能要他所想要的。”这句格言从我青年时代起就给了我真正的启示；在我自己和别人的生活面临困难的时候，它总是使我们得到安慰，并且是宽容的持续不断的源泉。这种体会可以宽大为怀地减轻那种容易使人气馁的责任感，也可以防止我们过于严肃地对待自己和别人；它导致一种特别给幽默以应有地位的人生观。\n　要追究一个人自己或一切生物生存的意义或目的，从客观的角度来看，我总觉得是愚蠢可笑的。可是每个人都有一些理想，这些理想决定着他的努力和判断的方向。就在这个意义上，我从来不把安逸和享乐看作生活目的本身──我把这种伦理基础叫做“猪栏的理想”。照亮我的道路，是善、美和真。要是没有志同道合者之间的亲切感情，要不是全神贯注于客观世界──那个在艺术和科学工作领域里永远达不到的对象，那么在我看来，生活就会是空虚的。我总觉得，人们所努力追求的庸俗目标──财产、虚荣、奢侈的生活──都是可鄙的。\n　我有强烈的社会正义感和社会责任感，但我又明显地缺乏与别人和社会直接接触的要求，这两者总是形成古怪的对照。我实在是一个“孤独的旅客”，我未曾全心全意地属于我的国家、我的家庭、我的朋友，甚至我最为接近的亲人；在所有这些关系面前，我总是感觉到有一定距离而且需要保持孤独──而这种感受正与年俱增。人们会清楚地发觉，同别人的相互了解和协调一致是有限度的，但这不值得惋惜。无疑，这样的人在某种程度上会失去他的天真无邪和无忧无虑的心境；但另一方面，他却能够在很大程度上不为别人的意见、习惯和判断所左右，并且能够避免那种把他的内心平衡建立在这样一些不可靠的基础之上的诱惑。\n　我的政治理想是民主政体。让每一个人都作为个人而受到尊重，而不让任何人成为被崇拜的偶像。我自己一直受到同代人的过分的赞扬和尊敬，这不是由于我自己的过错，也不是由于我自己的功劳，而实在是一种命运的嘲弄。其原因大概在于人们有一种愿望，想理解我以自已微薄的绵力，通过不断的斗争所获得的少数几个观念，而这种愿望有很多人却未能实现。我完全明白，一个组织要实现它的目的，就必须有一个人去思考，去指挥、并且全面担负起责任来。但是被领导的人不应当受到强迫，他们必须能够选择自己的领袖。在我看来，强迫的专制制度很快就会腐化堕落。因为暴力所招引来的总是一些品德低劣的人；而且我相信，天才的暴君总是由无赖来继承的，这是一条千古不易的规律。就是由于这个缘故，我总强烈地反对今天在意大利和俄国所见到的那种制度。像欧洲今天所存在的情况，已使得民主形式受到怀疑，这不能归咎于民主原则本身，而是由于政府的不稳定和选举制度中与个人无关的特征。我相信美国在这方面已经找到了正确的道路。他们选出了一个任期足够长的总统，他有充分的权力来真正履行他的职责。另一方面，在德国政治制度中，为我所看重的是它为救济患病或贫困的人作出了可贵的广泛的规定。在人生的丰富多彩的表演中，我觉得真正可贵的，不是政治上的国家，而是有创造性的、有感情的个人，是人格；只有个人才能创造出高尚的和卓越的东西，而群众本身在思想上总是迟钝的，在感觉上也总是迟钝的。\n　讲到这里，我想起了群众生活中最坏的一种表现，那就是使我厌恶的军事制度。一个人能够洋洋得意的随着军乐队在四列纵队里行进，单凭这一点就足以使我对他鄙夷不屑。他所以长了一个大脑，只是出于误会；光是骨髓就可满足他的全部需要了。文明的这种罪恶的渊薮，应当尽快加以消灭。任人支配的英雄主义、冷酷无情的暴行，以及在爱国主义名义下的一切可恶的胡闹，所有这些都使我深恶痛绝！在我看来，战争是多么卑鄙、下流！我宁愿被千刀万剐，也不愿参与这种可憎的勾当。尽管如此，我对人类的评价还是十分高的。我相信，要是人民的健康感情没有遭到那些通过学校和报纸而起作用的商业利益和政治利益的蓄意败坏，那么战争这个妖魔早就该绝迹了。\n　我们能拥有的最美好的体验是探求奥秘的体验。它是坚守在真正艺术和真正科学发源地上的基本感情。谁要是体会不到它，谁要是不再有好奇心，也不再有惊讶的感觉，谁就无异于行尸走肉，他的眼睛便是模糊不清的。就是这种奥秘的体验──虽然掺杂着恐惧──产生了宗教。我们认识到有某种为我们所不能洞察的东西存在，感觉到那种只能以其最原始的形式接近我们的心灵的最深奥的理性和最灿烂的美──正是这种认识和这种情感构成了真正的宗教感情；在这个意义上，而且也只是在这个意义上，我才是一个具有深挚的宗教感情的人。我无法想象存在这样一个上帝，它会对自己的创造物加以赏罚，会具有我们在自己身上所体验到的那种意志。我不能也不愿去想象一个人在肉体死亡以后还会继续活着；让那些脆弱的灵魂，由于恐惧或者由于可笑的唯我论，去拿这种思想当宝贝吧！我自己只求满足于生命永恒的奥秘，满足于觉察现存世界的神奇结构，窥见它的一鳞半爪，并且以诚挚的努力去领悟在自然界中显示出来的那个理性的一部分，倘若真能如此，即使只领悟其极小的一部分，我也就心满意足了。\n★《乔布斯：在斯坦福大学的演讲》 　我十七岁的时候，读到了一句话：“如果你把每一天都当作生命中最后一天去生活的话，那么有一天你会发现自己是正确的。”这句话给我留下了深刻的印象。从那时开始，过了33年，我在每天早晨都会对着镜子问自己：“如果今天是我生命中的最后一天，我还会做今天要做的事情吗？”如果连续很多天得到否定的回答，那我就需要作出一些改变了。\n　“记住你即将死去”是我一生中遇到的最重要箴言。它帮我指明了生命中重要的选择。因为几乎所有的事情（包括所有的荣誉、所有的骄傲、所有对难堪和失败的恐惧），在死亡面前都会消失。我看到的是留下的真正重要的东西。\n　你有时候会思考你将要失去的东西，“记住你即将死去”是我知道的避免这些想法的最好办法。你已经赤身裸体了，你没有理由不去跟随自己的心一起跳动。\n　大概一年以前，我的一次体检结果清楚的显示在我的胰腺有一个肿瘤。医生告诉我那很可能是一种无法治愈的癌症，我还有三到六个月的时间活在这个世界上。我的医生叫我回家，然后整理好我的一切，那就是医生准备死亡的程序。那意味着你将要把未来十年对你小孩说的话在几个月里面说完；那意味着把每件事情都搞定，让你的家人会尽可能轻松的生活；那意味着你要说“再见了”。我整天和那个诊断书一起生活。后来有一天早上医生将一个内窥镜从我的喉咙伸进去，通过我的胃，然后进入我的肠子，用一根针在我的胰腺上的肿瘤上取了几个细胞。我当时很镇静，因为我被注射了镇定剂。但是我的妻子在那里，后来告诉我，当医生在显微镜地下观察这些细胞的时候他们开始尖叫，因为这些细胞最后竟然是一种非常罕见的、可以用手术治愈的胰腺癌细胞。我做了这个手术，现在我痊愈了。\n　那是我最接近死亡的时候，我还希望这也是以后的几十年最接近的一次。从死亡线上又活了过来，死亡对我来说，只是一个有用但是纯粹是知识上的概念的时候，我可以更肯定一点地对你们说：没有人愿意死，即使人们想上天堂，人们也不会为了去那里而死。但是死亡是我们每个人共同的终点。从来没有人能够逃脱它，也应该如此。因为死亡是生命中最好的一个发明。它把旧的清除以便给新的让路。你们现在是新的，但是从现在开始不久以后，你们将会逐渐的变成旧的然后被清除。这很有戏剧性，而事实就是如此。\n　你们的时间有限，所以不要浪费时间去重复别人的生活。不要被教条束缚，那意味着你和其他人思考的结果一起生活。不要被其他人喧嚣的观点掩盖你内心真正的想法。还有最重要的是，拥有追随自己内心与直觉的勇气——你的内心与直觉多少已经知道你真正想要成为什么样的人。与之相比，所有其它事情都是次要的。\n　当我年轻的时候，有一本振聋发聩的杂志叫做《全球概览》——它是我们那代人的圣经之一。一个叫 Stewart Brand 的家伙神奇地将这本杂志带到这个世界上。当时还是60年代末，所以这本书全部是用打字机、剪刀还有偏光镜制作的。Stewart 和他的伙伴出版了几期《全球概览》，当它完成了自己使命的时候，他们出了最后一期。在最后一期的封底上是清晨乡村公路的照片（如果你有冒险精神的话，你可以自己找到这条路的），在照片之下有这样一段话：“Stay Hungry, Stay Foolish”。这是他们停止了发刊的告别语。“Stay Hungry, Stay Foolish”，我总是希望自己能够那样。现在，在你们即将毕业，开始新的旅程的时候。我也希望你们能做到：Stay Hungry, Stay Foolish。\n★《王小波：工作与人生》 　我现在已经活到了人生的中途，拿一日来比喻人的一生，现在正是中午。人在童年时从朦胧中醒来，需要一些时间来克服清晨的软弱，然后就要投入工作；在正午时分，他的精力最为充沛，但已隐隐感到疲惫；到了黄昏时节，就要总结一日的工作，准备沉入永恒的休息。按我这种说法，工作是人一生的主题。这个想法不是人人都能同意的。我知道在中国，农村的人把生儿育女看作是一生的主题。把儿女养大，自己就死掉，给他们空出地方来——这是很流行的想法。在城市里则另有一种想法，但不知是不是很流行：它把取得社会地位看作一生的主题。站在北京八宝山的骨灰墙前，可以体会到这种想法。我在那里看到一位已故的大叔墓上写着：副系主任、支部副书记、副教授、某某教研室副主任，等等。假如能把这些“副”字去掉个把，对这位大叔当然更好一些，但这些“副”字最能证明有这样一种想法。顺便说一句，我到美国的公墓里看过，发现他们的墓碑上只写两件事：一是生卒年月，二是某年至某年服兵役；这就是说，他们以为人的一生只有这两件事值得记述：这位上帝的子民曾经来到尘世，以及这位公民曾去为国尽忠，写别的都是多余的，我觉得这种想法比较质朴……恐怕在一份青年刊物上写这些墓前的景物是太过伤感，还是及早回到正题上来罢。\n　我想要把自己对人生的看法推荐给青年朋友们：人从工作中可以得到乐趣，这是一种巨大的好处。相比之下，从金钱、权力、生育子女方面可以得到的快乐，总要受到制约。举例来说，现在把生育作为生活的主题，首先是不合时宜；其次，人在生育力方面比兔子大为不如，更不要说和黄花鱼相比较；在这方面很难取得无穷无尽的成就。我对权力没有兴趣，对钱有一些兴趣，但也不愿为它去受罪——做我想做的事（这件事对我来说，就是写小说），并且把它做好，这就是我的目标。我想，和我志趣相投的人总不会是一个都没有。\n　根据我的经验，人在年轻时，最头疼的一件事就是决定自己这一生要做什么。在这方面，我倒没有什么具体的建议：干什么都可以，但最好不要写小说，这是和我抢饭碗。当然，假如你执意要写，我也没理由反对。总而言之，干什么都是好的；但要干出个样子来，这才是人的价值和尊严所在。人在工作时，不单要用到手、腿和腰，还要用脑子和自己的心胸。我总觉得国人对这后一方面不够重视，这样就会把工作看成是受罪。失掉了快乐最主要的源泉，对生活的态度也会因之变得灰暗……\n　人活在世上，不但有身体，还有头脑和心胸——对此请勿从解剖学上理解。人脑是怎样的一种东西，科学还不能说清楚。心胸是怎么回事就更难说清。对我自己来说，心胸是我在生活中想要达到的最低目标。某件事有悖于我的心胸，我就认为它不值得一做；某个人有悖于我的心胸，我就觉得他不值得一交；某种生活有悖于我的心胸，我就会以为它不值得一过。罗素先生曾言，对人来说，不加检点的生活，确实不值得一过。我同意他的意见：不加检点的生活，属于不能接受的生活之一种。人必须过他可以接受的生活，这恰恰是他改变一切的动力。人有了心胸，就可以用它来改变自己的生活。\n　中国人喜欢接受这样的想法：只要能活着就是好的，活成什么样子无所谓。从一些电影的名字就可以看出来：《活着》、《找乐》……我对这种想法是断然地不赞成，因为抱有这种想法的人就可能活成任何一种糟糕的样子，从而使生活本身失去意义。高尚、清洁、充满乐趣的生活是好的，人们很容易得到共识。卑下、肮脏、贫乏的生活是不好的，这也能得到共识。但只有这两条远远不够。我以写作为生，我知道某种文章好，也知道某种文章坏。仅知道这两条尚不足以开始写作。还有更加重要的一条，那就是：某种样子的文章对我来说不可取，绝不能让它从我笔下写出来，冠以我的名字登在报刊上。以小喻大，这也是我对生活的态度。\n","description":"转载三篇有关于爱因斯坦对人生、政治、宗教的看法的著名演讲以及乔布斯在斯坦福大学的演讲、王小波对工作与人生的看法相关文章。","id":19,"section":"reproduced","tags":["转载",""],"title":"转载：关于人生","uri":"http://blog.langchao2020.tech/reproduced/my-worldview/"},{"content":"Sample images from Pixabay\n","description":"cartoon gallery","id":20,"section":"gallery","tags":null,"title":"Cartoon","uri":"http://blog.langchao2020.tech/gallery/cartoon/"},{"content":"Sample images from Pixabay\n","description":"photo gallery","id":21,"section":"gallery","tags":null,"title":"Photo","uri":"http://blog.langchao2020.tech/gallery/photo/"}]